{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook match and combine dataframes with the enrollment data\n",
    "\n",
    "### going to use fuzzy matching to acomplish the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### File Locations\n",
    "# File location and type\n",
    "\n",
    "# 2022 Enrollment Data\n",
    "enroll_df = pd.read_excel('data\\collected.xlsx', sheet_name='2022_enrollment')\n",
    "\n",
    "# Sheet with manually collected data\n",
    "manual_df = pd.read_excel('data\\collected.xlsx', sheet_name='manual')\n",
    "\n",
    "# Sheet with calculated data\n",
    "area_sqft_df = pd.read_excel('data\\collected.xlsx', sheet_name='area_sqft')\n",
    "\n",
    "high_school_df = manual_df[manual_df['Level'] == 'high school']\n",
    "# high_school_df.head()\n",
    "# enroll_df.head()\n",
    "# area_sqft_df.head()\n",
    "\n",
    "##### Working to Load all the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_904\\253980905.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  high_school_df['match'] = high_school_df['School'].apply(lambda x: difflib.get_close_matches(x, enroll_df['school_name'].tolist(), n=1, cutoff=0.8))\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_904\\253980905.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  high_school_df['match'] = high_school_df['match'].apply(lambda x: x[0] if len(x) > 0 else np.nan)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_904\\253980905.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  high_school_df['enrollment'] = high_school_df['match'].apply(lambda x: enroll_df[enroll_df['school_name'] == x]['enrollment_classification'].values[0] if type(x) == str else np.nan)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_904\\253980905.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  high_school_df['school_id'] = high_school_df['match'].apply(lambda x: enroll_df[enroll_df['school_name'] == x]['school_id'].values[0] if type(x) == str else np.nan)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_904\\253980905.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  high_school_df['Div'] = high_school_df['match'].apply(lambda x: enroll_df[enroll_df['school_name'] == x]['division'].values[0] if type(x) == str else np.nan)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_904\\253980905.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  high_school_df['enrollment'] = high_school_df['enrollment'].fillna(0)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_904\\253980905.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  high_school_df['school_id'] = high_school_df['school_id'].fillna(0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FOP_GE_area</th>\n",
       "      <th>FOP_perim</th>\n",
       "      <th>Foul_GE_area</th>\n",
       "      <th>Foul_perim</th>\n",
       "      <th>FOP_ratio</th>\n",
       "      <th>Foul-ratio</th>\n",
       "      <th>Foul_pct_of_whole</th>\n",
       "      <th>YE_2022_rank</th>\n",
       "      <th>Region_div</th>\n",
       "      <th>enrollment</th>\n",
       "      <th>school_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>148.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>148.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>90254.837838</td>\n",
       "      <td>1178.319728</td>\n",
       "      <td>27357.493243</td>\n",
       "      <td>1398.128378</td>\n",
       "      <td>76.227799</td>\n",
       "      <td>19.887823</td>\n",
       "      <td>0.235314</td>\n",
       "      <td>10.328947</td>\n",
       "      <td>2.550000</td>\n",
       "      <td>337.209459</td>\n",
       "      <td>1991.844595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8070.986379</td>\n",
       "      <td>55.351305</td>\n",
       "      <td>6528.582436</td>\n",
       "      <td>72.717072</td>\n",
       "      <td>4.195067</td>\n",
       "      <td>4.503542</td>\n",
       "      <td>0.044588</td>\n",
       "      <td>5.881923</td>\n",
       "      <td>1.111191</td>\n",
       "      <td>558.265490</td>\n",
       "      <td>2662.015997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>70894.000000</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>13992.000000</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>62.560057</td>\n",
       "      <td>10.629978</td>\n",
       "      <td>0.131112</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>86184.250000</td>\n",
       "      <td>1150.500000</td>\n",
       "      <td>21988.500000</td>\n",
       "      <td>1355.750000</td>\n",
       "      <td>74.189485</td>\n",
       "      <td>16.229598</td>\n",
       "      <td>0.207135</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>90089.500000</td>\n",
       "      <td>1176.000000</td>\n",
       "      <td>27621.500000</td>\n",
       "      <td>1392.500000</td>\n",
       "      <td>76.318259</td>\n",
       "      <td>20.007988</td>\n",
       "      <td>0.237437</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>93751.750000</td>\n",
       "      <td>1200.500000</td>\n",
       "      <td>32033.250000</td>\n",
       "      <td>1431.500000</td>\n",
       "      <td>78.282507</td>\n",
       "      <td>23.240048</td>\n",
       "      <td>0.267046</td>\n",
       "      <td>15.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>457.750000</td>\n",
       "      <td>3633.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>139904.000000</td>\n",
       "      <td>1540.000000</td>\n",
       "      <td>46286.000000</td>\n",
       "      <td>1750.000000</td>\n",
       "      <td>91.496469</td>\n",
       "      <td>27.961942</td>\n",
       "      <td>0.313700</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2812.000000</td>\n",
       "      <td>8192.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         FOP_GE_area    FOP_perim  Foul_GE_area   Foul_perim  FOP_ratio  \\\n",
       "count     148.000000   147.000000    148.000000   148.000000  63.000000   \n",
       "mean    90254.837838  1178.319728  27357.493243  1398.128378  76.227799   \n",
       "std      8070.986379    55.351305   6528.582436    72.717072   4.195067   \n",
       "min     70894.000000  1046.000000  13992.000000  1166.000000  62.560057   \n",
       "25%     86184.250000  1150.500000  21988.500000  1355.750000  74.189485   \n",
       "50%     90089.500000  1176.000000  27621.500000  1392.500000  76.318259   \n",
       "75%     93751.750000  1200.500000  32033.250000  1431.500000  78.282507   \n",
       "max    139904.000000  1540.000000  46286.000000  1750.000000  91.496469   \n",
       "\n",
       "       Foul-ratio  Foul_pct_of_whole  YE_2022_rank  Region_div   enrollment  \\\n",
       "count   63.000000          63.000000     76.000000   60.000000   148.000000   \n",
       "mean    19.887823           0.235314     10.328947    2.550000   337.209459   \n",
       "std      4.503542           0.044588      5.881923    1.111191   558.265490   \n",
       "min     10.629978           0.131112      1.000000    1.000000     0.000000   \n",
       "25%     16.229598           0.207135      5.000000    2.000000     0.000000   \n",
       "50%     20.007988           0.237437     10.000000    2.500000     0.000000   \n",
       "75%     23.240048           0.267046     15.250000    4.000000   457.750000   \n",
       "max     27.961942           0.313700     20.000000    4.000000  2812.000000   \n",
       "\n",
       "         school_id  \n",
       "count   148.000000  \n",
       "mean   1991.844595  \n",
       "std    2662.015997  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%    3633.250000  \n",
       "max    8192.000000  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Lookup enrollment numbers and school id from the enrollment sheet and add them to the high school sheet\n",
    "\n",
    "import difflib\n",
    "\n",
    "high_school_df['match'] = high_school_df['School'].apply(lambda x: difflib.get_close_matches(x, enroll_df['school_name'].tolist(), n=1, cutoff=0.8))\n",
    "high_school_df['match'] = high_school_df['match'].apply(lambda x: x[0] if len(x) > 0 else np.nan)\n",
    "high_school_df['enrollment'] = high_school_df['match'].apply(lambda x: enroll_df[enroll_df['school_name'] == x]['enrollment_classification'].values[0] if type(x) == str else np.nan)\n",
    "high_school_df['school_id'] = high_school_df['match'].apply(lambda x: enroll_df[enroll_df['school_name'] == x]['school_id'].values[0] if type(x) == str else np.nan)\n",
    "high_school_df['Div'] = high_school_df['match'].apply(lambda x: enroll_df[enroll_df['school_name'] == x]['division'].values[0] if type(x) == str else np.nan)\n",
    "high_school_df['enrollment'] = high_school_df['enrollment'].fillna(0)\n",
    "high_school_df['school_id'] = high_school_df['school_id'].fillna(0)\n",
    "high_school_df = high_school_df.drop(columns=['match'])\n",
    "high_school_df.head()\n",
    "\n",
    "high_school_df.describe()\n",
    "\n",
    "## Export csv to check output\n",
    "\n",
    "# high_school_df.to_csv('data\\high_school_df_test.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 222 entries, 0 to 221\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  222 non-null    int64  \n",
      " 1   field       222 non-null    object \n",
      " 2   home_plate  222 non-null    object \n",
      " 3   foul_ft     222 non-null    float64\n",
      " 4   fop_ft      222 non-null    float64\n",
      " 5   foul_pct    222 non-null    float64\n",
      " 6   enrollment  222 non-null    float64\n",
      " 7   school_id   222 non-null    float64\n",
      " 8   Div         64 non-null     object \n",
      "dtypes: float64(5), int64(1), object(3)\n",
      "memory usage: 15.7+ KB\n"
     ]
    }
   ],
   "source": [
    "## Lookup enrollment numbers and school id from the enrollment sheet and add them to the area_sqft sheet\n",
    "\n",
    "import difflib\n",
    "\n",
    "area_sqft_df['match'] = area_sqft_df['field'].apply(lambda x: difflib.get_close_matches(x, enroll_df['school_name'].tolist(), n=1, cutoff=0.8))\n",
    "area_sqft_df['match'] = area_sqft_df['match'].apply(lambda x: x[0] if len(x) > 0 else np.nan)\n",
    "area_sqft_df['enrollment'] = area_sqft_df['match'].apply(lambda x: enroll_df[enroll_df['school_name'] == x]['enrollment_classification'].values[0] if type(x) == str else np.nan)\n",
    "area_sqft_df['school_id'] = area_sqft_df['match'].apply(lambda x: enroll_df[enroll_df['school_name'] == x]['school_id'].values[0] if type(x) == str else np.nan)\n",
    "area_sqft_df['Div'] = area_sqft_df['match'].apply(lambda x: enroll_df[enroll_df['school_name'] == x]['division'].values[0] if type(x) == str else np.nan)\n",
    "area_sqft_df['enrollment'] = area_sqft_df['enrollment'].fillna(0)\n",
    "area_sqft_df['school_id'] = area_sqft_df['school_id'].fillna(0)\n",
    "area_sqft_df = area_sqft_df.drop(columns=['match'])\n",
    "area_sqft_df.info()\n",
    "\n",
    "## Export csv to check output\n",
    "area_sqft_df.to_csv('area_sqft_df_test.csv')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code above works\n",
    "\n",
    "### the lookups need to be a lot better. only matched 64 records out of 222\n",
    "\n",
    "\n",
    "#### the problem might just be how messy the field names are in the area_sqft_df\n",
    "#### might need to clean them up at the google maps level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_904\\1073604786.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  high_school_df['match'] = high_school_df['School'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "##### THIS BLOCK IS KIND OF A MESS AND PROBABLY ISN'T GOING TO BE USED\n",
    "\n",
    "### merge the dataframes\n",
    "import difflib\n",
    "# from fuzzywuzzy import fuzz\n",
    "# from fuzzywuzzy import process\n",
    "\n",
    "\n",
    "high_school_df['match'] = high_school_df['School'].str.lower()\n",
    "enroll_df['match'] = enroll_df['school_name'].str.lower()\n",
    "area_sqft_df['match'] = area_sqft_df['field'].str.lower()\n",
    "\n",
    "## Drop the columns that are not needed\n",
    "high_school_df = high_school_df.drop(columns=['FOP_ratio','Foul-ratio','Foul_pct_of_whole'])\n",
    "\n",
    "\n",
    "## Match the school names\n",
    "high_school_df['mat2'] = high_school_df['match'].apply(lambda x: difflib.get_close_matches(x, enroll_df['match'], n=1, cutoff=0.8))\n",
    "area_sqft_df['mat2'] = area_sqft_df['match'].apply(lambda x: difflib.get_close_matches(x, enroll_df['match'], n=1, cutoff=0.8))\n",
    "enroll_df['mat2'] = high_school_df['match'].apply(lambda x: difflib.get_close_matches(x, enroll_df['match'], n=1, cutoff=0.8))\n",
    "\n",
    "enroll_df['mat2'] = enroll_df['mat2'].to_string()\n",
    "high_school_df['mat2'] = high_school_df['mat2'].to_string()\n",
    "area_sqft_df['mat2'] = area_sqft_df['mat2'].to_string()\n",
    "temp_df = high_school_df.merge(area_sqft_df, on='mat2', how = 'outer')\n",
    "# new_df = temp_df.merge(enroll_df, on='mat2',how='right')\n",
    "\n",
    "temp_df.head()\n",
    "\n",
    "#### Merge seems to work\n",
    "## Output a csv to see what is going on\n",
    "# temp_df.to_csv('new_df.csv')\n",
    "\n",
    "\n",
    "## cAN'T make the merge work yet\n",
    "# outputing the dataframes to csv to see what is going on\n",
    "# high_school_df.to_csv('high_school_df.csv')\n",
    "# enroll_df.to_csv('enroll_df.csv')\n",
    "area_sqft_df.to_csv('area_sqft_df.csv')\n",
    "\n",
    "# ## Merge the dataframes\n",
    "# new_df = high_school_df.merge(area_sqft_df, on='mat2',how='right')\n",
    "\n",
    "# new_df.head()\n",
    "# high_school_df.head()\n",
    "# enroll_df.head()\n",
    "# area_sqft_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Justin\\Desktop\\Project\\BB_parks\\fuzzy_match_book.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/BB_parks/fuzzy_match_book.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m enroll_df[\u001b[39m'\u001b[39m\u001b[39mschool_match\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m enroll_df[\u001b[39m'\u001b[39m\u001b[39mschool_name\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/BB_parks/fuzzy_match_book.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m area_sqft_df[\u001b[39m'\u001b[39m\u001b[39mschool_match\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m area_sqft_df[\u001b[39m'\u001b[39m\u001b[39mfield\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: difflib\u001b[39m.\u001b[39mget_close_matches(x, enroll_df[\u001b[39m'\u001b[39m\u001b[39mschool_match\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/BB_parks/fuzzy_match_book.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m new_df \u001b[39m=\u001b[39m area_sqft_df\u001b[39m.\u001b[39;49mjoin(enroll_df, on\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mschool_match\u001b[39;49m\u001b[39m'\u001b[39;49m, how\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mleft\u001b[39;49m\u001b[39m'\u001b[39;49m, lsuffix\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m_left\u001b[39;49m\u001b[39m'\u001b[39;49m, rsuffix\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m_right\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/BB_parks/fuzzy_match_book.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# area_sqft_df['school_match'] = area_sqft_df['school_match']\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/BB_parks/fuzzy_match_book.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# area_sqft_df.dtypes\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/BB_parks/fuzzy_match_book.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m high_school_df\u001b[39m.\u001b[39mdtypes\n",
      "File \u001b[1;32mc:\\Users\\Justin\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:9254\u001b[0m, in \u001b[0;36mDataFrame.join\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   9100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjoin\u001b[39m(\n\u001b[0;32m   9101\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   9102\u001b[0m     other: DataFrame \u001b[39m|\u001b[39m Series,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9107\u001b[0m     sort: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   9108\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m   9109\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   9110\u001b[0m \u001b[39m    Join columns of another DataFrame.\u001b[39;00m\n\u001b[0;32m   9111\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9252\u001b[0m \u001b[39m    5  K1  A5   B1\u001b[39;00m\n\u001b[0;32m   9253\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 9254\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_join_compat(\n\u001b[0;32m   9255\u001b[0m         other, on\u001b[39m=\u001b[39;49mon, how\u001b[39m=\u001b[39;49mhow, lsuffix\u001b[39m=\u001b[39;49mlsuffix, rsuffix\u001b[39m=\u001b[39;49mrsuffix, sort\u001b[39m=\u001b[39;49msort\n\u001b[0;32m   9256\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Justin\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:9285\u001b[0m, in \u001b[0;36mDataFrame._join_compat\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   9276\u001b[0m     \u001b[39mif\u001b[39;00m how \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcross\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   9277\u001b[0m         \u001b[39mreturn\u001b[39;00m merge(\n\u001b[0;32m   9278\u001b[0m             \u001b[39mself\u001b[39m,\n\u001b[0;32m   9279\u001b[0m             other,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9283\u001b[0m             sort\u001b[39m=\u001b[39msort,\n\u001b[0;32m   9284\u001b[0m         )\n\u001b[1;32m-> 9285\u001b[0m     \u001b[39mreturn\u001b[39;00m merge(\n\u001b[0;32m   9286\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   9287\u001b[0m         other,\n\u001b[0;32m   9288\u001b[0m         left_on\u001b[39m=\u001b[39;49mon,\n\u001b[0;32m   9289\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[0;32m   9290\u001b[0m         left_index\u001b[39m=\u001b[39;49mon \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   9291\u001b[0m         right_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   9292\u001b[0m         suffixes\u001b[39m=\u001b[39;49m(lsuffix, rsuffix),\n\u001b[0;32m   9293\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m   9294\u001b[0m     )\n\u001b[0;32m   9295\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   9296\u001b[0m     \u001b[39mif\u001b[39;00m on \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Justin\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:107\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    106\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m--> 107\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[0;32m    108\u001b[0m         left,\n\u001b[0;32m    109\u001b[0m         right,\n\u001b[0;32m    110\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[0;32m    111\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[0;32m    112\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[0;32m    113\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[0;32m    114\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[0;32m    115\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[0;32m    116\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    117\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[0;32m    118\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    119\u001b[0m         indicator\u001b[39m=\u001b[39;49mindicator,\n\u001b[0;32m    120\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m    121\u001b[0m     )\n\u001b[0;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\Justin\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:704\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    696\u001b[0m (\n\u001b[0;32m    697\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft_join_keys,\n\u001b[0;32m    698\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_join_keys,\n\u001b[0;32m    699\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjoin_names,\n\u001b[0;32m    700\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_merge_keys()\n\u001b[0;32m    702\u001b[0m \u001b[39m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    703\u001b[0m \u001b[39m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m--> 704\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_coerce_merge_keys()\n\u001b[0;32m    706\u001b[0m \u001b[39m# If argument passed to validate,\u001b[39;00m\n\u001b[0;32m    707\u001b[0m \u001b[39m# check if columns specified as unique\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[39m# are in fact unique.\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[39mif\u001b[39;00m validate \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Justin\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1257\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1251\u001b[0m     \u001b[39m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[0;32m   1252\u001b[0m     \u001b[39melif\u001b[39;00m (\n\u001b[0;32m   1253\u001b[0m         inferred_left \u001b[39min\u001b[39;00m string_types \u001b[39mand\u001b[39;00m inferred_right \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m string_types\n\u001b[0;32m   1254\u001b[0m     ) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   1255\u001b[0m         inferred_right \u001b[39min\u001b[39;00m string_types \u001b[39mand\u001b[39;00m inferred_left \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m string_types\n\u001b[0;32m   1256\u001b[0m     ):\n\u001b[1;32m-> 1257\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1259\u001b[0m \u001b[39m# datetimelikes must match exactly\u001b[39;00m\n\u001b[0;32m   1260\u001b[0m \u001b[39melif\u001b[39;00m needs_i8_conversion(lk\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m needs_i8_conversion(rk\u001b[39m.\u001b[39mdtype):\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "import difflib \n",
    "\n",
    "# high_school_df['school_match'] = high_school_df['School'].apply(lambda x: difflib.get_close_matches(x, enroll_df['school_name']))\n",
    "# # high_school_df['school_match'] = high_school_df['school_match']\n",
    "# high_school_df.dtypes\n",
    "\n",
    "# new_df = high_school_df.join(enroll_df, on='school_name', how='left', lsuffix='_left', rsuffix='_right')\n",
    "# new_df\n",
    "enroll_df['school_match'] = enroll_df['school_name']\n",
    "\n",
    "area_sqft_df['school_match'] = area_sqft_df['field'].apply(lambda x: difflib.get_close_matches(x, enroll_df['school_match']))\n",
    "new_df = area_sqft_df.join(enroll_df, on='school_match', how='left', lsuffix='_left', rsuffix='_right')\n",
    "\n",
    "# area_sqft_df['school_match'] = area_sqft_df['school_match']\n",
    "# area_sqft_df.dtypes\n",
    "\n",
    "high_school_df.dtypes\n",
    "# area_sqft_df.dtypes\n",
    "\n",
    "\n",
    "# new_df = area_sqft_df.join(high_school_df, on='school_match', how='left', lsuffix='_left', rsuffix='_right')\n",
    "# new_df\n",
    "\n",
    "\n",
    "# # Merge the dataframes\n",
    "# out_df = pd.merge(high_school_df, area_sqft_df, on='school_match', how='left')\n",
    "# out_df\n",
    "\n",
    "\n",
    "\n",
    "# area_sqft_df['school_match'] = area_sqft_df['field'].apply(lambda x: difflib.get_close_matches(x, enroll_df['school_match']))\n",
    "# area_sqft_df\n",
    "# high_school_df.to_csv('data\\high_school_df.csv')\n",
    "\n",
    "# enroll_df['school_match'] = enroll_df['school_name'].apply(lambda x: difflib.get_close_matches(x, high_school_df['School']))\n",
    "# enroll_df\n",
    "# #create duplicate column to retain team name from df2\n",
    "# high_school_df['team'] = high_school_df['School']\n",
    "\n",
    "# #convert team name in df2 to team name it most closely matches in df1\n",
    "# high_school_df['school_name'] = high_school_df['team'].apply(lambda x: difflib.get_close_matches(x, enroll_df['school_name']))\n",
    "\n",
    "# #merge the DataFrames into one\n",
    "# out_df = pd.merge(high_school_df, enroll_df, on='school_name', how='left')\n",
    "\n",
    "# #view final DataFrame\n",
    "# print(out_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3071ee50c89c1c794c04ecbcb4eb8f9585468a45756c3a74d8e9479e4a2bc436"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
