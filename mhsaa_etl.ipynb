{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ETL NOTEBOOK FOR 2023 MHSAA TOURNEY SPECIFIC MAP\n",
    "\n",
    "#### Adapted from ETL for JSON\n",
    "\n",
    "## Dependencies and Setup\n",
    "### Dependencies\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "## Start timer\n",
    "start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD BLOCK###\n",
    "#### Load data from kml file exported from Google Earth\n",
    "\n",
    "file_path = ('data/kml/MHSAA_2023.kml') # file path to kml file\n",
    "\n",
    "\n",
    "# Read the KML file\n",
    "with open(file_path) as file:\n",
    "    xml_data = file.read()\n",
    "\n",
    "# Initialize soup variables for parsing file\n",
    "soup = BeautifulSoup(xml_data, 'xml')\n",
    "folders = soup.Document.Folder\n",
    "list = soup.Document.Folder.find_all('Folder')\n",
    "\n",
    "# Create a list to store rows to append to the DataFrame\n",
    "rows = []\n",
    "\n",
    "# Loop through the folders and extract the data\n",
    "for folder in list:\n",
    "    try:\n",
    "        field_name = folder.find('name').text\n",
    "        foul = folder.find_all('coordinates')[0].text\n",
    "        fop = folder.find_all('coordinates')[1].text\n",
    "        notes = None\n",
    "\n",
    "        # Check if there is a description tag, if so, use it for notes\n",
    "        if folder.find('description') is not None:\n",
    "            notes = folder.find('description').text\n",
    "\n",
    "        row = {\n",
    "            'field': field_name,\n",
    "            'foul': foul,\n",
    "            'fop': fop,\n",
    "            'notes': notes\n",
    "        }\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Add name of folder to a list of failed folders\n",
    "        failed.append(folder.find('name').text)\n",
    "        print(f\"Error processing folder: {folder.find('name').text}. Error message: {str(e)}\")\n",
    "\n",
    "# Convert the list of rows to a DataFrame\n",
    "df = pd.DataFrame(rows, columns=['field', 'foul', 'fop', 'notes'])\n",
    "\n",
    "# print('Failed to parse:', failed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>foul</th>\n",
       "      <th>fop</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adams Butzel Complex</td>\n",
       "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t-83.1678186,42.3966942,0 -83...</td>\n",
       "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t-83.1678186,42.3966942,0 -83...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adrian College</td>\n",
       "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t-84.0697145,41.901861,0 -84....</td>\n",
       "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t-84.0697145,41.901861,0 -84....</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adrian HS</td>\n",
       "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t-84.0416584,41.9091676,0 -84...</td>\n",
       "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t-84.0416584,41.9091676,0 -84...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alcona HS</td>\n",
       "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t-83.4068606,44.6597432,0 -83...</td>\n",
       "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t-83.4068606,44.6597432,0 -83...</td>\n",
       "      <td>tough treeline in center and left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Algonac High School</td>\n",
       "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t-82.58239759999999,42.628620...</td>\n",
       "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t-82.58239759999999,42.628620...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  field                                               foul  \\\n",
       "0  Adams Butzel Complex  \\n\\t\\t\\t\\t\\t\\t\\t\\t-83.1678186,42.3966942,0 -83...   \n",
       "1        Adrian College  \\n\\t\\t\\t\\t\\t\\t\\t\\t-84.0697145,41.901861,0 -84....   \n",
       "2             Adrian HS  \\n\\t\\t\\t\\t\\t\\t\\t\\t-84.0416584,41.9091676,0 -84...   \n",
       "3             Alcona HS  \\n\\t\\t\\t\\t\\t\\t\\t\\t-83.4068606,44.6597432,0 -83...   \n",
       "4   Algonac High School  \\n\\t\\t\\t\\t\\t\\t\\t\\t-82.58239759999999,42.628620...   \n",
       "\n",
       "                                                 fop  \\\n",
       "0  \\n\\t\\t\\t\\t\\t\\t\\t\\t-83.1678186,42.3966942,0 -83...   \n",
       "1  \\n\\t\\t\\t\\t\\t\\t\\t\\t-84.0697145,41.901861,0 -84....   \n",
       "2  \\n\\t\\t\\t\\t\\t\\t\\t\\t-84.0416584,41.9091676,0 -84...   \n",
       "3  \\n\\t\\t\\t\\t\\t\\t\\t\\t-83.4068606,44.6597432,0 -83...   \n",
       "4  \\n\\t\\t\\t\\t\\t\\t\\t\\t-82.58239759999999,42.628620...   \n",
       "\n",
       "                               notes  \n",
       "0                               None  \n",
       "1                               None  \n",
       "2                               None  \n",
       "3  tough treeline in center and left  \n",
       "4                               None  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the new dataframe\n",
    "\n",
    "\n",
    "# Create a copy of the original DataFrame\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "# Remove new line and space characters from coordinates\n",
    "df_cleaned = df_cleaned.replace(r'\\n','', regex=True) \n",
    "df_cleaned = df_cleaned.replace(r'\\t','', regex=True) \n",
    "\n",
    "# Drop any duplicate rows\n",
    "df_cleaned = df_cleaned.drop_duplicates(subset=['field'], keep='first')\n",
    "\n",
    "# Drop any rows with empty fields\n",
    "df_cleaned = df_cleaned[(df_cleaned != 0).all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 140 entries, 0 to 143\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   field   140 non-null    object\n",
      " 1   foul    140 non-null    object\n",
      " 2   fop     140 non-null    object\n",
      " 3   notes   7 non-null      object\n",
      "dtypes: object(4)\n",
      "memory usage: 5.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>foul</th>\n",
       "      <th>fop</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adams Butzel Complex</td>\n",
       "      <td>-83.1678186,42.3966942,0 -83.1678776,42.397648...</td>\n",
       "      <td>-83.1678186,42.3966942,0 -83.1665385,42.396724...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adrian College</td>\n",
       "      <td>-84.0697145,41.901861,0 -84.0703958,41.9026485...</td>\n",
       "      <td>-84.0697145,41.901861,0 -84.0687248,41.9023461...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adrian HS</td>\n",
       "      <td>-84.0416584,41.9091676,0 -84.04166909999999,41...</td>\n",
       "      <td>-84.0416584,41.9091676,0 -84.0405493,41.909184...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alcona HS</td>\n",
       "      <td>-83.4068606,44.6597432,0 -83.40803409999999,44...</td>\n",
       "      <td>-83.4068606,44.6597432,0 -83.40680159999999,44...</td>\n",
       "      <td>tough treeline in center and left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Algonac High School</td>\n",
       "      <td>-82.58239759999999,42.6286202,0 -82.5813153999...</td>\n",
       "      <td>-82.58239759999999,42.6286202,0 -82.5826256,42...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  field                                               foul  \\\n",
       "0  Adams Butzel Complex  -83.1678186,42.3966942,0 -83.1678776,42.397648...   \n",
       "1        Adrian College  -84.0697145,41.901861,0 -84.0703958,41.9026485...   \n",
       "2             Adrian HS  -84.0416584,41.9091676,0 -84.04166909999999,41...   \n",
       "3             Alcona HS  -83.4068606,44.6597432,0 -83.40803409999999,44...   \n",
       "4   Algonac High School  -82.58239759999999,42.6286202,0 -82.5813153999...   \n",
       "\n",
       "                                                 fop  \\\n",
       "0  -83.1678186,42.3966942,0 -83.1665385,42.396724...   \n",
       "1  -84.0697145,41.901861,0 -84.0687248,41.9023461...   \n",
       "2  -84.0416584,41.9091676,0 -84.0405493,41.909184...   \n",
       "3  -83.4068606,44.6597432,0 -83.40680159999999,44...   \n",
       "4  -82.58239759999999,42.6286202,0 -82.5826256,42...   \n",
       "\n",
       "                               notes  \n",
       "0                               None  \n",
       "1                               None  \n",
       "2                               None  \n",
       "3  tough treeline in center and left  \n",
       "4                               None  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.info()\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Clean up polygon data and create a new home_plate column\n",
    "\n",
    "def parse_coordinates(coord_string):\n",
    "    coords = coord_string.split()\n",
    "    parsed_coords = [tuple(map(float, coord.split(',')[:2])) for coord in coords]\n",
    "    return parsed_coords\n",
    "\n",
    "# Create a new column for the home_plate location using the first set of coordinates in the 'fop' column\n",
    "df_cleaned['home_plate'] = df_cleaned['fop'].apply(lambda x: parse_coordinates(x)[0])\n",
    "\n",
    "# Apply the parse_coordinates function to the 'foul' and 'fop' columns\n",
    "df_cleaned['foul'] = df_cleaned['foul'].apply(parse_coordinates)\n",
    "df_cleaned['fop'] = df_cleaned['fop'].apply(parse_coordinates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## AREA CALCULATION ##############\n",
    "\n",
    "\n",
    "import pyproj\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import transform\n",
    "\n",
    "\n",
    "def calculate_area(coords):\n",
    "    # Create a Polygon object from the coordinates\n",
    "    polygon = Polygon(coords)\n",
    "\n",
    "    # Calculate the centroid of the polygon\n",
    "    centroid = polygon.centroid\n",
    "\n",
    "    # Create a custom LAEA projection centered on the centroid\n",
    "    custom_projection = f\"+proj=laea +lat_0={centroid.y} +lon_0={centroid.x} +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs\"\n",
    "\n",
    "    # Create a transformer for converting coordinates to the custom LAEA projection\n",
    "    transformer = pyproj.Transformer.from_crs(\n",
    "        pyproj.CRS(\"EPSG:4326\"),  # WGS 84 (latitude and longitude)\n",
    "        pyproj.CRS(custom_projection),  # Custom LAEA projection\n",
    "        always_xy=True\n",
    "    )\n",
    "\n",
    "    # Define a function to transform coordinates using the transformer\n",
    "    def transform_coordinates(x, y):\n",
    "        return transformer.transform(x, y)\n",
    "\n",
    "    # Convert the coordinates to the custom LAEA projection\n",
    "    polygon_laea = transform(transform_coordinates, polygon)\n",
    "\n",
    "    # Calculate the area in square meters\n",
    "    area_sqm = polygon_laea.area\n",
    "\n",
    "    # Convert the area to square feet (1 square meter = 10.764 square feet)\n",
    "    area_sqft = area_sqm * 10.764\n",
    "\n",
    "    return area_sqft\n",
    "\n",
    "\n",
    "\n",
    "### Call Function and add to dataframe\n",
    "df_cleaned['foul_area_sqft'] = df_cleaned['foul'].apply(calculate_area)\n",
    "df_cleaned['fop_area_sqft'] = df_cleaned['fop'].apply(calculate_area)\n",
    "\n",
    "## Calculate the total area of the field and the ratio of foul area to field area\n",
    "df_cleaned['field_area_sqft'] = df_cleaned['foul_area_sqft'] + df_cleaned['fop_area_sqft']\n",
    "## Percentage foul area\n",
    "df_cleaned['foul_area_per'] = df_cleaned['foul_area_sqft'] / df_cleaned['field_area_sqft']\n",
    "## Fair to Foul Ratio\n",
    "df_cleaned['fair_to_foul'] = df_cleaned['fop_area_sqft'] / df_cleaned['foul_area_sqft']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# FENCE DISTANCE CALCULATION #############\n",
    "\n",
    "from geopy.distance import great_circle\n",
    "import numpy as np\n",
    "\n",
    "def interpolate_points(start, end, length_ratio):\n",
    "    start_np = np.array(start)\n",
    "    end_np = np.array(end)\n",
    "    return tuple(start_np + (end_np - start_np) * length_ratio)\n",
    "\n",
    "def calculate_distances(home_plate, outfield_coords, num_points=540):\n",
    "    def is_same_point(point1, point2, tolerance=1e-6):\n",
    "        return abs(point1[0] - point2[0]) < tolerance and abs(point1[1] - point2[1]) < tolerance\n",
    "\n",
    "    home_plate_lat_lon = (home_plate[1], home_plate[0])\n",
    "    distances = []\n",
    "\n",
    "    # Calculate total line length\n",
    "    total_length = 0\n",
    "    segments = []\n",
    "    for i in range(len(outfield_coords) - 1):\n",
    "        start = outfield_coords[i]\n",
    "        end = outfield_coords[i + 1]\n",
    "        if not is_same_point(home_plate, start) and not is_same_point(home_plate, end):\n",
    "            segment_length = great_circle((start[1], start[0]), (end[1], end[0])).feet\n",
    "            segments.append((start, end, segment_length))\n",
    "            total_length += segment_length\n",
    "\n",
    "    # Calculate the distance between equally spaced points\n",
    "    spacing = total_length / (num_points - 1)\n",
    "\n",
    "    # Interpolate points and calculate distances\n",
    "    current_length = 0\n",
    "    segment_index = 0\n",
    "    for i in range(num_points):\n",
    "        while segment_index < len(segments) - 1 and current_length > segments[segment_index][2]:\n",
    "            current_length -= segments[segment_index][2]\n",
    "            segment_index += 1\n",
    "\n",
    "        start, end, segment_length = segments[segment_index]\n",
    "        length_ratio = current_length / segment_length\n",
    "        point = interpolate_points(start, end, length_ratio)\n",
    "        distance = round(great_circle(home_plate_lat_lon, (point[1], point[0])).feet)\n",
    "        distances.append(distance)\n",
    "\n",
    "        current_length += spacing\n",
    "\n",
    "    return distances\n",
    "\n",
    "# Calculate distances for each row\n",
    "df_cleaned['distances'] = df_cleaned.apply(lambda row: calculate_distances(row['home_plate'], row['fop']), axis=1)\n",
    "\n",
    "# Calculate max, min, and average distances for each row\n",
    "df_cleaned['max_distance'] = df_cleaned['distances'].apply(max)\n",
    "df_cleaned['min_distance'] = df_cleaned['distances'].apply(min)\n",
    "df_cleaned['avg_distance'] = df_cleaned['distances'].apply(lambda distances: sum(distances) / len(distances))\n",
    "# get the median distance\n",
    "df_cleaned['median_distance'] = df_cleaned['distances'].apply(lambda distances: np.median(distances))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540    140\n",
       "Name: num_distances, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######## CHECK BLOCK ########\n",
    "\n",
    "## Check how long the distance list is for each row\n",
    "df_cleaned['num_distances'] = df_cleaned['distances'].apply(len)\n",
    "\n",
    "## Print the value counts for the 'num_distances' column\n",
    "df_cleaned['num_distances'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### NOT NECESSARY FOR THIS PROJECT ##########\n",
    "\n",
    "# ### Get Geolocation of each field based on home plate coordinates and return state and country\n",
    "# ### This block takes a long time to run - will need to revisit\n",
    "# ## up to ten minutes\n",
    "\n",
    "# from geopy.geocoders import Nominatim\n",
    "# from geopy.exc import GeocoderTimedOut, GeocoderServiceError\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# geolocator = Nominatim(user_agent=\"baseball_field_locator\")\n",
    "\n",
    "# import time\n",
    "\n",
    "# def get_location_info(lng, lat):\n",
    "#     try:\n",
    "#         time.sleep(1)  # Delay for 1 second\n",
    "#         location = geolocator.reverse((lat, lng), timeout=10)\n",
    "#         city = location.raw['address'].get('city', None)\n",
    "#         state = location.raw['address'].get('state', None)\n",
    "#         return city, state\n",
    "#     except GeocoderTimedOut:\n",
    "#         print(f\"GeocoderTimedOut error for coordinates: ({lng}, {lat})\")\n",
    "#         return None, None\n",
    "#     except GeocoderServiceError:\n",
    "#         print(f\"GeocoderServiceError for coordinates: ({lng}, {lat})\")\n",
    "#         return None, None\n",
    "\n",
    "\n",
    "# # Extract the first coordinate for each field\n",
    "# df_cleaned['lng'], df_cleaned['lat'] = zip(*df_cleaned['home_plate'].apply(lambda x: x))\n",
    "\n",
    "# # Wrap the DataFrame apply function with tqdm for progress indication\n",
    "# tqdm.pandas(desc=\"Processing coordinates\")\n",
    "\n",
    "# # Get state and country information for each field\n",
    "# df_cleaned[['city', 'state']] = df_cleaned.progress_apply(lambda row: get_location_info(row['lng'], row['lat']), axis=1, result_type='expand')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to create ranks for each column\n",
    "\n",
    "def rank_fields(df):\n",
    "    # Calculate the rank for each category\n",
    "    df['max_distance_rank'] = df['max_distance'].rank(ascending=False, method='min')\n",
    "    df['min_distance_rank'] = df['min_distance'].rank(ascending=False, method='min')\n",
    "    df['avg_distance_rank'] = df['avg_distance'].rank(ascending=False, method='min')\n",
    "    df['median_distance_rank'] = df['median_distance'].rank(ascending=False, method='min')\n",
    "    df['field_area_rank'] = df['field_area_sqft'].rank(ascending=False, method='min')\n",
    "    df['foul_area_rank'] = df['foul_area_sqft'].rank(ascending=False, method='min')\n",
    "    df['fop_area_per_rank'] = df['fop_area_sqft'].rank(ascending=False, method='min')\n",
    "    df['ratio_rank'] = df['fair_to_foul'].rank(ascending=False, method='min')\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run Function\n",
    "\n",
    "df_cleaned = rank_fields(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Orienting the map to the home plate location ####\n",
    "\n",
    "### Find the center of the field\n",
    "def calculate_centroid(coords):\n",
    "    x_coords = [coord[0] for coord in coords]\n",
    "    y_coords = [coord[1] for coord in coords]\n",
    "    centroid_x = sum(x_coords) / len(coords)\n",
    "    centroid_y = sum(y_coords) / len(coords)\n",
    "    return (centroid_x, centroid_y)\n",
    "\n",
    "\n",
    "## Find the bearing between the home plate and the center of the field\n",
    "import math\n",
    "\n",
    "def calculate_bearing(point1, point2):\n",
    "    lat1, lon1 = math.radians(point1[1]), math.radians(point1[0])\n",
    "    lat2, lon2 = math.radians(point2[1]), math.radians(point2[0])\n",
    "\n",
    "    d_lon = lon2 - lon1\n",
    "\n",
    "    x = math.cos(lat2) * math.sin(d_lon)\n",
    "    y = math.cos(lat1) * math.sin(lat2) - math.sin(lat1) * math.cos(lat2) * math.cos(d_lon)\n",
    "\n",
    "    bearing = math.degrees(math.atan2(x, y))\n",
    "    bearing = (bearing + 360) % 360  # Normalize the bearing to the range [0, 360)\n",
    "\n",
    "    return bearing\n",
    "\n",
    "### Function to classify direction in laymans terms North, South, East, West, ect\n",
    "def degrees_to_cardinal_direction(degrees):\n",
    "    directions = ['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW', 'N']\n",
    "    index = round(degrees / 45)\n",
    "    return directions[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the centroid of the outfield fence coordinates for each row\n",
    "df_cleaned['fop_centroid'] = df_cleaned['fop'].apply(lambda coords: calculate_centroid(coords[1:]))\n",
    "\n",
    "# Calculate the bearing between home plate and the centroid for each row\n",
    "df_cleaned['field_orientation'] = df_cleaned.apply(lambda row: calculate_bearing(row['home_plate'], row['fop_centroid']), axis=1)\n",
    "\n",
    "# Convert the bearing to a cardinal direction\n",
    "df_cleaned['field_cardinal_direction'] = df_cleaned['field_orientation'].apply(degrees_to_cardinal_direction)\n",
    "\n",
    "# rename 'field' to 'park_name'\n",
    "df_cleaned.rename(columns={'field': 'park_name'}, inplace=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All the geo transformation should take place above this\n",
    "\n",
    "## starting the process of matching in data from other sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## output to csv \n",
    "# df_cleaned.to_csv('data/fields_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cleaned.info()\n",
    "\n",
    "# # Load the host team info with nickname and team colors\n",
    "path = 'data/MHSAA/2023_MHSAA_sites.csv'\n",
    "df_hosts = pd.read_csv(path)\n",
    "\n",
    "df_parks = df_cleaned\n",
    "\n",
    "df_hosts.head()\n",
    "\n",
    "park_df = df_parks\n",
    "host_df = df_hosts\n",
    "# df_hosts.info()\n",
    "\n",
    "# # Merge the host team info with the field info\n",
    "# df_cleaned = df_cleaned.merge(df_hosts, on='host_team', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>park_name</th>\n",
       "      <th>foul</th>\n",
       "      <th>fop</th>\n",
       "      <th>notes</th>\n",
       "      <th>home_plate</th>\n",
       "      <th>foul_area_sqft</th>\n",
       "      <th>fop_area_sqft</th>\n",
       "      <th>field_area_sqft</th>\n",
       "      <th>foul_area_per</th>\n",
       "      <th>fair_to_foul</th>\n",
       "      <th>...</th>\n",
       "      <th>min_distance_rank</th>\n",
       "      <th>avg_distance_rank</th>\n",
       "      <th>median_distance_rank</th>\n",
       "      <th>field_area_rank</th>\n",
       "      <th>foul_area_rank</th>\n",
       "      <th>fop_area_per_rank</th>\n",
       "      <th>ratio_rank</th>\n",
       "      <th>fop_centroid</th>\n",
       "      <th>field_orientation</th>\n",
       "      <th>field_cardinal_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Lowell High School - high school</td>\n",
       "      <td>[(-85.3763871, 42.9571353), (-85.3768716, 42.9...</td>\n",
       "      <td>[(-85.3763871, 42.9571353), (-85.3752914, 42.9...</td>\n",
       "      <td>guestimate on the fenceline based on the mow p...</td>\n",
       "      <td>(-85.3763871, 42.9571353)</td>\n",
       "      <td>29097.855748</td>\n",
       "      <td>99166.362021</td>\n",
       "      <td>128264.217769</td>\n",
       "      <td>0.226859</td>\n",
       "      <td>3.40803</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>(-85.3761548818182, 42.95801321363636)</td>\n",
       "      <td>10.956002</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           park_name  \\\n",
       "81  Lowell High School - high school   \n",
       "\n",
       "                                                 foul  \\\n",
       "81  [(-85.3763871, 42.9571353), (-85.3768716, 42.9...   \n",
       "\n",
       "                                                  fop  \\\n",
       "81  [(-85.3763871, 42.9571353), (-85.3752914, 42.9...   \n",
       "\n",
       "                                                notes  \\\n",
       "81  guestimate on the fenceline based on the mow p...   \n",
       "\n",
       "                   home_plate  foul_area_sqft  fop_area_sqft  field_area_sqft  \\\n",
       "81  (-85.3763871, 42.9571353)    29097.855748   99166.362021    128264.217769   \n",
       "\n",
       "    foul_area_per  fair_to_foul  ... min_distance_rank  avg_distance_rank  \\\n",
       "81       0.226859       3.40803  ...              29.0               20.0   \n",
       "\n",
       "    median_distance_rank  field_area_rank  foul_area_rank  fop_area_per_rank  \\\n",
       "81                  19.0             24.0            56.0               19.0   \n",
       "\n",
       "    ratio_rank                            fop_centroid  field_orientation  \\\n",
       "81        72.0  (-85.3761548818182, 42.95801321363636)          10.956002   \n",
       "\n",
       "    field_cardinal_direction  \n",
       "81                         N  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# host_df.info()\n",
    "\n",
    "## find the Lowell High School field\n",
    "host_df[host_df['park_name'] == 'Lowell High School - high school']\n",
    "\n",
    "\n",
    "\n",
    "# park_df.info()\n",
    "\n",
    "## find the Lowell High School field\n",
    "park_df[park_df['park_name'] == 'Lowell High School - high school']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simple Merge, should work because the park_name columns should match exactly\n",
    "## Do not detroy any data\n",
    "df_merged = park_df.merge(host_df, on='park_name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 140 entries, 0 to 139\n",
      "Data columns (total 38 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   park_name                 140 non-null    object \n",
      " 1   foul                      140 non-null    object \n",
      " 2   fop                       140 non-null    object \n",
      " 3   notes                     7 non-null      object \n",
      " 4   home_plate                140 non-null    object \n",
      " 5   foul_area_sqft            140 non-null    float64\n",
      " 6   fop_area_sqft             140 non-null    float64\n",
      " 7   field_area_sqft           140 non-null    float64\n",
      " 8   foul_area_per             140 non-null    float64\n",
      " 9   fair_to_foul              140 non-null    float64\n",
      " 10  distances                 140 non-null    object \n",
      " 11  max_distance              140 non-null    int64  \n",
      " 12  min_distance              140 non-null    int64  \n",
      " 13  avg_distance              140 non-null    float64\n",
      " 14  median_distance           140 non-null    float64\n",
      " 15  num_distances             140 non-null    int64  \n",
      " 16  max_distance_rank         140 non-null    float64\n",
      " 17  min_distance_rank         140 non-null    float64\n",
      " 18  avg_distance_rank         140 non-null    float64\n",
      " 19  median_distance_rank      140 non-null    float64\n",
      " 20  field_area_rank           140 non-null    float64\n",
      " 21  foul_area_rank            140 non-null    float64\n",
      " 22  fop_area_per_rank         140 non-null    float64\n",
      " 23  ratio_rank                140 non-null    float64\n",
      " 24  fop_centroid              140 non-null    object \n",
      " 25  field_orientation         140 non-null    float64\n",
      " 26  field_cardinal_direction  140 non-null    object \n",
      " 27  host_team                 138 non-null    object \n",
      " 28  division                  136 non-null    float64\n",
      " 29  district                  123 non-null    float64\n",
      " 30  region_semi_number        63 non-null     float64\n",
      " 31  regional_div              76 non-null     float64\n",
      " 32  region_final_quarter      15 non-null     float64\n",
      " 33  finals                    1 non-null      float64\n",
      " 34  nickname                  137 non-null    object \n",
      " 35  color1                    137 non-null    object \n",
      " 36  color2                    137 non-null    object \n",
      " 37  color3                    11 non-null     object \n",
      "dtypes: float64(22), int64(3), object(13)\n",
      "memory usage: 42.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 140 entries, 0 to 139\n",
      "Data columns (total 38 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   park_name                 140 non-null    object \n",
      " 1   foul                      140 non-null    object \n",
      " 2   fop                       140 non-null    object \n",
      " 3   notes                     7 non-null      object \n",
      " 4   home_plate                140 non-null    object \n",
      " 5   foul_area_sqft            140 non-null    float64\n",
      " 6   fop_area_sqft             140 non-null    float64\n",
      " 7   field_area_sqft           140 non-null    float64\n",
      " 8   foul_area_per             140 non-null    float64\n",
      " 9   fair_to_foul              140 non-null    float64\n",
      " 10  distances                 140 non-null    object \n",
      " 11  max_distance              140 non-null    int64  \n",
      " 12  min_distance              140 non-null    int64  \n",
      " 13  avg_distance              140 non-null    float64\n",
      " 14  median_distance           140 non-null    float64\n",
      " 15  num_distances             140 non-null    int64  \n",
      " 16  max_distance_rank         140 non-null    float64\n",
      " 17  min_distance_rank         140 non-null    float64\n",
      " 18  avg_distance_rank         140 non-null    float64\n",
      " 19  median_distance_rank      140 non-null    float64\n",
      " 20  field_area_rank           140 non-null    float64\n",
      " 21  foul_area_rank            140 non-null    float64\n",
      " 22  fop_area_per_rank         140 non-null    float64\n",
      " 23  ratio_rank                140 non-null    float64\n",
      " 24  fop_centroid              140 non-null    object \n",
      " 25  field_orientation         140 non-null    float64\n",
      " 26  field_cardinal_direction  140 non-null    object \n",
      " 27  host_team                 138 non-null    object \n",
      " 28  division                  136 non-null    float64\n",
      " 29  district                  123 non-null    float64\n",
      " 30  region_semi_number        63 non-null     float64\n",
      " 31  regional_div              76 non-null     float64\n",
      " 32  region_final_quarter      15 non-null     float64\n",
      " 33  finals                    1 non-null      float64\n",
      " 34  nickname                  137 non-null    object \n",
      " 35  color1                    137 non-null    object \n",
      " 36  color2                    137 non-null    object \n",
      " 37  color3                    11 non-null     object \n",
      "dtypes: float64(22), int64(3), object(13)\n",
      "memory usage: 42.7+ KB\n"
     ]
    }
   ],
   "source": [
    "## Drop the rows with null values in the 'fop', 'foul' or 'home_plate' columns\n",
    "df_merged.dropna(subset=['fop', 'foul', 'home_plate'], inplace=True)\n",
    "\n",
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Division</th>\n",
       "      <th>District</th>\n",
       "      <th>Host</th>\n",
       "      <th>Location</th>\n",
       "      <th>Teams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>North Marquette Fields</td>\n",
       "      <td>['Alpena', 'Mount Pleasant', 'Traverse City Ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Midland Dow</td>\n",
       "      <td>H H Dow High School - Baseball - Midland</td>\n",
       "      <td>['Bay City Central', 'Bay City Western', 'Midl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Muskegon Mona Shores</td>\n",
       "      <td>Mona Shores Baseball Field (Baseball Field) - ...</td>\n",
       "      <td>['Grand Haven', 'Grand Rapids Kenowa Hills', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Grand Rapids Forest Hills Northern</td>\n",
       "      <td>FHN Stadium - Baseball - Grand Rapids</td>\n",
       "      <td>['Cedar Springs', 'Grand Rapids Northview', 'G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Grandville</td>\n",
       "      <td>Grandville High School - Baseball</td>\n",
       "      <td>['Byron Center', 'Grand Rapids Union', 'Jeniso...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Division  District                                Host  \\\n",
       "0         1         1                           Marquette   \n",
       "1         1         2                         Midland Dow   \n",
       "2         1         3                Muskegon Mona Shores   \n",
       "3         1         4  Grand Rapids Forest Hills Northern   \n",
       "4         1         5                          Grandville   \n",
       "\n",
       "                                            Location  \\\n",
       "0                             North Marquette Fields   \n",
       "1          H H Dow High School - Baseball - Midland    \n",
       "2  Mona Shores Baseball Field (Baseball Field) - ...   \n",
       "3              FHN Stadium - Baseball - Grand Rapids   \n",
       "4                  Grandville High School - Baseball   \n",
       "\n",
       "                                               Teams  \n",
       "0  ['Alpena', 'Mount Pleasant', 'Traverse City Ce...  \n",
       "1  ['Bay City Central', 'Bay City Western', 'Midl...  \n",
       "2  ['Grand Haven', 'Grand Rapids Kenowa Hills', '...  \n",
       "3  ['Cedar Springs', 'Grand Rapids Northview', 'G...  \n",
       "4  ['Byron Center', 'Grand Rapids Union', 'Jeniso...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Merge the display names into the dataframe\n",
    "\n",
    "## Load the display names from csv\n",
    "path = 'data/MHSAA/2023_district_teams.csv'\n",
    "places_df = pd.read_csv(path)\n",
    "\n",
    "places_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Merge the display names into the dataframe\n",
    "# ## merged_df column District, places_df column district\n",
    "# df_merged = df_merged.merge(places_df, on='district', how='left')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 140 entries, 0 to 139\n",
      "Data columns (total 38 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   park_name                 140 non-null    object \n",
      " 1   foul                      140 non-null    object \n",
      " 2   fop                       140 non-null    object \n",
      " 3   notes                     7 non-null      object \n",
      " 4   home_plate                140 non-null    object \n",
      " 5   foul_area_sqft            140 non-null    float64\n",
      " 6   fop_area_sqft             140 non-null    float64\n",
      " 7   field_area_sqft           140 non-null    float64\n",
      " 8   foul_area_per             140 non-null    float64\n",
      " 9   fair_to_foul              140 non-null    float64\n",
      " 10  distances                 140 non-null    object \n",
      " 11  max_distance              140 non-null    int64  \n",
      " 12  min_distance              140 non-null    int64  \n",
      " 13  avg_distance              140 non-null    float64\n",
      " 14  median_distance           140 non-null    float64\n",
      " 15  num_distances             140 non-null    int64  \n",
      " 16  max_distance_rank         140 non-null    float64\n",
      " 17  min_distance_rank         140 non-null    float64\n",
      " 18  avg_distance_rank         140 non-null    float64\n",
      " 19  median_distance_rank      140 non-null    float64\n",
      " 20  field_area_rank           140 non-null    float64\n",
      " 21  foul_area_rank            140 non-null    float64\n",
      " 22  fop_area_per_rank         140 non-null    float64\n",
      " 23  ratio_rank                140 non-null    float64\n",
      " 24  fop_centroid              140 non-null    object \n",
      " 25  field_orientation         140 non-null    float64\n",
      " 26  field_cardinal_direction  140 non-null    object \n",
      " 27  host_team                 138 non-null    object \n",
      " 28  division                  136 non-null    float64\n",
      " 29  district                  123 non-null    float64\n",
      " 30  region_semi_number        63 non-null     float64\n",
      " 31  regional_div              76 non-null     float64\n",
      " 32  region_final_quarter      15 non-null     float64\n",
      " 33  finals                    1 non-null      float64\n",
      " 34  nickname                  137 non-null    object \n",
      " 35  color1                    137 non-null    object \n",
      " 36  color2                    137 non-null    object \n",
      " 37  color3                    11 non-null     object \n",
      "dtypes: float64(22), int64(3), object(13)\n",
      "memory usage: 42.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_merged.info()\n",
    "df = df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              park_name      score\n",
      "61                              Hart HS   9.912756\n",
      "20        Central Lake HS - high_school   9.753206\n",
      "74                          Kingston HS   9.386839\n",
      "85                            Martin HS   8.412362\n",
      "35             East Jackson High School   7.839091\n",
      "..                                  ...        ...\n",
      "118      Sagniaw Valley State - college  -9.514021\n",
      "1                        Adrian College  -9.516080\n",
      "88   Michigan State - Old College Field -10.451569\n",
      "72          Kalamazoo College - college -10.731596\n",
      "30                    Detroit Osborn HS -16.961198\n",
      "\n",
      "[140 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "### THIS BLOCK CREATES THE RANKING OF PITCHER VS HITTER FRIENDLY FIELDS\n",
    "def rank_fields(data):\n",
    "    # Define weights for each parameter\n",
    "    weights = {\n",
    "        'max_distance': -1, # negative weight since longer fences favor pitchers\n",
    "        'min_distance': 1,  # positive weight since shorter fences favor hitters\n",
    "        'avg_distance': -1, # negative weight since longer fences favor pitchers\n",
    "        'median_distance': -1, # negative weight since longer fences favor pitchers\n",
    "        'field_area_sqft': -1,  # negative weight since larger fields favor pitchers\n",
    "        'fair_to_foul': -1,  # negative weight since larger ratio (more foul territory) favors pitchers\n",
    "        'foul_area_sqft': -1, # negative weight since larger foul area favors pitchers\n",
    "        'fop_area_sqft': -1, # negative weight since larger out of play area favors pitchers\n",
    "    }\n",
    "\n",
    "    # Standardize features (subtract mean and divide by standard deviation)\n",
    "    standardized_data = data.copy()\n",
    "    for column in weights.keys():\n",
    "        standardized_data[column] = (standardized_data[column] - standardized_data[column].mean()) / standardized_data[column].std()\n",
    "\n",
    "    # Calculate score for each field\n",
    "    standardized_data['score'] = standardized_data.apply(lambda row: sum(row[param] * weight for param, weight in weights.items()), axis=1)\n",
    "\n",
    "    # Save scores to original dataframe\n",
    "    data['score'] = standardized_data['score']\n",
    "\n",
    "    # Rank fields based on score (higher scores are more hitter-friendly)\n",
    "    ranked_fields = data.sort_values('score', ascending=False)\n",
    "\n",
    "    return ranked_fields\n",
    "\n",
    "# Suppose 'df' is your DataFrame containing the field data\n",
    "ranked_fields = rank_fields(df)\n",
    "print(ranked_fields[['park_name', 'score']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 140 entries, 61 to 30\n",
      "Data columns (total 39 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   park_name                 140 non-null    object \n",
      " 1   foul                      140 non-null    object \n",
      " 2   fop                       140 non-null    object \n",
      " 3   notes                     7 non-null      object \n",
      " 4   home_plate                140 non-null    object \n",
      " 5   foul_area_sqft            140 non-null    float64\n",
      " 6   fop_area_sqft             140 non-null    float64\n",
      " 7   field_area_sqft           140 non-null    float64\n",
      " 8   foul_area_per             140 non-null    float64\n",
      " 9   fair_to_foul              140 non-null    float64\n",
      " 10  distances                 140 non-null    object \n",
      " 11  max_distance              140 non-null    int64  \n",
      " 12  min_distance              140 non-null    int64  \n",
      " 13  avg_distance              140 non-null    float64\n",
      " 14  median_distance           140 non-null    float64\n",
      " 15  num_distances             140 non-null    int64  \n",
      " 16  max_distance_rank         140 non-null    float64\n",
      " 17  min_distance_rank         140 non-null    float64\n",
      " 18  avg_distance_rank         140 non-null    float64\n",
      " 19  median_distance_rank      140 non-null    float64\n",
      " 20  field_area_rank           140 non-null    float64\n",
      " 21  foul_area_rank            140 non-null    float64\n",
      " 22  fop_area_per_rank         140 non-null    float64\n",
      " 23  ratio_rank                140 non-null    float64\n",
      " 24  fop_centroid              140 non-null    object \n",
      " 25  field_orientation         140 non-null    float64\n",
      " 26  field_cardinal_direction  140 non-null    object \n",
      " 27  host_team                 138 non-null    object \n",
      " 28  division                  136 non-null    float64\n",
      " 29  district                  123 non-null    float64\n",
      " 30  region_semi_number        63 non-null     float64\n",
      " 31  regional_div              76 non-null     float64\n",
      " 32  region_final_quarter      15 non-null     float64\n",
      " 33  finals                    1 non-null      float64\n",
      " 34  nickname                  137 non-null    object \n",
      " 35  color1                    137 non-null    object \n",
      " 36  color2                    137 non-null    object \n",
      " 37  color3                    11 non-null     object \n",
      " 38  score                     140 non-null    float64\n",
      "dtypes: float64(23), int64(3), object(13)\n",
      "memory usage: 43.8+ KB\n"
     ]
    }
   ],
   "source": [
    "ranked_fields.info()\n",
    "merged_df = ranked_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import webcolors\n",
    "\n",
    "# Assuming df is your DataFrame and it has columns 'color1' and 'color2'\n",
    "\n",
    "custom_colors = {\n",
    "    'Maize': '#F2C649',\n",
    "    'Columbia Blue': '#C4D8E2',\n",
    "    'Carolina Blue': '#56A0D3',\n",
    "    'Cardinal': '#C41E3A',\n",
    "    'Burgundy': '#800020',\n",
    "    'Forrest Green': '#18453B',\n",
    "    'Forest Green': '#18453B',\n",
    "    'Columbia': '#C4D8E2',\n",
    "    'Royal': '#4169e1',\n",
    "    'Royal Blue': '#4169e1',\n",
    "    'Vegas Gold': '#C5B358',\n",
    "    'Navy Blue': '#000080'\n",
    "}\n",
    "\n",
    "def convert_to_hex(color_name):\n",
    "    if isinstance(color_name, str):  # Check if color_name is a string\n",
    "        try:\n",
    "            return webcolors.name_to_hex(color_name)\n",
    "        except ValueError:\n",
    "            return custom_colors.get(color_name, '#000000')  # default to black if color name not recognized\n",
    "    else:\n",
    "        return '#000000'  # default to black if color_name is not a string\n",
    "\n",
    "# Convert the color columns to string and strip any trailing spaces\n",
    "df['color1'] = df['color1'].astype(str).str.strip()\n",
    "df['color2'] = df['color2'].astype(str).str.strip()\n",
    "\n",
    "# Convert color names to hex values\n",
    "df['color1'] = df['color1'].apply(convert_to_hex)\n",
    "df['color2'] = df['color2'].apply(convert_to_hex)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recreate the division_final and level columns\n",
    "\n",
    "## If division column is not null use that value as division_final. if it is null use the value in the regional_division column\n",
    "df['division_final'] = df['division'].fillna(df['regional_div'])\n",
    "\n",
    "## Create a level column based if the field hosts a district the value should be 1\n",
    "## if region_semi_number is present assign level 2 and if region_final_number is present assign level 3\n",
    "## if finals is present assign level 4\n",
    "df['level'] = np.where(df['district'].notnull(), 1, 0)\n",
    "df['level'] = np.where(df['region_semi_number'].notnull(), 2, df['level'])\n",
    "df['level'] = np.where(df['region_final_quarter'].notnull(), 3, df['level'])\n",
    "df['level'] = np.where(df['finals'].notnull(), 4, df['level'])\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 140 entries, 61 to 30\n",
      "Data columns (total 41 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   park_name                 140 non-null    object \n",
      " 1   foul                      140 non-null    object \n",
      " 2   fop                       140 non-null    object \n",
      " 3   notes                     7 non-null      object \n",
      " 4   home_plate                140 non-null    object \n",
      " 5   foul_area_sqft            140 non-null    float64\n",
      " 6   fop_area_sqft             140 non-null    float64\n",
      " 7   field_area_sqft           140 non-null    float64\n",
      " 8   foul_area_per             140 non-null    float64\n",
      " 9   fair_to_foul              140 non-null    float64\n",
      " 10  distances                 140 non-null    object \n",
      " 11  max_distance              140 non-null    int64  \n",
      " 12  min_distance              140 non-null    int64  \n",
      " 13  avg_distance              140 non-null    float64\n",
      " 14  median_distance           140 non-null    float64\n",
      " 15  num_distances             140 non-null    int64  \n",
      " 16  max_distance_rank         140 non-null    float64\n",
      " 17  min_distance_rank         140 non-null    float64\n",
      " 18  avg_distance_rank         140 non-null    float64\n",
      " 19  median_distance_rank      140 non-null    float64\n",
      " 20  field_area_rank           140 non-null    float64\n",
      " 21  foul_area_rank            140 non-null    float64\n",
      " 22  fop_area_per_rank         140 non-null    float64\n",
      " 23  ratio_rank                140 non-null    float64\n",
      " 24  fop_centroid              140 non-null    object \n",
      " 25  field_orientation         140 non-null    float64\n",
      " 26  field_cardinal_direction  140 non-null    object \n",
      " 27  host_team                 138 non-null    object \n",
      " 28  division                  136 non-null    float64\n",
      " 29  district                  123 non-null    float64\n",
      " 30  region_semi_number        63 non-null     float64\n",
      " 31  regional_div              76 non-null     float64\n",
      " 32  region_final_quarter      15 non-null     float64\n",
      " 33  finals                    1 non-null      float64\n",
      " 34  nickname                  137 non-null    object \n",
      " 35  color1                    140 non-null    object \n",
      " 36  color2                    140 non-null    object \n",
      " 37  color3                    11 non-null     object \n",
      " 38  score                     140 non-null    float64\n",
      " 39  division_final            136 non-null    float64\n",
      " 40  level                     140 non-null    int32  \n",
      "dtypes: float64(24), int32(1), int64(3), object(13)\n",
      "memory usage: 45.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_merged = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Get me a list of every color name used in the color1 and color2 columns\n",
    "# color_list = merged_df['color1'].append(merged_df['color2']).unique()\n",
    "# color_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "### outpus csv to check\n",
    "df_merged.to_csv('data/MHSAA_FINAL_TEST.csv', index=False)\n",
    "\n",
    "### OUTPUT JSON TO USE IN MAP\n",
    "df_merged.to_json('data/html/mhsaa/data/map.json', orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>park_name</th>\n",
       "      <th>foul</th>\n",
       "      <th>fop</th>\n",
       "      <th>notes</th>\n",
       "      <th>home_plate</th>\n",
       "      <th>foul_area_sqft</th>\n",
       "      <th>fop_area_sqft</th>\n",
       "      <th>field_area_sqft</th>\n",
       "      <th>foul_area_per</th>\n",
       "      <th>fair_to_foul</th>\n",
       "      <th>...</th>\n",
       "      <th>regional_div</th>\n",
       "      <th>region_final_quarter</th>\n",
       "      <th>finals</th>\n",
       "      <th>nickname</th>\n",
       "      <th>color1</th>\n",
       "      <th>color2</th>\n",
       "      <th>color3</th>\n",
       "      <th>score</th>\n",
       "      <th>division_final</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Hart HS</td>\n",
       "      <td>[(-86.3725369, 43.694431), (-86.3725369, 43.69...</td>\n",
       "      <td>[(-86.3725369, 43.694431), (-86.371409, 43.694...</td>\n",
       "      <td>None</td>\n",
       "      <td>(-86.3725369, 43.694431)</td>\n",
       "      <td>20362.716493</td>\n",
       "      <td>74084.002514</td>\n",
       "      <td>94446.719007</td>\n",
       "      <td>0.215600</td>\n",
       "      <td>3.638218</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pirates</td>\n",
       "      <td>#ff0000</td>\n",
       "      <td>#ffffff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.912756</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Central Lake HS - high_school</td>\n",
       "      <td>[(-85.2690937, 45.0671277), (-85.2679149, 45.0...</td>\n",
       "      <td>[(-85.2690937, 45.0671277), (-85.269142, 45.06...</td>\n",
       "      <td>None</td>\n",
       "      <td>(-85.2690937, 45.0671277)</td>\n",
       "      <td>17031.960373</td>\n",
       "      <td>75950.501772</td>\n",
       "      <td>92982.462144</td>\n",
       "      <td>0.183174</td>\n",
       "      <td>4.459293</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trojans</td>\n",
       "      <td>#4169e1</td>\n",
       "      <td>#ffa500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.753206</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Kingston HS</td>\n",
       "      <td>[(-83.1919884, 43.4105303), (-83.1919496, 43.4...</td>\n",
       "      <td>[(-83.1919884, 43.4105303), (-83.1930426, 43.4...</td>\n",
       "      <td>None</td>\n",
       "      <td>(-83.1919884, 43.4105303)</td>\n",
       "      <td>20220.684021</td>\n",
       "      <td>74843.976378</td>\n",
       "      <td>95064.660399</td>\n",
       "      <td>0.212705</td>\n",
       "      <td>3.701357</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cardinals</td>\n",
       "      <td>#ff0000</td>\n",
       "      <td>#000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.386839</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Martin HS</td>\n",
       "      <td>[(-85.6333741, 42.5353963), (-85.6334251, 42.5...</td>\n",
       "      <td>[(-85.6333741, 42.5353963), (-85.6322717, 42.5...</td>\n",
       "      <td>None</td>\n",
       "      <td>(-85.6333741, 42.5353963)</td>\n",
       "      <td>25261.683727</td>\n",
       "      <td>78145.743178</td>\n",
       "      <td>103407.426905</td>\n",
       "      <td>0.244293</td>\n",
       "      <td>3.093450</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clippers</td>\n",
       "      <td>#800000</td>\n",
       "      <td>#ffffff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.412362</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>East Jackson High School</td>\n",
       "      <td>[(-84.343207, 42.2573129), (-84.3432365, 42.25...</td>\n",
       "      <td>[(-84.343207, 42.2573129), (-84.3420966, 42.25...</td>\n",
       "      <td>None</td>\n",
       "      <td>(-84.343207, 42.2573129)</td>\n",
       "      <td>33522.202877</td>\n",
       "      <td>77886.875612</td>\n",
       "      <td>111409.078489</td>\n",
       "      <td>0.300893</td>\n",
       "      <td>2.323441</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trojans</td>\n",
       "      <td>#000080</td>\n",
       "      <td>#ffffff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.839091</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        park_name  \\\n",
       "61                        Hart HS   \n",
       "20  Central Lake HS - high_school   \n",
       "74                    Kingston HS   \n",
       "85                      Martin HS   \n",
       "35       East Jackson High School   \n",
       "\n",
       "                                                 foul  \\\n",
       "61  [(-86.3725369, 43.694431), (-86.3725369, 43.69...   \n",
       "20  [(-85.2690937, 45.0671277), (-85.2679149, 45.0...   \n",
       "74  [(-83.1919884, 43.4105303), (-83.1919496, 43.4...   \n",
       "85  [(-85.6333741, 42.5353963), (-85.6334251, 42.5...   \n",
       "35  [(-84.343207, 42.2573129), (-84.3432365, 42.25...   \n",
       "\n",
       "                                                  fop notes  \\\n",
       "61  [(-86.3725369, 43.694431), (-86.371409, 43.694...  None   \n",
       "20  [(-85.2690937, 45.0671277), (-85.269142, 45.06...  None   \n",
       "74  [(-83.1919884, 43.4105303), (-83.1930426, 43.4...  None   \n",
       "85  [(-85.6333741, 42.5353963), (-85.6322717, 42.5...  None   \n",
       "35  [(-84.343207, 42.2573129), (-84.3420966, 42.25...  None   \n",
       "\n",
       "                   home_plate  foul_area_sqft  fop_area_sqft  field_area_sqft  \\\n",
       "61   (-86.3725369, 43.694431)    20362.716493   74084.002514     94446.719007   \n",
       "20  (-85.2690937, 45.0671277)    17031.960373   75950.501772     92982.462144   \n",
       "74  (-83.1919884, 43.4105303)    20220.684021   74843.976378     95064.660399   \n",
       "85  (-85.6333741, 42.5353963)    25261.683727   78145.743178    103407.426905   \n",
       "35   (-84.343207, 42.2573129)    33522.202877   77886.875612    111409.078489   \n",
       "\n",
       "    foul_area_per  fair_to_foul  ... regional_div  region_final_quarter  \\\n",
       "61       0.215600      3.638218  ...          NaN                   NaN   \n",
       "20       0.183174      4.459293  ...          NaN                   NaN   \n",
       "74       0.212705      3.701357  ...          4.0                   NaN   \n",
       "85       0.244293      3.093450  ...          NaN                   NaN   \n",
       "35       0.300893      2.323441  ...          NaN                   NaN   \n",
       "\n",
       "    finals   nickname   color1   color2  color3     score  division_final  \\\n",
       "61     NaN    Pirates  #ff0000  #ffffff     NaN  9.912756             3.0   \n",
       "20     NaN    Trojans  #4169e1  #ffa500     NaN  9.753206             4.0   \n",
       "74     NaN  Cardinals  #ff0000  #000000     NaN  9.386839             4.0   \n",
       "85     NaN   Clippers  #800000  #ffffff     NaN  8.412362             4.0   \n",
       "35     NaN    Trojans  #000080  #ffffff     NaN  7.839091             4.0   \n",
       "\n",
       "    level  \n",
       "61      1  \n",
       "20      1  \n",
       "74      2  \n",
       "85      1  \n",
       "35      1  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-16.96119754485339\n",
      "9.91275550455552\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>park_name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Detroit Osborn HS</td>\n",
       "      <td>-16.961198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Kalamazoo College - college</td>\n",
       "      <td>-10.731596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Michigan State - Old College Field</td>\n",
       "      <td>-10.451569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adrian College</td>\n",
       "      <td>-9.516080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Sagniaw Valley State - college</td>\n",
       "      <td>-9.514021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CMU - college</td>\n",
       "      <td>-9.363523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Flushing HS</td>\n",
       "      <td>-7.540115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Gaylord High School - high school</td>\n",
       "      <td>-7.518583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Newaygo High School - high school</td>\n",
       "      <td>-7.256577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Cornerstone Baseball Field - college</td>\n",
       "      <td>-7.256400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                park_name      score\n",
       "30                      Detroit Osborn HS -16.961198\n",
       "72            Kalamazoo College - college -10.731596\n",
       "88     Michigan State - Old College Field -10.451569\n",
       "1                          Adrian College  -9.516080\n",
       "118        Sagniaw Valley State - college  -9.514021\n",
       "25                          CMU - college  -9.363523\n",
       "38                            Flushing HS  -7.540115\n",
       "44      Gaylord High School - high school  -7.518583\n",
       "99      Newaygo High School - high school  -7.256577\n",
       "29   Cornerstone Baseball Field - college  -7.256400"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.describe()\n",
    "\n",
    "## Min and max values of score column\n",
    "print(df_merged['score'].min())\n",
    "print(df_merged['score'].max())\n",
    "\n",
    "# lowest 10 scores with field names\n",
    "df_merged.nsmallest(10, 'score')[['park_name', 'score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>park_name</th>\n",
       "      <th>foul</th>\n",
       "      <th>fop</th>\n",
       "      <th>notes</th>\n",
       "      <th>home_plate</th>\n",
       "      <th>foul_area_sqft</th>\n",
       "      <th>fop_area_sqft</th>\n",
       "      <th>field_area_sqft</th>\n",
       "      <th>foul_area_per</th>\n",
       "      <th>fair_to_foul</th>\n",
       "      <th>...</th>\n",
       "      <th>regional_div</th>\n",
       "      <th>region_final_quarter</th>\n",
       "      <th>finals</th>\n",
       "      <th>nickname</th>\n",
       "      <th>color1</th>\n",
       "      <th>color2</th>\n",
       "      <th>color3</th>\n",
       "      <th>score</th>\n",
       "      <th>division_final</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Lowell High School - high school</td>\n",
       "      <td>[(-85.3763871, 42.9571353), (-85.3768716, 42.9...</td>\n",
       "      <td>[(-85.3763871, 42.9571353), (-85.3752914, 42.9...</td>\n",
       "      <td>guestimate on the fenceline based on the mow p...</td>\n",
       "      <td>(-85.3763871, 42.9571353)</td>\n",
       "      <td>29097.855748</td>\n",
       "      <td>99166.362021</td>\n",
       "      <td>128264.217769</td>\n",
       "      <td>0.226859</td>\n",
       "      <td>3.40803</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Red Arrows</td>\n",
       "      <td>#ff0000</td>\n",
       "      <td>#ffffff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.20302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           park_name  \\\n",
       "81  Lowell High School - high school   \n",
       "\n",
       "                                                 foul  \\\n",
       "81  [(-85.3763871, 42.9571353), (-85.3768716, 42.9...   \n",
       "\n",
       "                                                  fop  \\\n",
       "81  [(-85.3763871, 42.9571353), (-85.3752914, 42.9...   \n",
       "\n",
       "                                                notes  \\\n",
       "81  guestimate on the fenceline based on the mow p...   \n",
       "\n",
       "                   home_plate  foul_area_sqft  fop_area_sqft  field_area_sqft  \\\n",
       "81  (-85.3763871, 42.9571353)    29097.855748   99166.362021    128264.217769   \n",
       "\n",
       "    foul_area_per  fair_to_foul  ... regional_div  region_final_quarter  \\\n",
       "81       0.226859       3.40803  ...          NaN                   NaN   \n",
       "\n",
       "    finals    nickname   color1   color2  color3    score  division_final  \\\n",
       "81     NaN  Red Arrows  #ff0000  #ffffff     NaN -5.20302             1.0   \n",
       "\n",
       "    level  \n",
       "81      1  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[df_merged['park_name'] == 'Lowell High School - high school']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>park_name</th>\n",
       "      <th>foul</th>\n",
       "      <th>fop</th>\n",
       "      <th>notes</th>\n",
       "      <th>home_plate</th>\n",
       "      <th>foul_area_sqft</th>\n",
       "      <th>fop_area_sqft</th>\n",
       "      <th>field_area_sqft</th>\n",
       "      <th>foul_area_per</th>\n",
       "      <th>fair_to_foul</th>\n",
       "      <th>...</th>\n",
       "      <th>min_distance_rank</th>\n",
       "      <th>avg_distance_rank</th>\n",
       "      <th>median_distance_rank</th>\n",
       "      <th>field_area_rank</th>\n",
       "      <th>foul_area_rank</th>\n",
       "      <th>fop_area_per_rank</th>\n",
       "      <th>ratio_rank</th>\n",
       "      <th>fop_centroid</th>\n",
       "      <th>field_orientation</th>\n",
       "      <th>field_cardinal_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Lowell High School - high school</td>\n",
       "      <td>[(-85.3763871, 42.9571353), (-85.3768716, 42.9...</td>\n",
       "      <td>[(-85.3763871, 42.9571353), (-85.3752914, 42.9...</td>\n",
       "      <td>guestimate on the fenceline based on the mow p...</td>\n",
       "      <td>(-85.3763871, 42.9571353)</td>\n",
       "      <td>29097.855748</td>\n",
       "      <td>99166.362021</td>\n",
       "      <td>128264.217769</td>\n",
       "      <td>0.226859</td>\n",
       "      <td>3.40803</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>(-85.3761548818182, 42.95801321363636)</td>\n",
       "      <td>10.956002</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           park_name  \\\n",
       "81  Lowell High School - high school   \n",
       "\n",
       "                                                 foul  \\\n",
       "81  [(-85.3763871, 42.9571353), (-85.3768716, 42.9...   \n",
       "\n",
       "                                                  fop  \\\n",
       "81  [(-85.3763871, 42.9571353), (-85.3752914, 42.9...   \n",
       "\n",
       "                                                notes  \\\n",
       "81  guestimate on the fenceline based on the mow p...   \n",
       "\n",
       "                   home_plate  foul_area_sqft  fop_area_sqft  field_area_sqft  \\\n",
       "81  (-85.3763871, 42.9571353)    29097.855748   99166.362021    128264.217769   \n",
       "\n",
       "    foul_area_per  fair_to_foul  ... min_distance_rank  avg_distance_rank  \\\n",
       "81       0.226859       3.40803  ...              29.0               20.0   \n",
       "\n",
       "    median_distance_rank  field_area_rank  foul_area_rank  fop_area_per_rank  \\\n",
       "81                  19.0             24.0            56.0               19.0   \n",
       "\n",
       "    ratio_rank                            fop_centroid  field_orientation  \\\n",
       "81        72.0  (-85.3761548818182, 42.95801321363636)          10.956002   \n",
       "\n",
       "    field_cardinal_direction  \n",
       "81                         N  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Find Lowell High School in final Dataframe\n",
    "\n",
    "df_parks[df_parks['park_name'] == 'Lowell High School - high school']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END BLOCK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Do a FUZZY MATCH OF DF_HOSTS AND DF_PARKS\n",
    "# # Debugging step to check for non-string values in host_teams\n",
    "# for team in host_teams:\n",
    "#     if not isinstance(team, str):\n",
    "#         print(f\"Non-string value found in host_teams: {team}\")\n",
    "\n",
    "# # Debugging step to check for non-string values in park_names\n",
    "# for park in park_names:\n",
    "#     if not isinstance(park, str):\n",
    "#         print(f\"Non-string value found in park_names: {park}\")\n",
    "\n",
    "# # Continue with fuzzy matching if no non-string values are found\n",
    "# matches = [(team, process.extractOne(team, park_names)) for team in host_teams]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## List the values from the team column\n",
    "\n",
    "# print(len(df_hosts['team'].unique()))\n",
    "# df_hosts['team'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parks = df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parks_df = df_cleaned.copy()\n",
    "\n",
    "parks_df.info()\n",
    "host_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataframes(parks_df, host_df, min_score=90):\n",
    "    dict_list = []\n",
    "    unmatched_rows = []\n",
    "    # Drop NaN values in 'team' and 'park_name' before matching\n",
    "    host_names = host_df.team.dropna().unique()\n",
    "    for name in parks_df.park_name.dropna():  # ignore NaN values\n",
    "        match = match_team(name, host_names, min_score)\n",
    "        \n",
    "        # If no match found, add to unmatched_rows and continue to next iteration\n",
    "        if match[0] == \"\":\n",
    "            unmatched_rows.append(name)\n",
    "            continue\n",
    "\n",
    "        dict_ = {}\n",
    "        dict_.update({\"park_name_parks\" : name})\n",
    "        dict_.update({\"match_name_host\" : match[0]})\n",
    "        dict_.update({\"score\" : match[1]})\n",
    "        dict_list.append(dict_)\n",
    "\n",
    "    merge_table = pd.DataFrame(dict_list)\n",
    "    \n",
    "    # Remove duplicates in merge_table, keeping only the row with the highest score\n",
    "    merge_table = merge_table.sort_values('score', ascending=False).drop_duplicates(['park_name_parks'], keep='first')\n",
    "\n",
    "    if 'match_name_host' in merge_table.columns:\n",
    "        merged_df = pd.merge(parks_df, merge_table, left_on='park_name', right_on='park_name_parks', how='left')\n",
    "        merged_df = pd.merge(merged_df, host_df, left_on='match_name_host', right_on='team', how='left')\n",
    "    else:\n",
    "        print(\"No matches found.\")\n",
    "        merged_df = None\n",
    "\n",
    "    return merged_df, unmatched_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df = merged_df.sort_values('score', ascending=False).drop_duplicates(subset=['park_name', 'team'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df, unmatched_rows = merge_dataframes(parks_df, host_df, min_score=90)\n",
    "\n",
    "merged_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this function, we first match each team name in host_df with the park names in parks_df. If a match with a similarity score greater than the threshold (85 in your case) is found, we record the match in merge_table. If no match is found, we record the team name in unmatched_rows. After going through all team names, we merge host_df and parks_df based on the matches in merge_table.\n",
    "\n",
    "The function merge_dataframes returns two objects. The first object, merged_df, is a DataFrame that contains the merged data. The second object, unmatched_rows, is a list of team names in host_df for which no match in parks_df could be found. You can inspect unmatched_rows to see which rows couldn't be matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataframes(parks_df, host_df, min_score=90):\n",
    "    dict_list = []\n",
    "    unmatched_rows = []\n",
    "    # Drop NaN values in 'team' and 'park_name' before matching\n",
    "    host_names = host_df.team.dropna().unique()\n",
    "    for name in parks_df.park_name.dropna():  # ignore NaN values\n",
    "        match = match_team(name, host_names, min_score)\n",
    "        \n",
    "        # If no match found, add to unmatched_rows and continue to next iteration\n",
    "        if match[0] == \"\":\n",
    "            unmatched_rows.append(name)\n",
    "            continue\n",
    "\n",
    "        dict_ = {}\n",
    "        dict_.update({\"park_name_parks\" : name})\n",
    "        dict_.update({\"match_name_host\" : match[0]})\n",
    "        dict_.update({\"score\" : match[1]})\n",
    "        dict_list.append(dict_)\n",
    "\n",
    "    merge_table = pd.DataFrame(dict_list)\n",
    "    \n",
    "    # Remove duplicates in merge_table, keeping only the row with the highest score\n",
    "    merge_table = merge_table.sort_values('score', ascending=False).drop_duplicates(['park_name_parks'], keep='first')\n",
    "\n",
    "    if 'match_name_host' in merge_table.columns:\n",
    "        merged_df = pd.merge(parks_df, merge_table, left_on='park_name', right_on='park_name_parks', how='left')\n",
    "        merged_df = pd.merge(merged_df, host_df, left_on='match_name_host', right_on='team', how='left')\n",
    "    else:\n",
    "        print(\"No matches found.\")\n",
    "        merged_df = None\n",
    "\n",
    "    return merged_df, unmatched_rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WORKING HERE DOWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Matching Function to compair host names to park names \n",
    "\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "def find_host_matches(host_df, parks_df):\n",
    "    # Initialize empty lists to store the matches and unmatched park names\n",
    "    matches = []\n",
    "    unmatched_park_names = []\n",
    "\n",
    "    # Iterate over each host and district in the host_df\n",
    "    for host, district in zip(host_df['team'], host_df['district']):\n",
    "        # Use fuzzy matching to find potential matches in park names\n",
    "        potential_matches = process.extractBests(host, parks_df['park_name'], scorer=fuzz.token_set_ratio, score_cutoff=80)\n",
    "\n",
    "        # Store the host, district, and potential matches with their scores\n",
    "        matches.append({'host': host, 'district': district, 'potential_matches': potential_matches})\n",
    "\n",
    "        # Check if any strong matches were found\n",
    "        if len(potential_matches) > 0:\n",
    "            max_score = max(potential_matches, key=lambda x: x[1])[1]\n",
    "            if max_score >= 80:\n",
    "                continue\n",
    "\n",
    "        # If no strong matches were found, add the park name to unmatched list\n",
    "        unmatched_park_names.append((host, district))\n",
    "\n",
    "    # Create a dataframe from the matches list\n",
    "    matches_df = pd.DataFrame(matches)\n",
    "\n",
    "    # Count the number of strong matches and unmatched park names\n",
    "    strong_matches_count = matches_df['potential_matches'].apply(lambda x: sum(match[1] >= 80 for match in x)).sum()\n",
    "    unmatched_count = len(unmatched_park_names)\n",
    "\n",
    "    print(\"Number of strong matches:\", strong_matches_count)\n",
    "    print(\"Number of unmatched park names:\", unmatched_count)\n",
    "    print(\"Unmatched park names:\", unmatched_park_names)\n",
    "\n",
    "    return matches_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_df.info()\n",
    "parks_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to find host matches\n",
    "result_df = find_host_matches(host_df, parks_df)\n",
    "\n",
    "# # Merge the result_df to messe_df on district number\n",
    "# merged_df = result_df.merge(messe_df, left_on='district', right_on='district number')\n",
    "\n",
    "# # Select the desired column'region_semi_numbers\n",
    "# merged_df = merged_df[['host', 'division', 'district', 'region_semi_number', 'region_final_quarter', 'finals', 'potential_matches', 'Plot Note', 'Map Link MHSAA']]\n",
    "# merged_df.head()\n",
    "# # merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Keep only the field name from the potential matches, ignore if the potential match is empty\n",
    "merged_df['potential_matches'] = merged_df['potential_matches'].apply(lambda x: x[0][0] if len(x) > 0 else np.nan)\n",
    "\n",
    "\n",
    "# merged_df['potential_matches'] = merged_df['potential_matches'].apply(lambda x: x[0][0])\n",
    "\n",
    "# Rename the potential_matches column to park_name\n",
    "\n",
    "merged_df.rename(columns={'potential_matches': 'park_name'}, inplace=True)\n",
    "\n",
    "\n",
    "merged_df.head()\n",
    "merged_df.info()\n",
    "# # Merge the merged_df to the parks_df on park_name\n",
    "\n",
    "# parks_df = parks_df.merge(merged_df, on='park_name', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge the merged_df to the parks_df on park_name\n",
    "parks_df = parks_df.merge(merged_df, on='park_name', how='left')\n",
    "\n",
    "parks_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parks_df.info()\n",
    "parks_df.head()\n",
    "\n",
    "# host_df.info()\n",
    "# host_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From here down are simple plots to do spot check of data and hold example of polar chart\n",
    "\n",
    "### FILL IN THE REST OF JSON WITH THE DATA FOR THE 2023 TOURNEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pull the host team information into the parks_df\n",
    "parks_df = parks_df.merge(host_df, on='host', how='left')\n",
    "\n",
    "### Create columns for tournament levels\n",
    "# District is done, Need regional semi, regional final, quarter final, final_four\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "parks_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Build the file path using os.path.join\n",
    "file_path = os.path.join('data', 'html', 'mhsaa', 'data', 'tourney_2023.json')\n",
    "\n",
    "# Save the dataframe to JSON using the constructed file path\n",
    "parks_df.to_json(file_path, orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of the max distance, min distance, average distance, and median distance\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "ax[0, 0].hist(df_cleaned['max_distance'], bins=20)\n",
    "\n",
    "ax[0, 1].hist(df_cleaned['min_distance'], bins=20)\n",
    "\n",
    "ax[1, 0].hist(df_cleaned['avg_distance'], bins=20)\n",
    "\n",
    "ax[1, 1].hist(df_cleaned['median_distance'], bins=20)\n",
    "\n",
    "ax[0, 0].set_title('Max Distance')\n",
    "ax[0, 1].set_title('Min Distance')\n",
    "\n",
    "ax[1, 0].set_title('Average Distance')\n",
    "ax[1, 1].set_title('Median Distance')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compile a list of fields that are outliers\n",
    "\n",
    "outlier_fields = df_cleaned[(df_cleaned['max_distance'] > 400) | (df_cleaned['min_distance'] < 200) | (df_cleaned['avg_distance'] > 400) | (df_cleaned['median_distance'] > 400)]\n",
    "\n",
    "len(outlier_fields)\n",
    "\n",
    "print(outlier_fields['park_name'].values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of the top and bottom ten from each category\n",
    "\n",
    "top_ten_max = df_cleaned.sort_values(by='max_distance', ascending=False).head(10)\n",
    "top_ten_min = df_cleaned.sort_values(by='min_distance', ascending=True).head(10)\n",
    "\n",
    "top_ten_avg = df_cleaned.sort_values(by='avg_distance', ascending=False).head(10)\n",
    "top_ten_median = df_cleaned.sort_values(by='median_distance', ascending=False).head(10)\n",
    "\n",
    "top_ten_field_area = df_cleaned.sort_values(by='field_area_sqft', ascending=False).head(10)\n",
    "\n",
    "top_ten_foul_area = df_cleaned.sort_values(by='foul_area_sqft', ascending=False).head(10)\n",
    "\n",
    "top_ten_fop_area = df_cleaned.sort_values(by='fop_area_sqft', ascending=False).head(10)\n",
    "\n",
    "top_ten_ratio = df_cleaned.sort_values(by='fair_to_foul', ascending=False).head(10)\n",
    "\n",
    "bottom_ten_ratio = df_cleaned.sort_values(by='fair_to_foul', ascending=True).head(10)\n",
    "\n",
    "bottom_ten_max = df_cleaned.sort_values(by='max_distance', ascending=True).head(10)\n",
    "bottom_ten_min = df_cleaned.sort_values(by='min_distance', ascending=False).head(10)\n",
    "bottom_ten_avg = df_cleaned.sort_values(by='avg_distance', ascending=True).head(10)\n",
    "bottom_ten_median = df_cleaned.sort_values(by='median_distance', ascending=True).head(10)\n",
    "\n",
    "\n",
    "### Create and display a dataframe with columns for the top and bottom ten fields for each category\n",
    "\n",
    "top_bottom_df = pd.DataFrame()\n",
    "\n",
    "top_bottom_df['top_ten_max'] = top_ten_max['park_name'].values\n",
    "top_bottom_df['top_ten_min'] = top_ten_min['park_name'].values\n",
    "top_bottom_df['top_ten_avg'] = top_ten_avg['park_name'].values\n",
    "\n",
    "top_bottom_df['top_ten_median'] = top_ten_median['park_name'].values\n",
    "top_bottom_df['top_ten_field_area'] = top_ten_field_area['park_name'].values\n",
    "top_bottom_df['top_ten_foul_area'] = top_ten_foul_area['park_name'].values\n",
    "top_bottom_df['top_ten_fop_area'] = top_ten_fop_area['park_name'].values\n",
    "top_bottom_df['top_ten_ratio'] = top_ten_ratio['park_name'].values\n",
    "\n",
    "top_bottom_df['bottom_ten_ratio'] = bottom_ten_ratio['park_name'].values\n",
    "top_bottom_df['bottom_ten_max'] = bottom_ten_max['park_name'].values\n",
    "top_bottom_df['bottom_ten_min'] = bottom_ten_min['park_name'].values\n",
    "top_bottom_df['bottom_ten_avg'] = bottom_ten_avg['park_name'].values\n",
    "top_bottom_df['bottom_ten_median'] = bottom_ten_median['park_name'].values\n",
    "\n",
    "\n",
    "top_bottom_df.head(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NEW WITH AUTO SCALING\n",
    "\n",
    "def calculate_max_y(data, num_bins=36, level_filter=None):\n",
    "    count_by_orientation = process_data(data, level_filter)\n",
    "    \n",
    "    # Compute the histogram\n",
    "    bin_counts = np.zeros(num_bins)\n",
    "    \n",
    "    for orientation, count in count_by_orientation.items():\n",
    "        idx = int(orientation / (360 / num_bins))\n",
    "        if idx == num_bins:\n",
    "            idx = 0\n",
    "        bin_counts[idx] += count\n",
    "    \n",
    "    return max(bin_counts)\n",
    "\n",
    "\n",
    "def create_polar_chart(data, num_bins=36, level_filter=None, y_min=-20, background_color='#2b2b2b', color_map=plt.cm.viridis, bar_alpha=0.8):\n",
    "    count_by_orientation = process_data(data, level_filter)\n",
    "    \n",
    "    # Compute the histogram\n",
    "    bin_edges = np.linspace(0.0, 2 * np.pi, num_bins + 1)\n",
    "    bin_counts = np.zeros(num_bins)\n",
    "    \n",
    "    for orientation, count in count_by_orientation.items():\n",
    "        idx = int(orientation / (360 / num_bins))\n",
    "        if idx == num_bins:\n",
    "            idx = 0\n",
    "        bin_counts[idx] += count\n",
    "    \n",
    "    bin_width = 2 * np.pi / num_bins\n",
    "\n",
    "    # Set plot size\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    ax = plt.subplot(111, projection='polar')\n",
    "    ax.set_theta_direction(-1)\n",
    "    ax.set_theta_offset(np.pi / 2)\n",
    "\n",
    "    ax.set_facecolor('#808080')\n",
    "    # ax.set_yscale('log')\n",
    "\n",
    "    # Set dark background\n",
    "    ax.set_facecolor(background_color)\n",
    "    plt.gca().set_rlabel_position(22.5)\n",
    "    y_max = calculate_max_y(data, num_bins=num_bins, level_filter=level_filter) + 5\n",
    "    ax.set_ylim(y_min, y_max)  # Adjust based on max count\n",
    "\n",
    "    # Add bars for negative values\n",
    "    zero_height_bars = ax.bar(bin_edges[:-1], np.abs(ax.get_ylim()[0]), width=bin_width, bottom=0.0, color='k', alpha=0.3)\n",
    "\n",
    "    bars = ax.bar(bin_edges[:-1], bin_counts, width=bin_width, bottom=0)\n",
    "    \n",
    "    # Use custom colors and opacity\n",
    "    for r, bar in zip(bin_counts, bars):\n",
    "        bar.set_facecolor(color_map(r / max(bin_counts)))\n",
    "        bar.set_alpha(bar_alpha)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CALL AUTO ADJUSTING CHART #####\n",
    "\n",
    "\n",
    "## NEW PERAMS\n",
    "\n",
    "\n",
    "# Call your function\n",
    "create_polar_chart(\n",
    "    data, \n",
    "    num_bins=30, \n",
    "    # level_filter=\"level1\", \n",
    "    y_min=0, \n",
    "    background_color='#2b2b2b', \n",
    "    color_map=plt.cm.viridis, \n",
    "    bar_alpha=0.8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NEW CHAT GPT CODE\n",
    "\n",
    "def create_polar_chart(data, num_bins=36, level_filter=None, y_min=-20, y_max=130, background_color='#2b2b2b', color_map=plt.cm.viridis, bar_alpha=0.8):\n",
    "    count_by_orientation = process_data(data, level_filter)\n",
    "    \n",
    "    # Compute the histogram\n",
    "    bin_edges = np.linspace(0.0, 2 * np.pi, num_bins + 1)\n",
    "    bin_counts = np.zeros(num_bins)\n",
    "    \n",
    "    for orientation, count in count_by_orientation.items():\n",
    "        idx = int(orientation / (360 / num_bins))\n",
    "        if idx == num_bins:\n",
    "            idx = 0\n",
    "        bin_counts[idx] += count\n",
    "    \n",
    "    bin_width = 2 * np.pi / num_bins\n",
    "\n",
    "    # Set plot size\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    ax = plt.subplot(111, projection='polar')\n",
    "    ax.set_theta_direction(-1)\n",
    "    ax.set_theta_offset(np.pi / 2)\n",
    "\n",
    "    ax.set_facecolor('#808080')\n",
    "    # ax.set_yscale('log')\n",
    "\n",
    "    # Set dark background\n",
    "    ax.set_facecolor(background_color)\n",
    "    plt.gca().set_rlabel_position(22.5)\n",
    "    ax.set_ylim(y_min, y_max)  # Adjust based on max count\n",
    "\n",
    "    # Add bars for negative values\n",
    "    zero_height_bars = ax.bar(bin_edges[:-1], np.abs(ax.get_ylim()[0]), width=bin_width, bottom=0.0, color='k', alpha=0.3)\n",
    "\n",
    "    bars = ax.bar(bin_edges[:-1], bin_counts, width=bin_width, bottom=0)\n",
    "    \n",
    "    # Use custom colors and opacity\n",
    "    for r, bar in zip(bin_counts, bars):\n",
    "        bar.set_facecolor(color_map(r / max(bin_counts)))\n",
    "        bar.set_alpha(bar_alpha)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a polar chart showing the direction of all the tournment fields\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create a function to process the data, counting the orientations and filtering by level.\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def process_data(data, level_filter=None):\n",
    "    count_by_orientation = defaultdict(int)\n",
    "    \n",
    "    for record in data:\n",
    "        if level_filter is None or record['level'] == level_filter:\n",
    "            orientation = round(record['field_orientation'])\n",
    "            count_by_orientation[orientation] += 1\n",
    "\n",
    "    return count_by_orientation\n",
    "\n",
    "def create_polar_chart(data, num_bins=36, level_filter=None):\n",
    "    count_by_orientation = process_data(data, level_filter)\n",
    "    \n",
    "    # Compute the histogram\n",
    "    bin_edges = np.linspace(0.0, 2 * np.pi, num_bins + 1)\n",
    "    bin_counts = np.zeros(num_bins)\n",
    "    \n",
    "    for orientation, count in count_by_orientation.items():\n",
    "        idx = int(orientation / (360 / num_bins))\n",
    "        if idx == num_bins:\n",
    "            idx = 0\n",
    "        bin_counts[idx] += count\n",
    "    \n",
    "    bin_width = 2 * np.pi / num_bins\n",
    "\n",
    "    # Set plot size\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    ax = plt.subplot(111, projection='polar')\n",
    "    ax.set_theta_direction(-1)\n",
    "    ax.set_theta_offset(np.pi / 2)\n",
    "\n",
    "    ax.set_facecolor('#808080')\n",
    "    ###\n",
    "    # ax.set_yscale('log')\n",
    "\n",
    "    \n",
    "    # # Set dark background\n",
    "    ax.set_facecolor('#2b2b2b')\n",
    "    plt.gca().set_rlabel_position(22.5)\n",
    "    ax.set_ylim(-20, 130)  # Adjust based on max count\n",
    "\n",
    "    # Add bars for negative values\n",
    "    zero_height_bars = ax.bar(bin_edges[:-1], np.abs(ax.get_ylim()[0]), width=bin_width, bottom=0.0, color='k', alpha=0.3)\n",
    "\n",
    "    bars = ax.bar(bin_edges[:-1], bin_counts, width=bin_width, bottom=0)\n",
    "    \n",
    "    # Use custom colors and opacity\n",
    "    for r, bar in zip(bin_counts, bars):\n",
    "        bar.set_facecolor(plt.cm.viridis(r / max(bin_counts)))\n",
    "        # bar.set_facecolor(plt.cm.plasma(r / max(bin_counts)))\n",
    "        bar.set_alpha(0.8)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_polar_chart(data, num_bins=50, level_filter=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
