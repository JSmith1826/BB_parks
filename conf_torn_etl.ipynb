{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ETL NOTEBOOK FOR 2023 MHSAA TOURNEY SPECIFIC MAP\n",
    "\n",
    "#### Adapted from ETL for JSON\n",
    "\n",
    "## Dependencies and Setup\n",
    "### Dependencies\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "## Start timer\n",
    "start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD BLOCK###\n",
    "#### Load data from kml file exported from Google Earth\n",
    "\n",
    "file_path = ('data/kml/conf_tourny.kml') # file path to kml file\n",
    "\n",
    "\n",
    "# Read the KML file\n",
    "with open(file_path) as file:\n",
    "    xml_data = file.read()\n",
    "\n",
    "# Initialize soup variables for parsing file\n",
    "soup = BeautifulSoup(xml_data, 'xml')\n",
    "folders = soup.Document\n",
    "list = soup.Document.find_all('Folder')\n",
    "\n",
    "# Create a list to store rows to append to the DataFrame\n",
    "rows = []\n",
    "\n",
    "# Loop through the folders and extract the data\n",
    "for folder in list:\n",
    "    try:\n",
    "        field_name = folder.find('name').text\n",
    "        foul = folder.find_all('coordinates')[0].text\n",
    "        fop = folder.find_all('coordinates')[1].text\n",
    "        notes = None\n",
    "\n",
    "        # Check if there is a description tag, if so, use it for notes\n",
    "        if folder.find('description') is not None:\n",
    "            notes = folder.find('description').text\n",
    "\n",
    "        row = {\n",
    "            'field': field_name,\n",
    "            'foul': foul,\n",
    "            'fop': fop,\n",
    "            'notes': notes\n",
    "        }\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Add name of folder to a list of failed folders\n",
    "        failed.append(folder.find('name').text)\n",
    "        print(f\"Error processing folder: {folder.find('name').text}. Error message: {str(e)}\")\n",
    "\n",
    "# Convert the list of rows to a DataFrame\n",
    "df = pd.DataFrame(rows, columns=['field', 'foul', 'fop', 'notes'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the new dataframe\n",
    "\n",
    "\n",
    "# Create a copy of the original DataFrame\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "# Remove new line and space characters from coordinates\n",
    "df_cleaned = df_cleaned.replace(r'\\n','', regex=True) \n",
    "df_cleaned = df_cleaned.replace(r'\\t','', regex=True) \n",
    "\n",
    "# Drop any duplicate rows\n",
    "df_cleaned = df_cleaned.drop_duplicates(subset=['field'], keep='first')\n",
    "\n",
    "# Drop any rows with empty fields\n",
    "df_cleaned = df_cleaned[(df_cleaned != 0).all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Clean up polygon data and create a new home_plate column\n",
    "\n",
    "def parse_coordinates(coord_string):\n",
    "    coords = coord_string.split()\n",
    "    parsed_coords = [tuple(map(float, coord.split(',')[:2])) for coord in coords]\n",
    "    return parsed_coords\n",
    "\n",
    "# Create a new column for the home_plate location using the first set of coordinates in the 'fop' column\n",
    "df_cleaned['home_plate'] = df_cleaned['fop'].apply(lambda x: parse_coordinates(x)[0])\n",
    "\n",
    "# Apply the parse_coordinates function to the 'foul' and 'fop' columns\n",
    "df_cleaned['foul'] = df_cleaned['foul'].apply(parse_coordinates)\n",
    "df_cleaned['fop'] = df_cleaned['fop'].apply(parse_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## AREA CALCULATION ##############\n",
    "\n",
    "\n",
    "import pyproj\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import transform\n",
    "\n",
    "\n",
    "def calculate_area(coords):\n",
    "    # Create a Polygon object from the coordinates\n",
    "    polygon = Polygon(coords)\n",
    "\n",
    "    # Calculate the centroid of the polygon\n",
    "    centroid = polygon.centroid\n",
    "\n",
    "    # Create a custom LAEA projection centered on the centroid\n",
    "    custom_projection = f\"+proj=laea +lat_0={centroid.y} +lon_0={centroid.x} +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs\"\n",
    "\n",
    "    # Create a transformer for converting coordinates to the custom LAEA projection\n",
    "    transformer = pyproj.Transformer.from_crs(\n",
    "        pyproj.CRS(\"EPSG:4326\"),  # WGS 84 (latitude and longitude)\n",
    "        pyproj.CRS(custom_projection),  # Custom LAEA projection\n",
    "        always_xy=True\n",
    "    )\n",
    "\n",
    "    # Define a function to transform coordinates using the transformer\n",
    "    def transform_coordinates(x, y):\n",
    "        return transformer.transform(x, y)\n",
    "\n",
    "    # Convert the coordinates to the custom LAEA projection\n",
    "    polygon_laea = transform(transform_coordinates, polygon)\n",
    "\n",
    "    # Calculate the area in square meters\n",
    "    area_sqm = polygon_laea.area\n",
    "\n",
    "    # Convert the area to square feet (1 square meter = 10.764 square feet)\n",
    "    area_sqft = area_sqm * 10.764\n",
    "\n",
    "    return area_sqft\n",
    "\n",
    "\n",
    "\n",
    "### Call Function and add to dataframe\n",
    "df_cleaned['foul_area_sqft'] = df_cleaned['foul'].apply(calculate_area)\n",
    "df_cleaned['fop_area_sqft'] = df_cleaned['fop'].apply(calculate_area)\n",
    "\n",
    "## Calculate the total area of the field and the ratio of foul area to field area\n",
    "df_cleaned['field_area_sqft'] = df_cleaned['foul_area_sqft'] + df_cleaned['fop_area_sqft']\n",
    "## Percentage foul area\n",
    "df_cleaned['foul_area_per'] = df_cleaned['foul_area_sqft'] / df_cleaned['field_area_sqft']\n",
    "## Fair to Foul Ratio\n",
    "df_cleaned['fair_to_foul'] = df_cleaned['fop_area_sqft'] / df_cleaned['foul_area_sqft']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# FENCE DISTANCE CALCULATION #############\n",
    "\n",
    "from geopy.distance import great_circle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def interpolate_points(start, end, length_ratio):\n",
    "    start_np = np.array(start)\n",
    "    end_np = np.array(end)\n",
    "    return tuple(start_np + (end_np - start_np) * length_ratio)\n",
    "\n",
    "def calculate_distances(home_plate, outfield_coords, num_points=540):\n",
    "    def is_same_point(point1, point2, tolerance=1e-6):\n",
    "        return abs(point1[0] - point2[0]) < tolerance and abs(point1[1] - point2[1]) < tolerance\n",
    "\n",
    "    home_plate_lat_lon = (home_plate[1], home_plate[0])\n",
    "    distances = []\n",
    "\n",
    "    # Calculate total line length\n",
    "    total_length = 0\n",
    "    segments = []\n",
    "    for i in range(len(outfield_coords) - 1):\n",
    "        start = outfield_coords[i]\n",
    "        end = outfield_coords[i + 1]\n",
    "        if not is_same_point(home_plate, start) and not is_same_point(home_plate, end):\n",
    "            segment_length = great_circle((start[1], start[0]), (end[1], end[0])).feet\n",
    "            segments.append((start, end, segment_length))\n",
    "            total_length += segment_length\n",
    "\n",
    "    # Calculate the distance between equally spaced points\n",
    "    spacing = total_length / (num_points - 1)\n",
    "\n",
    "    # Interpolate points and calculate distances\n",
    "    current_length = 0\n",
    "    segment_index = 0\n",
    "    for i in range(num_points):\n",
    "        while segment_index < len(segments) - 1 and current_length > segments[segment_index][2]:\n",
    "            current_length -= segments[segment_index][2]\n",
    "            segment_index += 1\n",
    "\n",
    "        start, end, segment_length = segments[segment_index]\n",
    "        length_ratio = current_length / segment_length\n",
    "        point = interpolate_points(start, end, length_ratio)\n",
    "        distance = round(great_circle(home_plate_lat_lon, (point[1], point[0])).feet)\n",
    "        distances.append(distance)\n",
    "\n",
    "        current_length += spacing\n",
    "\n",
    "    return distances\n",
    "\n",
    "# Calculate distances for each row\n",
    "df_cleaned['distances'] = df_cleaned.apply(lambda row: calculate_distances(row['home_plate'], row['fop']), axis=1)\n",
    "\n",
    "# Calculate max, min, and average distances for each row\n",
    "df_cleaned['max_distance'] = df_cleaned['distances'].apply(max)\n",
    "df_cleaned['min_distance'] = df_cleaned['distances'].apply(min)\n",
    "df_cleaned['avg_distance'] = df_cleaned['distances'].apply(lambda distances: sum(distances) / len(distances))\n",
    "# get the median distance\n",
    "df_cleaned['median_distance'] = df_cleaned['distances'].apply(lambda distances: np.median(distances))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>foul</th>\n",
       "      <th>fop</th>\n",
       "      <th>notes</th>\n",
       "      <th>home_plate</th>\n",
       "      <th>foul_area_sqft</th>\n",
       "      <th>fop_area_sqft</th>\n",
       "      <th>field_area_sqft</th>\n",
       "      <th>foul_area_per</th>\n",
       "      <th>fair_to_foul</th>\n",
       "      <th>distances</th>\n",
       "      <th>max_distance</th>\n",
       "      <th>min_distance</th>\n",
       "      <th>avg_distance</th>\n",
       "      <th>median_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BayCare Ballpark</td>\n",
       "      <td>[(-82.7319934, 27.9713686), (-82.7319914, 27.9...</td>\n",
       "      <td>[(-82.7319934, 27.9713686), (-82.7309761, 27.9...</td>\n",
       "      <td>None</td>\n",
       "      <td>(-82.7319934, 27.9713686)</td>\n",
       "      <td>22578.905659</td>\n",
       "      <td>103478.725629</td>\n",
       "      <td>126057.631288</td>\n",
       "      <td>0.179116</td>\n",
       "      <td>4.582982</td>\n",
       "      <td>[328, 328, 328, 328, 328, 328, 328, 328, 328, ...</td>\n",
       "      <td>411</td>\n",
       "      <td>328</td>\n",
       "      <td>366.090741</td>\n",
       "      <td>364.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Binghamton University Baseball Stadium</td>\n",
       "      <td>[(-75.9744521, 42.0939984), (-75.9747317, 42.0...</td>\n",
       "      <td>[(-75.9744521, 42.0939984), (-75.9732887, 42.0...</td>\n",
       "      <td>None</td>\n",
       "      <td>(-75.9744521, 42.0939984)</td>\n",
       "      <td>27367.812527</td>\n",
       "      <td>100508.745834</td>\n",
       "      <td>127876.558360</td>\n",
       "      <td>0.214017</td>\n",
       "      <td>3.672517</td>\n",
       "      <td>[324, 324, 324, 324, 324, 324, 324, 324, 324, ...</td>\n",
       "      <td>394</td>\n",
       "      <td>324</td>\n",
       "      <td>358.872222</td>\n",
       "      <td>358.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bob Bennett Stadium</td>\n",
       "      <td>[(-119.7560656, 36.8138062), (-119.7549411, 36...</td>\n",
       "      <td>[(-119.7560656, 36.8138062), (-119.7560716, 36...</td>\n",
       "      <td>None</td>\n",
       "      <td>(-119.7560656, 36.8138062)</td>\n",
       "      <td>28895.424648</td>\n",
       "      <td>102732.414339</td>\n",
       "      <td>131627.838987</td>\n",
       "      <td>0.219524</td>\n",
       "      <td>3.555318</td>\n",
       "      <td>[331, 331, 331, 331, 331, 331, 331, 331, 331, ...</td>\n",
       "      <td>400</td>\n",
       "      <td>328</td>\n",
       "      <td>362.298148</td>\n",
       "      <td>360.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bob Warn Field at Sycamore Stadium</td>\n",
       "      <td>[(-87.4163934, 39.4786282), (-87.4164034, 39.4...</td>\n",
       "      <td>[(-87.4163934, 39.4786282), (-87.4152152, 39.4...</td>\n",
       "      <td>None</td>\n",
       "      <td>(-87.4163934, 39.4786282)</td>\n",
       "      <td>31712.602869</td>\n",
       "      <td>104193.618959</td>\n",
       "      <td>135906.221828</td>\n",
       "      <td>0.233342</td>\n",
       "      <td>3.285559</td>\n",
       "      <td>[332, 332, 332, 332, 332, 332, 332, 332, 332, ...</td>\n",
       "      <td>397</td>\n",
       "      <td>332</td>\n",
       "      <td>365.172222</td>\n",
       "      <td>365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charles Schwab Field</td>\n",
       "      <td>[(-95.93202390000002, 41.2671943), (-95.930798...</td>\n",
       "      <td>[(-95.93202390000002, 41.2671943), (-95.932004...</td>\n",
       "      <td>None</td>\n",
       "      <td>(-95.93202390000002, 41.2671943)</td>\n",
       "      <td>29845.574280</td>\n",
       "      <td>108845.278059</td>\n",
       "      <td>138690.852339</td>\n",
       "      <td>0.215195</td>\n",
       "      <td>3.646949</td>\n",
       "      <td>[333, 333, 333, 333, 333, 333, 333, 333, 333, ...</td>\n",
       "      <td>409</td>\n",
       "      <td>333</td>\n",
       "      <td>372.203704</td>\n",
       "      <td>370.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    field  \\\n",
       "0                        BayCare Ballpark   \n",
       "1  Binghamton University Baseball Stadium   \n",
       "2                     Bob Bennett Stadium   \n",
       "3      Bob Warn Field at Sycamore Stadium   \n",
       "4                    Charles Schwab Field   \n",
       "\n",
       "                                                foul  \\\n",
       "0  [(-82.7319934, 27.9713686), (-82.7319914, 27.9...   \n",
       "1  [(-75.9744521, 42.0939984), (-75.9747317, 42.0...   \n",
       "2  [(-119.7560656, 36.8138062), (-119.7549411, 36...   \n",
       "3  [(-87.4163934, 39.4786282), (-87.4164034, 39.4...   \n",
       "4  [(-95.93202390000002, 41.2671943), (-95.930798...   \n",
       "\n",
       "                                                 fop notes  \\\n",
       "0  [(-82.7319934, 27.9713686), (-82.7309761, 27.9...  None   \n",
       "1  [(-75.9744521, 42.0939984), (-75.9732887, 42.0...  None   \n",
       "2  [(-119.7560656, 36.8138062), (-119.7560716, 36...  None   \n",
       "3  [(-87.4163934, 39.4786282), (-87.4152152, 39.4...  None   \n",
       "4  [(-95.93202390000002, 41.2671943), (-95.932004...  None   \n",
       "\n",
       "                         home_plate  foul_area_sqft  fop_area_sqft  \\\n",
       "0         (-82.7319934, 27.9713686)    22578.905659  103478.725629   \n",
       "1         (-75.9744521, 42.0939984)    27367.812527  100508.745834   \n",
       "2        (-119.7560656, 36.8138062)    28895.424648  102732.414339   \n",
       "3         (-87.4163934, 39.4786282)    31712.602869  104193.618959   \n",
       "4  (-95.93202390000002, 41.2671943)    29845.574280  108845.278059   \n",
       "\n",
       "   field_area_sqft  foul_area_per  fair_to_foul  \\\n",
       "0    126057.631288       0.179116      4.582982   \n",
       "1    127876.558360       0.214017      3.672517   \n",
       "2    131627.838987       0.219524      3.555318   \n",
       "3    135906.221828       0.233342      3.285559   \n",
       "4    138690.852339       0.215195      3.646949   \n",
       "\n",
       "                                           distances  max_distance  \\\n",
       "0  [328, 328, 328, 328, 328, 328, 328, 328, 328, ...           411   \n",
       "1  [324, 324, 324, 324, 324, 324, 324, 324, 324, ...           394   \n",
       "2  [331, 331, 331, 331, 331, 331, 331, 331, 331, ...           400   \n",
       "3  [332, 332, 332, 332, 332, 332, 332, 332, 332, ...           397   \n",
       "4  [333, 333, 333, 333, 333, 333, 333, 333, 333, ...           409   \n",
       "\n",
       "   min_distance  avg_distance  median_distance  \n",
       "0           328    366.090741            364.0  \n",
       "1           324    358.872222            358.0  \n",
       "2           328    362.298148            360.5  \n",
       "3           332    365.172222            365.0  \n",
       "4           333    372.203704            370.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_corner_sharpness(distances):\n",
    "    # Calculate the difference between each distance and its neighbors\n",
    "    differences = np.diff(distances)\n",
    "    \n",
    "    # Take the absolute value to ignore whether the difference is positive or negative\n",
    "    differences = np.abs(differences)\n",
    "    \n",
    "    # Sum up the differences to get a total \"sharpness\" score\n",
    "    sharpness_score = np.sum(differences)\n",
    "    \n",
    "    return sharpness_score\n",
    "\n",
    "# Calculate the sharpemss score for each row\n",
    "df_cleaned['corner_sharpness'] = df_cleaned['distances'].apply(calculate_corner_sharpness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cleaned['corner_sharpness'].describe()\n",
    "df_cleaned['corner_sharpness'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Function to create ranks for each column\n",
    "\n",
    "# def rank_fields(df):\n",
    "#     # Calculate the rank for each category\n",
    "#     df['max_distance_rank'] = df['max_distance'].rank(ascending=False, method='min')\n",
    "#     df['min_distance_rank'] = df['min_distance'].rank(ascending=False, method='min')\n",
    "#     df['avg_distance_rank'] = df['avg_distance'].rank(ascending=False, method='min')\n",
    "#     df['median_distance_rank'] = df['median_distance'].rank(ascending=False, method='min')\n",
    "#     df['field_area_rank'] = df['field_area_sqft'].rank(ascending=False, method='min')\n",
    "#     df['foul_area_rank'] = df['foul_area_sqft'].rank(ascending=False, method='min')\n",
    "#     df['fop_area_per_rank'] = df['fop_area_sqft'].rank(ascending=False, method='min')\n",
    "#     df['ratio_rank'] = df['fair_to_foul'].rank(ascending=False, method='min')\n",
    "\n",
    "#     return df\n",
    "\n",
    "# ## Run Function\n",
    "\n",
    "# df_cleaned = rank_fields(df_cleaned)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Orienting the map to the home plate location ####\n",
    "\n",
    "### Find the center of the field\n",
    "def calculate_centroid(coords):\n",
    "    x_coords = [coord[0] for coord in coords]\n",
    "    y_coords = [coord[1] for coord in coords]\n",
    "    centroid_x = sum(x_coords) / len(coords)\n",
    "    centroid_y = sum(y_coords) / len(coords)\n",
    "    return (centroid_x, centroid_y)\n",
    "\n",
    "\n",
    "## Find the bearing between the home plate and the center of the field\n",
    "import math\n",
    "\n",
    "def calculate_bearing(point1, point2):\n",
    "    lat1, lon1 = math.radians(point1[1]), math.radians(point1[0])\n",
    "    lat2, lon2 = math.radians(point2[1]), math.radians(point2[0])\n",
    "\n",
    "    d_lon = lon2 - lon1\n",
    "\n",
    "    x = math.cos(lat2) * math.sin(d_lon)\n",
    "    y = math.cos(lat1) * math.sin(lat2) - math.sin(lat1) * math.cos(lat2) * math.cos(d_lon)\n",
    "\n",
    "    bearing = math.degrees(math.atan2(x, y))\n",
    "    bearing = (bearing + 360) % 360  # Normalize the bearing to the range [0, 360)\n",
    "\n",
    "    return bearing\n",
    "\n",
    "### Function to classify direction in laymans terms North, South, East, West, ect\n",
    "def degrees_to_cardinal_direction(degrees):\n",
    "    directions = ['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW', 'N']\n",
    "    index = round(degrees / 45)\n",
    "    return directions[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the centroid of the outfield fence coordinates for each row\n",
    "df_cleaned['fop_centroid'] = df_cleaned['fop'].apply(lambda coords: calculate_centroid(coords[1:]))\n",
    "\n",
    "# Calculate the bearing between home plate and the centroid for each row\n",
    "df_cleaned['field_orientation'] = df_cleaned.apply(lambda row: calculate_bearing(row['home_plate'], row['fop_centroid']), axis=1)\n",
    "\n",
    "# Convert the bearing to a cardinal direction\n",
    "df_cleaned['field_cardinal_direction'] = df_cleaned['field_orientation'].apply(degrees_to_cardinal_direction)\n",
    "\n",
    "# rename 'field' to 'park_name'\n",
    "df_cleaned.rename(columns={'field': 'park_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>park_name</th>\n",
       "      <th>foul</th>\n",
       "      <th>fop</th>\n",
       "      <th>notes</th>\n",
       "      <th>home_plate</th>\n",
       "      <th>foul_area_sqft</th>\n",
       "      <th>fop_area_sqft</th>\n",
       "      <th>field_area_sqft</th>\n",
       "      <th>foul_area_per</th>\n",
       "      <th>fair_to_foul</th>\n",
       "      <th>distances</th>\n",
       "      <th>max_distance</th>\n",
       "      <th>min_distance</th>\n",
       "      <th>avg_distance</th>\n",
       "      <th>median_distance</th>\n",
       "      <th>corner_sharpness</th>\n",
       "      <th>fop_centroid</th>\n",
       "      <th>field_orientation</th>\n",
       "      <th>field_cardinal_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BayCare Ballpark</td>\n",
       "      <td>[(-82.7319934, 27.9713686), (-82.7319914, 27.9...</td>\n",
       "      <td>[(-82.7319934, 27.9713686), (-82.7309761, 27.9...</td>\n",
       "      <td>None</td>\n",
       "      <td>(-82.7319934, 27.9713686)</td>\n",
       "      <td>22578.905659</td>\n",
       "      <td>103478.725629</td>\n",
       "      <td>126057.631288</td>\n",
       "      <td>0.179116</td>\n",
       "      <td>4.582982</td>\n",
       "      <td>[328, 328, 328, 328, 328, 328, 328, 328, 328, ...</td>\n",
       "      <td>411</td>\n",
       "      <td>328</td>\n",
       "      <td>366.090741</td>\n",
       "      <td>364.0</td>\n",
       "      <td>172</td>\n",
       "      <td>(-82.73140348571428, 27.971967085714287)</td>\n",
       "      <td>41.040438</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Binghamton University Baseball Stadium</td>\n",
       "      <td>[(-75.9744521, 42.0939984), (-75.9747317, 42.0...</td>\n",
       "      <td>[(-75.9744521, 42.0939984), (-75.9732887, 42.0...</td>\n",
       "      <td>None</td>\n",
       "      <td>(-75.9744521, 42.0939984)</td>\n",
       "      <td>27367.812527</td>\n",
       "      <td>100508.745834</td>\n",
       "      <td>127876.558360</td>\n",
       "      <td>0.214017</td>\n",
       "      <td>3.672517</td>\n",
       "      <td>[324, 324, 324, 324, 324, 324, 324, 324, 324, ...</td>\n",
       "      <td>394</td>\n",
       "      <td>324</td>\n",
       "      <td>358.872222</td>\n",
       "      <td>358.0</td>\n",
       "      <td>142</td>\n",
       "      <td>(-75.97392160000001, 42.09464799999999)</td>\n",
       "      <td>31.215416</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bob Bennett Stadium</td>\n",
       "      <td>[(-119.7560656, 36.8138062), (-119.7549411, 36...</td>\n",
       "      <td>[(-119.7560656, 36.8138062), (-119.7560716, 36...</td>\n",
       "      <td>None</td>\n",
       "      <td>(-119.7560656, 36.8138062)</td>\n",
       "      <td>28895.424648</td>\n",
       "      <td>102732.414339</td>\n",
       "      <td>131627.838987</td>\n",
       "      <td>0.219524</td>\n",
       "      <td>3.555318</td>\n",
       "      <td>[331, 331, 331, 331, 331, 331, 331, 331, 331, ...</td>\n",
       "      <td>400</td>\n",
       "      <td>328</td>\n",
       "      <td>362.298148</td>\n",
       "      <td>360.5</td>\n",
       "      <td>145</td>\n",
       "      <td>(-119.75520886666668, 36.81334199166667)</td>\n",
       "      <td>124.089705</td>\n",
       "      <td>SE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bob Warn Field at Sycamore Stadium</td>\n",
       "      <td>[(-87.4163934, 39.4786282), (-87.4164034, 39.4...</td>\n",
       "      <td>[(-87.4163934, 39.4786282), (-87.4152152, 39.4...</td>\n",
       "      <td>None</td>\n",
       "      <td>(-87.4163934, 39.4786282)</td>\n",
       "      <td>31712.602869</td>\n",
       "      <td>104193.618959</td>\n",
       "      <td>135906.221828</td>\n",
       "      <td>0.233342</td>\n",
       "      <td>3.285559</td>\n",
       "      <td>[332, 332, 332, 332, 332, 332, 332, 332, 332, ...</td>\n",
       "      <td>397</td>\n",
       "      <td>332</td>\n",
       "      <td>365.172222</td>\n",
       "      <td>365.0</td>\n",
       "      <td>135</td>\n",
       "      <td>(-87.41569657142857, 39.479177671428566)</td>\n",
       "      <td>44.387589</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charles Schwab Field</td>\n",
       "      <td>[(-95.93202390000002, 41.2671943), (-95.930798...</td>\n",
       "      <td>[(-95.93202390000002, 41.2671943), (-95.932004...</td>\n",
       "      <td>None</td>\n",
       "      <td>(-95.93202390000002, 41.2671943)</td>\n",
       "      <td>29845.574280</td>\n",
       "      <td>108845.278059</td>\n",
       "      <td>138690.852339</td>\n",
       "      <td>0.215195</td>\n",
       "      <td>3.646949</td>\n",
       "      <td>[333, 333, 333, 333, 333, 333, 333, 333, 333, ...</td>\n",
       "      <td>409</td>\n",
       "      <td>333</td>\n",
       "      <td>372.203704</td>\n",
       "      <td>370.0</td>\n",
       "      <td>165</td>\n",
       "      <td>(-95.93112474333331, 41.266643856666676)</td>\n",
       "      <td>129.160797</td>\n",
       "      <td>SE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                park_name  \\\n",
       "0                        BayCare Ballpark   \n",
       "1  Binghamton University Baseball Stadium   \n",
       "2                     Bob Bennett Stadium   \n",
       "3      Bob Warn Field at Sycamore Stadium   \n",
       "4                    Charles Schwab Field   \n",
       "\n",
       "                                                foul  \\\n",
       "0  [(-82.7319934, 27.9713686), (-82.7319914, 27.9...   \n",
       "1  [(-75.9744521, 42.0939984), (-75.9747317, 42.0...   \n",
       "2  [(-119.7560656, 36.8138062), (-119.7549411, 36...   \n",
       "3  [(-87.4163934, 39.4786282), (-87.4164034, 39.4...   \n",
       "4  [(-95.93202390000002, 41.2671943), (-95.930798...   \n",
       "\n",
       "                                                 fop notes  \\\n",
       "0  [(-82.7319934, 27.9713686), (-82.7309761, 27.9...  None   \n",
       "1  [(-75.9744521, 42.0939984), (-75.9732887, 42.0...  None   \n",
       "2  [(-119.7560656, 36.8138062), (-119.7560716, 36...  None   \n",
       "3  [(-87.4163934, 39.4786282), (-87.4152152, 39.4...  None   \n",
       "4  [(-95.93202390000002, 41.2671943), (-95.932004...  None   \n",
       "\n",
       "                         home_plate  foul_area_sqft  fop_area_sqft  \\\n",
       "0         (-82.7319934, 27.9713686)    22578.905659  103478.725629   \n",
       "1         (-75.9744521, 42.0939984)    27367.812527  100508.745834   \n",
       "2        (-119.7560656, 36.8138062)    28895.424648  102732.414339   \n",
       "3         (-87.4163934, 39.4786282)    31712.602869  104193.618959   \n",
       "4  (-95.93202390000002, 41.2671943)    29845.574280  108845.278059   \n",
       "\n",
       "   field_area_sqft  foul_area_per  fair_to_foul  \\\n",
       "0    126057.631288       0.179116      4.582982   \n",
       "1    127876.558360       0.214017      3.672517   \n",
       "2    131627.838987       0.219524      3.555318   \n",
       "3    135906.221828       0.233342      3.285559   \n",
       "4    138690.852339       0.215195      3.646949   \n",
       "\n",
       "                                           distances  max_distance  \\\n",
       "0  [328, 328, 328, 328, 328, 328, 328, 328, 328, ...           411   \n",
       "1  [324, 324, 324, 324, 324, 324, 324, 324, 324, ...           394   \n",
       "2  [331, 331, 331, 331, 331, 331, 331, 331, 331, ...           400   \n",
       "3  [332, 332, 332, 332, 332, 332, 332, 332, 332, ...           397   \n",
       "4  [333, 333, 333, 333, 333, 333, 333, 333, 333, ...           409   \n",
       "\n",
       "   min_distance  avg_distance  median_distance  corner_sharpness  \\\n",
       "0           328    366.090741            364.0               172   \n",
       "1           324    358.872222            358.0               142   \n",
       "2           328    362.298148            360.5               145   \n",
       "3           332    365.172222            365.0               135   \n",
       "4           333    372.203704            370.0               165   \n",
       "\n",
       "                               fop_centroid  field_orientation  \\\n",
       "0  (-82.73140348571428, 27.971967085714287)          41.040438   \n",
       "1   (-75.97392160000001, 42.09464799999999)          31.215416   \n",
       "2  (-119.75520886666668, 36.81334199166667)         124.089705   \n",
       "3  (-87.41569657142857, 39.479177671428566)          44.387589   \n",
       "4  (-95.93112474333331, 41.266643856666676)         129.160797   \n",
       "\n",
       "  field_cardinal_direction  \n",
       "0                       NE  \n",
       "1                       NE  \n",
       "2                       SE  \n",
       "3                       NE  \n",
       "4                       SE  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 park_name      score\n",
      "22                   Russ Chandler Stadium   7.358562\n",
      "1   Binghamton University Baseball Stadium   5.739022\n",
      "7               Durham Bulls Athletic Park   5.102633\n",
      "18     Penn - Meiklejohn Stadium - college   4.648396\n",
      "2                      Bob Bennett Stadium   3.447884\n",
      "25                       The Diamond - VCU   2.922743\n",
      "12                     Joe Miller Ballpark   2.723356\n",
      "0                         BayCare Ballpark   2.141326\n",
      "8              Fluor Field Greenville, S.C   2.101599\n",
      "3       Bob Warn Field at Sycamore Stadium   1.910265\n",
      "17  Olga Mural Field at Schoonover Stadium   1.578771\n",
      "19                             Prasco Park   0.904803\n",
      "13      Johnson Stadium at Doubleday Field   0.525816\n",
      "21                       Riverwalk Stadium   0.074531\n",
      "5                           Clover Stadium   0.037347\n",
      "20                           Reckling Park  -0.144675\n",
      "26                            Truist Point  -0.232674\n",
      "6                              Conrad Park  -1.294103\n",
      "14                      Las Vegas Ballpark  -1.818362\n",
      "9                  Heritage Financial Park  -2.023494\n",
      "4                     Charles Schwab Field  -2.278406\n",
      "15               Marion Park - Mt Dew Park  -2.903120\n",
      "16                       Nischwitz Stadium  -3.410260\n",
      "11             Hoover Metropolitan Stadium  -3.544662\n",
      "24          The Ballpark at Patriots Point  -5.774033\n",
      "10                         Hohokam Stadium  -6.289714\n",
      "23                      Scottsdale Stadium -11.503551\n"
     ]
    }
   ],
   "source": [
    "### THIS BLOCK CREATES THE RANKING OF PITCHER VS HITTER FRIENDLY FIELDS\n",
    "def rank_fields(data):\n",
    "    # Define weights for each parameter\n",
    "    weights = {\n",
    "        'max_distance': -1, # negative weight since longer fences favor pitchers\n",
    "        'min_distance': 1,  # positive weight since shorter fences favor hitters\n",
    "        'avg_distance': -1, # negative weight since longer fences favor pitchers\n",
    "        'median_distance': -1, # negative weight since longer fences favor pitchers\n",
    "        'field_area_sqft': -1,  # negative weight since larger fields favor pitchers\n",
    "        'fair_to_foul': -1,  # negative weight since larger ratio (more foul territory) favors pitchers\n",
    "        'foul_area_sqft': -1, # negative weight since larger foul area favors pitchers\n",
    "        'fop_area_sqft': -1, # negative weight since larger out of play area favors pitchers\n",
    "    }\n",
    "\n",
    "    # Standardize features (subtract mean and divide by standard deviation)\n",
    "    standardized_data = data.copy()\n",
    "    for column in weights.keys():\n",
    "        standardized_data[column] = (standardized_data[column] - standardized_data[column].mean()) / standardized_data[column].std()\n",
    "\n",
    "    # Calculate score for each field\n",
    "    standardized_data['score'] = standardized_data.apply(lambda row: sum(row[param] * weight for param, weight in weights.items()), axis=1)\n",
    "\n",
    "    # Save scores to original dataframe\n",
    "    data['score'] = standardized_data['score']\n",
    "\n",
    "    # Rank fields based on score (higher scores are more hitter-friendly)\n",
    "    ranked_fields = data.sort_values('score', ascending=False)\n",
    "\n",
    "    return ranked_fields\n",
    "\n",
    "# Suppose 'df' is your DataFrame containing the field data\n",
    "df = rank_fields(df_cleaned)\n",
    "print(df[['park_name', 'score']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working to here: fields are loaded and calcs are done. Need to merge in data after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27 entries, 22 to 23\n",
      "Data columns (total 20 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   park_name                 27 non-null     object \n",
      " 1   foul                      27 non-null     object \n",
      " 2   fop                       27 non-null     object \n",
      " 3   notes                     0 non-null      object \n",
      " 4   home_plate                27 non-null     object \n",
      " 5   foul_area_sqft            27 non-null     float64\n",
      " 6   fop_area_sqft             27 non-null     float64\n",
      " 7   field_area_sqft           27 non-null     float64\n",
      " 8   foul_area_per             27 non-null     float64\n",
      " 9   fair_to_foul              27 non-null     float64\n",
      " 10  distances                 27 non-null     object \n",
      " 11  max_distance              27 non-null     int64  \n",
      " 12  min_distance              27 non-null     int64  \n",
      " 13  avg_distance              27 non-null     float64\n",
      " 14  median_distance           27 non-null     float64\n",
      " 15  corner_sharpness          27 non-null     int32  \n",
      " 16  fop_centroid              27 non-null     object \n",
      " 17  field_orientation         27 non-null     float64\n",
      " 18  field_cardinal_direction  27 non-null     object \n",
      " 19  score                     27 non-null     float64\n",
      "dtypes: float64(9), int32(1), int64(2), object(8)\n",
      "memory usage: 4.3+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   college division  30 non-null     object \n",
      " 1   conference        30 non-null     object \n",
      " 2   Column2           0 non-null      float64\n",
      " 3   Column1           0 non-null      float64\n",
      " 4   code              30 non-null     object \n",
      " 5   list of schools   30 non-null     object \n",
      " 6   conference_2      29 non-null     object \n",
      " 7   date_range        29 non-null     object \n",
      " 8   host_raw          28 non-null     object \n",
      " 9   final game info   28 non-null     object \n",
      " 10  coords            29 non-null     object \n",
      " 11  park_name         27 non-null     object \n",
      "dtypes: float64(2), object(10)\n",
      "memory usage: 2.9+ KB\n"
     ]
    }
   ],
   "source": [
    "## Open the CSV file with the conference names\n",
    "conf_df = pd.read_csv('data/NCAA_D1/site_table.csv')\n",
    "\n",
    "df.info()\n",
    "conf_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 0 to 29\n",
      "Data columns (total 31 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   park_name                 27 non-null     object \n",
      " 1   foul                      27 non-null     object \n",
      " 2   fop                       27 non-null     object \n",
      " 3   notes                     0 non-null      object \n",
      " 4   home_plate                27 non-null     object \n",
      " 5   foul_area_sqft            27 non-null     float64\n",
      " 6   fop_area_sqft             27 non-null     float64\n",
      " 7   field_area_sqft           27 non-null     float64\n",
      " 8   foul_area_per             27 non-null     float64\n",
      " 9   fair_to_foul              27 non-null     float64\n",
      " 10  distances                 27 non-null     object \n",
      " 11  max_distance              27 non-null     float64\n",
      " 12  min_distance              27 non-null     float64\n",
      " 13  avg_distance              27 non-null     float64\n",
      " 14  median_distance           27 non-null     float64\n",
      " 15  corner_sharpness          27 non-null     float64\n",
      " 16  fop_centroid              27 non-null     object \n",
      " 17  field_orientation         27 non-null     float64\n",
      " 18  field_cardinal_direction  27 non-null     object \n",
      " 19  score                     27 non-null     float64\n",
      " 20  college division          30 non-null     object \n",
      " 21  conference                30 non-null     object \n",
      " 22  Column2                   0 non-null      float64\n",
      " 23  Column1                   0 non-null      float64\n",
      " 24  code                      30 non-null     object \n",
      " 25  list of schools           30 non-null     object \n",
      " 26  conference_2              29 non-null     object \n",
      " 27  date_range                29 non-null     object \n",
      " 28  host_raw                  28 non-null     object \n",
      " 29  final game info           28 non-null     object \n",
      " 30  coords                    29 non-null     object \n",
      "dtypes: float64(14), object(17)\n",
      "memory usage: 7.5+ KB\n"
     ]
    }
   ],
   "source": [
    "## Merge the two dataframes\n",
    "\n",
    "df = pd.merge(df, conf_df, on='park_name', how='outer')\n",
    "\n",
    "df.info()\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()\n",
    "# df.to_csv('TEMP/TEMP.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop rows that don't have any field coordinate data because that breaks the map\n",
    "df = df.dropna(subset=['foul', 'fop', 'home_plate'])\n",
    "\n",
    "filenames = ['america-east-conference.png', 'american-athletic-conference.png', 'atlantic-10-conference.png', 'atlantic-coast-conference.png', 'atlantic-sun-conference.png', 'big-12-conference.png', 'big-east-conference.png', 'big-south-conference.png', 'big-ten-conference.png', 'big-west-conference.png', 'colonial-athletic-association.png', 'conference-usa.png', 'horizon-league.png', 'ivy-league.png', 'metro-atlantic-athletic-conference.png', 'mid-american-conference.png', 'missouri-valley-conference.png', 'mountain-west-conference.png', 'northeast-conference.png', 'ohio-valley-conference.png', 'pacific-12-conference.png', 'patriot-league.png', 'southeastern-conference.png', 'southern-conference.png', 'southland-conference.png', 'southwest-athletic-conference.png', 'summit-league.png', 'sun-belt-conference.png', 'west-coast-conference.png', 'western-athletic-conference.png']\n",
    "\n",
    "# Create a dictionary to map conference names to filenames\n",
    "file_dict = {name.replace(\"-\", \" \").replace(\".png\", \"\").title() : name for name in filenames}\n",
    "\n",
    "# Your DataFrame\n",
    "# df = pd.DataFrame({\n",
    "#     'Conference': ['Southwest Athletic Conference', 'America East Conference', 'Atlantic Coast Conference', 'Mountain West Conference', 'Atlantic 10 Conference', 'Southland Conference', 'American Athletic Conference', 'Missouri Valley Conference', 'Southern Conference', 'Mid-American Conference', 'Big East Conference', 'Patriot League', 'Big South Conference', 'Conference USA', 'Sun Belt Conference', 'Metro Atlantic Athletic Conference', 'Atlantic Sun Conference', 'West Coast Conference', 'Northeast Conference', 'Big Ten Conference', 'Ohio Valley Conference', 'Southeastern Conference', 'Horizon League', 'Western Athletic Conference', 'Colonial Athletic Association', 'Pacific-12 Conference']\n",
    "# })\n",
    "\n",
    "# Map the conference names to the filenames\n",
    "df['filename'] = df['conference'].map(file_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     27.000000\n",
       "mean     404.518519\n",
       "std       10.150295\n",
       "min      384.000000\n",
       "25%      399.500000\n",
       "50%      403.000000\n",
       "75%      412.000000\n",
       "max      432.000000\n",
       "Name: max_distance, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['max_distance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 27/27 [00:54<00:00,  2.03s/it]\n"
     ]
    }
   ],
   "source": [
    "## Get Altitudes of the ballparks\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# Set your Google Maps API key here\n",
    "api_key = 'AIzaSyA_BhlTupRdBPBhRptQuR6pYorMVYQnRMA'\n",
    "\n",
    "# Get the altitude of a location from its latitude and longitude\n",
    "def get_altitude(lat, lon):\n",
    "    query = f'https://maps.googleapis.com/maps/api/elevation/json?locations={lat},{lon}&key={api_key}'\n",
    "    r = requests.get(query).json()\n",
    "    elevation = r['results'][0]['elevation']\n",
    "    return elevation\n",
    "\n",
    "# Get the city and state of a location from its latitude and longitude\n",
    "def get_city_state(lat, lon):\n",
    "    query = f'https://maps.googleapis.com/maps/api/geocode/json?latlng={lat},{lon}&key={api_key}'\n",
    "    r = requests.get(query).json()\n",
    "    results = r['results'][0]['address_components']\n",
    "    city = next((item['long_name'] for item in results if 'locality' in item['types']), '')\n",
    "    state = next((item['long_name'] for item in results if 'administrative_area_level_1' in item['types']), '')\n",
    "    return city, state\n",
    "\n",
    "# Initialize empty lists for the new columns\n",
    "altitudes = []\n",
    "cities = []\n",
    "states = []\n",
    "\n",
    "# Loop through each row in the dataframe\n",
    "for coords in tqdm(df['home_plate']):\n",
    "    # Get altitude and add to list\n",
    "    altitude = get_altitude(coords[1], coords[0])\n",
    "    altitudes.append(altitude)\n",
    "\n",
    "    # Get city and state and add to lists\n",
    "    city, state = get_city_state(coords[1], coords[0])\n",
    "    cities.append(city)\n",
    "    states.append(state)\n",
    "\n",
    "    # Sleep for a bit to avoid hitting rate limits\n",
    "    time.sleep(1)  # Adjust this value as needed\n",
    "\n",
    "# Add the new columns to the dataframe\n",
    "df['altitude'] = altitudes\n",
    "df['city'] = cities\n",
    "df['state'] = states\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()\n",
    "# df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This version of the function accepts an additional argument, weights, which is a dictionary containing weights for each factor. These weights are used when calculating the hr_friendliness and old_school_friendliness scores.\n",
    "\n",
    "The pros of assigning different weights to different factors include:\n",
    "\n",
    "It allows for customization and fine-tuning of the scoring system based on specific needs or knowledge. For example, if you believe altitude has a bigger impact on home run friendliness than the average distance, you can reflect this in the weights.\n",
    "\n",
    "It provides a way to emphasize or de-emphasize certain factors based on their perceived importance or relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def rate_fields(df, weights):\n",
    "    # Copy original values to new columns\n",
    "    df[['original_foul_area_sqft', 'original_fop_area_sqft', 'original_fair_to_foul', 'original_max_distance', 'original_min_distance', 'original_avg_distance', 'original_median_distance', 'original_corner_sharpness', 'original_field_orientation', 'original_altitude']] = df[['foul_area_sqft', 'fop_area_sqft', 'fair_to_foul', 'max_distance', 'min_distance', 'avg_distance', 'median_distance', 'corner_sharpness', 'field_orientation', 'altitude']]\n",
    "\n",
    "    # Normalize the data\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    df[['foul_area_sqft', 'fop_area_sqft', 'fair_to_foul', 'max_distance', 'min_distance', 'avg_distance', 'median_distance', 'corner_sharpness', 'field_orientation', 'altitude']] = min_max_scaler.fit_transform(df[['foul_area_sqft', 'fop_area_sqft', 'fair_to_foul', 'max_distance', 'min_distance', 'avg_distance', 'median_distance', 'corner_sharpness', 'field_orientation', 'altitude']])\n",
    "    \n",
    "\n",
    "    # Weighted score for home run friendliness\n",
    "    df['hr_friendliness'] = weights['foul_area_sqft']*df['foul_area_sqft'] + weights['fair_to_foul']*df['fair_to_foul'] - weights['max_distance']*df['max_distance'] - weights['avg_distance']*df['avg_distance'] - weights['median_distance']*df['median_distance'] + weights['altitude']*df['altitude']\n",
    "\n",
    "    # Weighted score for old-school friendliness\n",
    "    df['old_school_friendliness'] = weights['fop_area_sqft']*df['fop_area_sqft'] + weights['max_distance']*df['max_distance'] + weights['avg_distance']*df['avg_distance'] + weights['median_distance']*df['median_distance'] + weights['corner_sharpness']*df['corner_sharpness'] - weights['altitude']*df['altitude']\n",
    "\n",
    "    # Field uniqueness score based on variance from mean values\n",
    "    mean_values = df[['foul_area_sqft', 'fop_area_sqft', 'fair_to_foul', 'max_distance', 'min_distance', 'avg_distance', 'median_distance', 'corner_sharpness', 'field_orientation', 'altitude']].mean()\n",
    "    df['uniqueness_score'] = df[['foul_area_sqft', 'fop_area_sqft', 'fair_to_foul', 'max_distance', 'min_distance', 'avg_distance', 'median_distance', 'corner_sharpness', 'field_orientation', 'altitude']].apply(lambda row: sum(abs(row - mean_values)), axis=1)\n",
    "\n",
    "      # Remove the normalized columns, restoring the original values\n",
    "    df[['foul_area_sqft', 'fop_area_sqft', 'fair_to_foul', 'max_distance', 'min_distance', 'avg_distance', 'median_distance', 'corner_sharpness', 'field_orientation', 'altitude']] = df[['original_foul_area_sqft', 'original_fop_area_sqft', 'original_fair_to_foul', 'original_max_distance', 'original_min_distance', 'original_avg_distance', 'original_median_distance', 'original_corner_sharpness', 'original_field_orientation', 'original_altitude']]\n",
    "    \n",
    "    # Remove the temporary columns storing the original values\n",
    "    df = df.drop(columns=['original_foul_area_sqft', 'original_fop_area_sqft', 'original_fair_to_foul', 'original_max_distance', 'original_min_distance', 'original_avg_distance', 'original_median_distance', 'original_corner_sharpness', 'original_field_orientation', 'original_altitude'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "weights = {'foul_area_sqft': 1, 'fop_area_sqft': 1, 'fair_to_foul': 1, 'max_distance': 1, 'min_distance': 1, 'avg_distance': 1, 'median_distance': 1, 'corner_sharpness': 1, 'field_orientation': 1, 'altitude': 1}\n",
    "\n",
    "df = rate_fields(df, weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Output the Files as a JSON and as a csv for review\n",
    "\n",
    "df.to_csv('data/NCAA_D1/conf_tourn_map.csv', index=False)\n",
    "\n",
    "df.to_json('data/NCAA_D1/conf_tourn_map.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()\n",
    "\n",
    "df['uniqueness_score'].hist(bins=20)\n",
    "# df['hr_friendliness'].hist(bins=20)\n",
    "# df['old_school_friendliness'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a plot of the uniqueness score and the hr friendliness score\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.scatter(df['uniqueness_score'], df['hr_friendliness'])\n",
    "# plt.xlabel('Uniqueness Score')\n",
    "# plt.ylabel('Home Run Friendliness Score')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['altitude'].describe()\n",
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END LOADING BLOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## list conference names\n",
    "df['conference'].unique()\n",
    "\n",
    "## print filemname column\n",
    "df['filename'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Your list of filenames\n",
    "filenames = ['america-east-conference.png', 'american-athletic-conference.png', 'atlantic-10-conference.png', 'atlantic-coast-conference.png', 'atlantic-sun-conference.png', 'big-12-conference.png', 'big-east-conference.png', 'big-south-conference.png', 'big-ten-conference.png', 'big-west-conference.png', 'colonial-athletic-association.png', 'conference-usa.png', 'horizon-league.png', 'ivy-league.png', 'metro-atlantic-athletic-conference.png', 'mid-american-conference.png', 'missouri-valley-conference.png', 'mountain-west-conference.png', 'northeast-conference.png', 'ohio-valley-conference.png', 'pacific-12-conference.png', 'patriot-league.png', 'southeastern-conference.png', 'southern-conference.png', 'southland-conference.png', 'southwest-athletic-conference.png', 'summit-league.png', 'sun-belt-conference.png', 'west-coast-conference.png', 'western-athletic-conference.png']\n",
    "\n",
    "# Create a dictionary to map conference names to filenames\n",
    "file_dict = {name.replace(\"-\", \" \").replace(\".png\", \"\").title() : name for name in filenames}\n",
    "\n",
    "# Your DataFrame\n",
    "# df = pd.DataFrame({\n",
    "#     'Conference': ['Southwest Athletic Conference', 'America East Conference', 'Atlantic Coast Conference', 'Mountain West Conference', 'Atlantic 10 Conference', 'Southland Conference', 'American Athletic Conference', 'Missouri Valley Conference', 'Southern Conference', 'Mid-American Conference', 'Big East Conference', 'Patriot League', 'Big South Conference', 'Conference USA', 'Sun Belt Conference', 'Metro Atlantic Athletic Conference', 'Atlantic Sun Conference', 'West Coast Conference', 'Northeast Conference', 'Big Ten Conference', 'Ohio Valley Conference', 'Southeastern Conference', 'Horizon League', 'Western Athletic Conference', 'Colonial Athletic Association', 'Pacific-12 Conference']\n",
    "# })\n",
    "\n",
    "# Map the conference names to the filenames\n",
    "df['Filename'] = df['conference'].map(file_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add files list to the dataframe as icon paths\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
