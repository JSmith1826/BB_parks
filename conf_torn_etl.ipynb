{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ETL NOTEBOOK FOR 2023 MHSAA TOURNEY SPECIFIC MAP\n",
    "\n",
    "#### Adapted from ETL for JSON\n",
    "\n",
    "## Dependencies and Setup\n",
    "### Dependencies\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "## Start timer\n",
    "start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD BLOCK###\n",
    "#### Load data from kml file exported from Google Earth\n",
    "\n",
    "file_path = ('data/kml/conf_tourny.kml') # file path to kml file\n",
    "\n",
    "\n",
    "# Read the KML file\n",
    "with open(file_path) as file:\n",
    "    xml_data = file.read()\n",
    "\n",
    "# Initialize soup variables for parsing file\n",
    "soup = BeautifulSoup(xml_data, 'xml')\n",
    "folders = soup.Document\n",
    "list = soup.Document.find_all('Folder')\n",
    "\n",
    "# Create a list to store rows to append to the DataFrame\n",
    "rows = []\n",
    "\n",
    "# Loop through the folders and extract the data\n",
    "for folder in list:\n",
    "    try:\n",
    "        field_name = folder.find('name').text\n",
    "        foul = folder.find_all('coordinates')[0].text\n",
    "        fop = folder.find_all('coordinates')[1].text\n",
    "        notes = None\n",
    "\n",
    "        # Check if there is a description tag, if so, use it for notes\n",
    "        if folder.find('description') is not None:\n",
    "            notes = folder.find('description').text\n",
    "\n",
    "        row = {\n",
    "            'field': field_name,\n",
    "            'foul': foul,\n",
    "            'fop': fop,\n",
    "            'notes': notes\n",
    "        }\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Add name of folder to a list of failed folders\n",
    "        failed.append(folder.find('name').text)\n",
    "        print(f\"Error processing folder: {folder.find('name').text}. Error message: {str(e)}\")\n",
    "\n",
    "# Convert the list of rows to a DataFrame\n",
    "df = pd.DataFrame(rows, columns=['field', 'foul', 'fop', 'notes'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the new dataframe\n",
    "\n",
    "\n",
    "# Create a copy of the original DataFrame\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "# Remove new line and space characters from coordinates\n",
    "df_cleaned = df_cleaned.replace(r'\\n','', regex=True) \n",
    "df_cleaned = df_cleaned.replace(r'\\t','', regex=True) \n",
    "\n",
    "# Drop any duplicate rows\n",
    "df_cleaned = df_cleaned.drop_duplicates(subset=['field'], keep='first')\n",
    "\n",
    "# Drop any rows with empty fields\n",
    "df_cleaned = df_cleaned[(df_cleaned != 0).all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Clean up polygon data and create a new home_plate column\n",
    "\n",
    "def parse_coordinates(coord_string):\n",
    "    coords = coord_string.split()\n",
    "    parsed_coords = [tuple(map(float, coord.split(',')[:2])) for coord in coords]\n",
    "    return parsed_coords\n",
    "\n",
    "# Create a new column for the home_plate location using the first set of coordinates in the 'fop' column\n",
    "df_cleaned['home_plate'] = df_cleaned['fop'].apply(lambda x: parse_coordinates(x)[0])\n",
    "\n",
    "# Apply the parse_coordinates function to the 'foul' and 'fop' columns\n",
    "df_cleaned['foul'] = df_cleaned['foul'].apply(parse_coordinates)\n",
    "df_cleaned['fop'] = df_cleaned['fop'].apply(parse_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## AREA CALCULATION ##############\n",
    "\n",
    "\n",
    "import pyproj\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import transform\n",
    "\n",
    "\n",
    "def calculate_area(coords):\n",
    "    # Create a Polygon object from the coordinates\n",
    "    polygon = Polygon(coords)\n",
    "\n",
    "    # Calculate the centroid of the polygon\n",
    "    centroid = polygon.centroid\n",
    "\n",
    "    # Create a custom LAEA projection centered on the centroid\n",
    "    custom_projection = f\"+proj=laea +lat_0={centroid.y} +lon_0={centroid.x} +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs\"\n",
    "\n",
    "    # Create a transformer for converting coordinates to the custom LAEA projection\n",
    "    transformer = pyproj.Transformer.from_crs(\n",
    "        pyproj.CRS(\"EPSG:4326\"),  # WGS 84 (latitude and longitude)\n",
    "        pyproj.CRS(custom_projection),  # Custom LAEA projection\n",
    "        always_xy=True\n",
    "    )\n",
    "\n",
    "    # Define a function to transform coordinates using the transformer\n",
    "    def transform_coordinates(x, y):\n",
    "        return transformer.transform(x, y)\n",
    "\n",
    "    # Convert the coordinates to the custom LAEA projection\n",
    "    polygon_laea = transform(transform_coordinates, polygon)\n",
    "\n",
    "    # Calculate the area in square meters\n",
    "    area_sqm = polygon_laea.area\n",
    "\n",
    "    # Convert the area to square feet (1 square meter = 10.764 square feet)\n",
    "    area_sqft = area_sqm * 10.764\n",
    "\n",
    "    return area_sqft\n",
    "\n",
    "\n",
    "\n",
    "### Call Function and add to dataframe\n",
    "df_cleaned['foul_area_sqft'] = df_cleaned['foul'].apply(calculate_area)\n",
    "df_cleaned['fop_area_sqft'] = df_cleaned['fop'].apply(calculate_area)\n",
    "\n",
    "## Calculate the total area of the field and the ratio of foul area to field area\n",
    "df_cleaned['field_area_sqft'] = df_cleaned['foul_area_sqft'] + df_cleaned['fop_area_sqft']\n",
    "## Percentage foul area\n",
    "df_cleaned['foul_area_per'] = df_cleaned['foul_area_sqft'] / df_cleaned['field_area_sqft']\n",
    "## Fair to Foul Ratio\n",
    "df_cleaned['fair_to_foul'] = df_cleaned['fop_area_sqft'] / df_cleaned['foul_area_sqft']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# FENCE DISTANCE CALCULATION #############\n",
    "\n",
    "from geopy.distance import great_circle\n",
    "import numpy as np\n",
    "\n",
    "def interpolate_points(start, end, length_ratio):\n",
    "    start_np = np.array(start)\n",
    "    end_np = np.array(end)\n",
    "    return tuple(start_np + (end_np - start_np) * length_ratio)\n",
    "\n",
    "def calculate_distances(home_plate, outfield_coords, num_points=540):\n",
    "    def is_same_point(point1, point2, tolerance=1e-6):\n",
    "        return abs(point1[0] - point2[0]) < tolerance and abs(point1[1] - point2[1]) < tolerance\n",
    "\n",
    "    home_plate_lat_lon = (home_plate[1], home_plate[0])\n",
    "    distances = []\n",
    "\n",
    "    # Calculate total line length\n",
    "    total_length = 0\n",
    "    segments = []\n",
    "    for i in range(len(outfield_coords) - 1):\n",
    "        start = outfield_coords[i]\n",
    "        end = outfield_coords[i + 1]\n",
    "        if not is_same_point(home_plate, start) and not is_same_point(home_plate, end):\n",
    "            segment_length = great_circle((start[1], start[0]), (end[1], end[0])).feet\n",
    "            segments.append((start, end, segment_length))\n",
    "            total_length += segment_length\n",
    "\n",
    "    # Calculate the distance between equally spaced points\n",
    "    spacing = total_length / (num_points - 1)\n",
    "\n",
    "    # Interpolate points and calculate distances\n",
    "    current_length = 0\n",
    "    segment_index = 0\n",
    "    for i in range(num_points):\n",
    "        while segment_index < len(segments) - 1 and current_length > segments[segment_index][2]:\n",
    "            current_length -= segments[segment_index][2]\n",
    "            segment_index += 1\n",
    "\n",
    "        start, end, segment_length = segments[segment_index]\n",
    "        length_ratio = current_length / segment_length\n",
    "        point = interpolate_points(start, end, length_ratio)\n",
    "        distance = round(great_circle(home_plate_lat_lon, (point[1], point[0])).feet)\n",
    "        distances.append(distance)\n",
    "\n",
    "        current_length += spacing\n",
    "\n",
    "    return distances\n",
    "\n",
    "# Calculate distances for each row\n",
    "df_cleaned['distances'] = df_cleaned.apply(lambda row: calculate_distances(row['home_plate'], row['fop']), axis=1)\n",
    "\n",
    "# Calculate max, min, and average distances for each row\n",
    "df_cleaned['max_distance'] = df_cleaned['distances'].apply(max)\n",
    "df_cleaned['min_distance'] = df_cleaned['distances'].apply(min)\n",
    "df_cleaned['avg_distance'] = df_cleaned['distances'].apply(lambda distances: sum(distances) / len(distances))\n",
    "# get the median distance\n",
    "df_cleaned['median_distance'] = df_cleaned['distances'].apply(lambda distances: np.median(distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to create ranks for each column\n",
    "\n",
    "def rank_fields(df):\n",
    "    # Calculate the rank for each category\n",
    "    df['max_distance_rank'] = df['max_distance'].rank(ascending=False, method='min')\n",
    "    df['min_distance_rank'] = df['min_distance'].rank(ascending=False, method='min')\n",
    "    df['avg_distance_rank'] = df['avg_distance'].rank(ascending=False, method='min')\n",
    "    df['median_distance_rank'] = df['median_distance'].rank(ascending=False, method='min')\n",
    "    df['field_area_rank'] = df['field_area_sqft'].rank(ascending=False, method='min')\n",
    "    df['foul_area_rank'] = df['foul_area_sqft'].rank(ascending=False, method='min')\n",
    "    df['fop_area_per_rank'] = df['fop_area_sqft'].rank(ascending=False, method='min')\n",
    "    df['ratio_rank'] = df['fair_to_foul'].rank(ascending=False, method='min')\n",
    "\n",
    "    return df\n",
    "\n",
    "## Run Function\n",
    "\n",
    "df_cleaned = rank_fields(df_cleaned)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Orienting the map to the home plate location ####\n",
    "\n",
    "### Find the center of the field\n",
    "def calculate_centroid(coords):\n",
    "    x_coords = [coord[0] for coord in coords]\n",
    "    y_coords = [coord[1] for coord in coords]\n",
    "    centroid_x = sum(x_coords) / len(coords)\n",
    "    centroid_y = sum(y_coords) / len(coords)\n",
    "    return (centroid_x, centroid_y)\n",
    "\n",
    "\n",
    "## Find the bearing between the home plate and the center of the field\n",
    "import math\n",
    "\n",
    "def calculate_bearing(point1, point2):\n",
    "    lat1, lon1 = math.radians(point1[1]), math.radians(point1[0])\n",
    "    lat2, lon2 = math.radians(point2[1]), math.radians(point2[0])\n",
    "\n",
    "    d_lon = lon2 - lon1\n",
    "\n",
    "    x = math.cos(lat2) * math.sin(d_lon)\n",
    "    y = math.cos(lat1) * math.sin(lat2) - math.sin(lat1) * math.cos(lat2) * math.cos(d_lon)\n",
    "\n",
    "    bearing = math.degrees(math.atan2(x, y))\n",
    "    bearing = (bearing + 360) % 360  # Normalize the bearing to the range [0, 360)\n",
    "\n",
    "    return bearing\n",
    "\n",
    "### Function to classify direction in laymans terms North, South, East, West, ect\n",
    "def degrees_to_cardinal_direction(degrees):\n",
    "    directions = ['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW', 'N']\n",
    "    index = round(degrees / 45)\n",
    "    return directions[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the centroid of the outfield fence coordinates for each row\n",
    "df_cleaned['fop_centroid'] = df_cleaned['fop'].apply(lambda coords: calculate_centroid(coords[1:]))\n",
    "\n",
    "# Calculate the bearing between home plate and the centroid for each row\n",
    "df_cleaned['field_orientation'] = df_cleaned.apply(lambda row: calculate_bearing(row['home_plate'], row['fop_centroid']), axis=1)\n",
    "\n",
    "# Convert the bearing to a cardinal direction\n",
    "df_cleaned['field_cardinal_direction'] = df_cleaned['field_orientation'].apply(degrees_to_cardinal_direction)\n",
    "\n",
    "# rename 'field' to 'park_name'\n",
    "df_cleaned.rename(columns={'field': 'park_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 park_name      score\n",
      "12                   Russ Chandler Stadium   7.992146\n",
      "15  Binghamton University Baseball Stadium   6.134127\n",
      "18              Durham Bulls Athletic Park   5.035419\n",
      "25                     Bob Bennett Stadium   3.848177\n",
      "17                       The Diamond - VCU   3.326890\n",
      "11                     Joe Miller Ballpark   3.166903\n",
      "16                        BayCare Ballpark   2.443897\n",
      "5       Bob Warn Field at Sycamore Stadium   2.370159\n",
      "10             Fluor Field Greenville, S.C   1.799821\n",
      "2   Olga Mural Field at Schoonover Stadium   1.596515\n",
      "20                             Prasco Park   0.963038\n",
      "3       Johnson Stadium at Doubleday Field   0.735563\n",
      "21                            Truist Point   0.201779\n",
      "23                           Reckling Park   0.133616\n",
      "13                       Riverwalk Stadium   0.004898\n",
      "24                          Clover Stadium  -0.135177\n",
      "19                             Conrad Park  -0.872847\n",
      "14                      Las Vegas Ballpark  -1.422850\n",
      "6                  Heritage Financial Park  -1.878109\n",
      "0                     Charles Schwab Field  -1.980002\n",
      "7                Marion Park - Mt Dew Park  -2.982428\n",
      "9              Hoover Metropolitan Stadium  -3.185589\n",
      "4                        Nischwitz Stadium  -3.308929\n",
      "1                          Hohokam Stadium  -5.916982\n",
      "22          The Ballpark at Patriots Point  -6.363698\n",
      "8                       Scottsdale Stadium -11.706340\n"
     ]
    }
   ],
   "source": [
    "### THIS BLOCK CREATES THE RANKING OF PITCHER VS HITTER FRIENDLY FIELDS\n",
    "def rank_fields(data):\n",
    "    # Define weights for each parameter\n",
    "    weights = {\n",
    "        'max_distance': -1, # negative weight since longer fences favor pitchers\n",
    "        'min_distance': 1,  # positive weight since shorter fences favor hitters\n",
    "        'avg_distance': -1, # negative weight since longer fences favor pitchers\n",
    "        'median_distance': -1, # negative weight since longer fences favor pitchers\n",
    "        'field_area_sqft': -1,  # negative weight since larger fields favor pitchers\n",
    "        'fair_to_foul': -1,  # negative weight since larger ratio (more foul territory) favors pitchers\n",
    "        'foul_area_sqft': -1, # negative weight since larger foul area favors pitchers\n",
    "        'fop_area_sqft': -1, # negative weight since larger out of play area favors pitchers\n",
    "    }\n",
    "\n",
    "    # Standardize features (subtract mean and divide by standard deviation)\n",
    "    standardized_data = data.copy()\n",
    "    for column in weights.keys():\n",
    "        standardized_data[column] = (standardized_data[column] - standardized_data[column].mean()) / standardized_data[column].std()\n",
    "\n",
    "    # Calculate score for each field\n",
    "    standardized_data['score'] = standardized_data.apply(lambda row: sum(row[param] * weight for param, weight in weights.items()), axis=1)\n",
    "\n",
    "    # Save scores to original dataframe\n",
    "    data['score'] = standardized_data['score']\n",
    "\n",
    "    # Rank fields based on score (higher scores are more hitter-friendly)\n",
    "    ranked_fields = data.sort_values('score', ascending=False)\n",
    "\n",
    "    return ranked_fields\n",
    "\n",
    "# Suppose 'df' is your DataFrame containing the field data\n",
    "df = rank_fields(df_cleaned)\n",
    "print(df[['park_name', 'score']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working to here: fields are loaded and calcs are done. Need to merge in data after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Russ Chandler Stadium',\n",
       " 'Binghamton University Baseball Stadium',\n",
       " 'Durham Bulls Athletic Park',\n",
       " 'Bob Bennett Stadium',\n",
       " 'The Diamond - VCU',\n",
       " 'Joe Miller Ballpark',\n",
       " 'BayCare Ballpark',\n",
       " 'Bob Warn Field at Sycamore Stadium',\n",
       " 'Fluor Field Greenville, S.C',\n",
       " 'Olga Mural Field at Schoonover Stadium',\n",
       " 'Prasco Park',\n",
       " 'Johnson Stadium at Doubleday Field',\n",
       " 'Truist Point',\n",
       " 'Reckling Park',\n",
       " 'Riverwalk Stadium',\n",
       " 'Clover Stadium',\n",
       " 'Conrad Park',\n",
       " 'Las Vegas Ballpark',\n",
       " 'Heritage Financial Park',\n",
       " 'Charles Schwab Field',\n",
       " 'Marion Park - Mt Dew Park',\n",
       " 'Hoover Metropolitan Stadium',\n",
       " 'Nischwitz Stadium',\n",
       " 'Hohokam Stadium',\n",
       " 'The Ballpark at Patriots Point',\n",
       " 'Scottsdale Stadium']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Merge in the Name of the conference\n",
    "df['park_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26 entries, 12 to 8\n",
      "Data columns (total 27 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   park_name                 26 non-null     object \n",
      " 1   foul                      26 non-null     object \n",
      " 2   fop                       26 non-null     object \n",
      " 3   notes                     0 non-null      object \n",
      " 4   home_plate                26 non-null     object \n",
      " 5   foul_area_sqft            26 non-null     float64\n",
      " 6   fop_area_sqft             26 non-null     float64\n",
      " 7   field_area_sqft           26 non-null     float64\n",
      " 8   foul_area_per             26 non-null     float64\n",
      " 9   fair_to_foul              26 non-null     float64\n",
      " 10  distances                 26 non-null     object \n",
      " 11  max_distance              26 non-null     int64  \n",
      " 12  min_distance              26 non-null     int64  \n",
      " 13  avg_distance              26 non-null     float64\n",
      " 14  median_distance           26 non-null     float64\n",
      " 15  max_distance_rank         26 non-null     float64\n",
      " 16  min_distance_rank         26 non-null     float64\n",
      " 17  avg_distance_rank         26 non-null     float64\n",
      " 18  median_distance_rank      26 non-null     float64\n",
      " 19  field_area_rank           26 non-null     float64\n",
      " 20  foul_area_rank            26 non-null     float64\n",
      " 21  fop_area_per_rank         26 non-null     float64\n",
      " 22  ratio_rank                26 non-null     float64\n",
      " 23  fop_centroid              26 non-null     object \n",
      " 24  field_orientation         26 non-null     float64\n",
      " 25  field_cardinal_direction  26 non-null     object \n",
      " 26  score                     26 non-null     float64\n",
      "dtypes: float64(17), int64(2), object(8)\n",
      "memory usage: 5.7+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   college division  30 non-null     object \n",
      " 1   conference        30 non-null     object \n",
      " 2   Column2           0 non-null      float64\n",
      " 3   Column1           0 non-null      float64\n",
      " 4   code              30 non-null     object \n",
      " 5   list of schools   30 non-null     object \n",
      " 6   conference_2      29 non-null     object \n",
      " 7   date_range        29 non-null     object \n",
      " 8   host_raw          28 non-null     object \n",
      " 9   final game info   28 non-null     object \n",
      " 10  coords            29 non-null     object \n",
      " 11  park_name         27 non-null     object \n",
      "dtypes: float64(2), object(10)\n",
      "memory usage: 2.9+ KB\n"
     ]
    }
   ],
   "source": [
    "## Open the CSV file with the conference names\n",
    "conf_df = pd.read_csv('data/NCAA_D1/site_table.csv')\n",
    "\n",
    "df.info()\n",
    "conf_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 0 to 29\n",
      "Data columns (total 38 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   park_name                 27 non-null     object \n",
      " 1   foul                      26 non-null     object \n",
      " 2   fop                       26 non-null     object \n",
      " 3   notes                     0 non-null      object \n",
      " 4   home_plate                26 non-null     object \n",
      " 5   foul_area_sqft            26 non-null     float64\n",
      " 6   fop_area_sqft             26 non-null     float64\n",
      " 7   field_area_sqft           26 non-null     float64\n",
      " 8   foul_area_per             26 non-null     float64\n",
      " 9   fair_to_foul              26 non-null     float64\n",
      " 10  distances                 26 non-null     object \n",
      " 11  max_distance              26 non-null     float64\n",
      " 12  min_distance              26 non-null     float64\n",
      " 13  avg_distance              26 non-null     float64\n",
      " 14  median_distance           26 non-null     float64\n",
      " 15  max_distance_rank         26 non-null     float64\n",
      " 16  min_distance_rank         26 non-null     float64\n",
      " 17  avg_distance_rank         26 non-null     float64\n",
      " 18  median_distance_rank      26 non-null     float64\n",
      " 19  field_area_rank           26 non-null     float64\n",
      " 20  foul_area_rank            26 non-null     float64\n",
      " 21  fop_area_per_rank         26 non-null     float64\n",
      " 22  ratio_rank                26 non-null     float64\n",
      " 23  fop_centroid              26 non-null     object \n",
      " 24  field_orientation         26 non-null     float64\n",
      " 25  field_cardinal_direction  26 non-null     object \n",
      " 26  score                     26 non-null     float64\n",
      " 27  college division          30 non-null     object \n",
      " 28  conference                30 non-null     object \n",
      " 29  Column2                   0 non-null      float64\n",
      " 30  Column1                   0 non-null      float64\n",
      " 31  code                      30 non-null     object \n",
      " 32  list of schools           30 non-null     object \n",
      " 33  conference_2              29 non-null     object \n",
      " 34  date_range                29 non-null     object \n",
      " 35  host_raw                  28 non-null     object \n",
      " 36  final game info           28 non-null     object \n",
      " 37  coords                    29 non-null     object \n",
      "dtypes: float64(21), object(17)\n",
      "memory usage: 9.1+ KB\n"
     ]
    }
   ],
   "source": [
    "## Merge the two dataframes\n",
    "\n",
    "df = pd.merge(df, conf_df, on='park_name', how='outer')\n",
    "\n",
    "df.info()\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop rows that don't have any field coordinate data because that breaks the map\n",
    "df = df.dropna(subset=['foul', 'fop', 'home_plate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26 entries, 0 to 25\n",
      "Data columns (total 38 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   park_name                 26 non-null     object \n",
      " 1   foul                      26 non-null     object \n",
      " 2   fop                       26 non-null     object \n",
      " 3   notes                     0 non-null      object \n",
      " 4   home_plate                26 non-null     object \n",
      " 5   foul_area_sqft            26 non-null     float64\n",
      " 6   fop_area_sqft             26 non-null     float64\n",
      " 7   field_area_sqft           26 non-null     float64\n",
      " 8   foul_area_per             26 non-null     float64\n",
      " 9   fair_to_foul              26 non-null     float64\n",
      " 10  distances                 26 non-null     object \n",
      " 11  max_distance              26 non-null     float64\n",
      " 12  min_distance              26 non-null     float64\n",
      " 13  avg_distance              26 non-null     float64\n",
      " 14  median_distance           26 non-null     float64\n",
      " 15  max_distance_rank         26 non-null     float64\n",
      " 16  min_distance_rank         26 non-null     float64\n",
      " 17  avg_distance_rank         26 non-null     float64\n",
      " 18  median_distance_rank      26 non-null     float64\n",
      " 19  field_area_rank           26 non-null     float64\n",
      " 20  foul_area_rank            26 non-null     float64\n",
      " 21  fop_area_per_rank         26 non-null     float64\n",
      " 22  ratio_rank                26 non-null     float64\n",
      " 23  fop_centroid              26 non-null     object \n",
      " 24  field_orientation         26 non-null     float64\n",
      " 25  field_cardinal_direction  26 non-null     object \n",
      " 26  score                     26 non-null     float64\n",
      " 27  college division          26 non-null     object \n",
      " 28  conference                26 non-null     object \n",
      " 29  Column2                   0 non-null      float64\n",
      " 30  Column1                   0 non-null      float64\n",
      " 31  code                      26 non-null     object \n",
      " 32  list of schools           26 non-null     object \n",
      " 33  conference_2              26 non-null     object \n",
      " 34  date_range                26 non-null     object \n",
      " 35  host_raw                  26 non-null     object \n",
      " 36  final game info           26 non-null     object \n",
      " 37  coords                    26 non-null     object \n",
      "dtypes: float64(21), object(17)\n",
      "memory usage: 7.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print all home_plates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Output the Files as a JSON and as a csv for review\n",
    "\n",
    "df.to_csv('data/NCAA_D1/conf_tourn_map.csv', index=False)\n",
    "\n",
    "df.to_json('data/NCAA_D1/conf_tourn_map2.json', orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
