{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to scrape MI High School Baseball school and conference info to integrate with the field measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependencies: requests, bs4\n",
    "\n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Web Addresses\n",
    "\n",
    "top_page_url = 'https://en.wikipedia.org/wiki/List_of_Michigan_High_School_Association_member_conferences'\n",
    "\n",
    "top_html = urlopen(top_page_url)\n",
    "\n",
    "soup = BeautifulSoup(top_html, 'html.parser')\n",
    "\n",
    "h2 = soup.find_all('h2')\n",
    "line = soup.find_all('li')\n",
    "\n",
    "\n",
    "### Get table of all conferences with names and links to conference pages\n",
    "\n",
    "conferences = []\n",
    "links = []\n",
    "names = []\n",
    "\n",
    "for each in line:\n",
    "    \n",
    "    if each.find('a'):\n",
    "        \n",
    "        names.append(each.find('a').get_text())\n",
    "        links.append(each.find('a').get('href'))\n",
    "\n",
    "# Convert to dataframe\n",
    "df = pd.DataFrame({'name': names, 'link': links})\n",
    "\n",
    "### Clean up dataframe\n",
    "\n",
    "## If link doesn't start with /wiki/ then it's not a conference page, remove these rows\n",
    "\n",
    "df = df[df['link'].str.contains('/wiki/')]\n",
    "\n",
    "## Reindex dataframe\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "### Drop all rows that don't have a conference name\n",
    "## this is all of the rows after the 44th row\n",
    "\n",
    "df = df.drop(df.index[45:])\n",
    "\n",
    "# df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 696 entries, 0 to 20\n",
      "Data columns (total 90 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   School                                        308 non-null    object \n",
      " 1   Mascot                                        205 non-null    object \n",
      " 2   Colors                                        73 non-null     object \n",
      " 3   Class (enrollment)                            6 non-null      object \n",
      " 4   City                                          6 non-null      object \n",
      " 5   County                                        186 non-null    object \n",
      " 6   Year joined                                   6 non-null      float64\n",
      " 7   Previous league                               16 non-null     object \n",
      " 8   conference                                    480 non-null    object \n",
      " 9   (Team, Blue Division)                         42 non-null     object \n",
      " 10  (Class, Blue Division)                        42 non-null     object \n",
      " 11  (Enrollment, Blue Division)                   42 non-null     object \n",
      " 12  (Joined, Blue Division)                       42 non-null     object \n",
      " 13  (City, Blue Division)                         42 non-null     object \n",
      " 14  (County, Blue Division)                       42 non-null     object \n",
      " 15  (Previous Conference, Blue Division)          42 non-null     object \n",
      " 16  (conference, )                                216 non-null    object \n",
      " 17  (Catholic High School League, School)         128 non-null    object \n",
      " 18  (Catholic High School League, Location)       128 non-null    object \n",
      " 19  (Catholic High School League, Enrollment[1])  128 non-null    float64\n",
      " 20  (Catholic High School League, Class)          128 non-null    object \n",
      " 21  (Catholic High School League, Nickname)       128 non-null    object \n",
      " 22  (Catholic High School League, Colors)         128 non-null    object \n",
      " 23  (Catholic High School League, Gender)         128 non-null    object \n",
      " 24  (Catholic High School League, Established)    128 non-null    float64\n",
      " 25  Nickname                                      134 non-null    object \n",
      " 26  Enrollment                                    353 non-null    float64\n",
      " 27  Class                                         353 non-null    object \n",
      " 28  Team[1]                                       17 non-null     object \n",
      " 29  Location                                      133 non-null    object \n",
      " 30  Joined                                        133 non-null    object \n",
      " 31  Previous Conference                           119 non-null    object \n",
      " 32  (Team, West Division)                         17 non-null     object \n",
      " 33  (Location, West Division)                     17 non-null     object \n",
      " 34  (Enrollment, West Division)                   17 non-null     object \n",
      " 35  (Joined, West Division)                       17 non-null     object \n",
      " 36  (Previous Conference, West Division)          17 non-null     object \n",
      " 37  Affiliation                                   171 non-null    object \n",
      " 38  Year Admitted                                 144 non-null    object \n",
      " 39  Division                                      144 non-null    object \n",
      " 40  (School, North Division)                      14 non-null     object \n",
      " 41  (Nickname, North Division)                    14 non-null     object \n",
      " 42  (Location, North Division)                    14 non-null     object \n",
      " 43  (Joined, North Division)                      12 non-null     object \n",
      " 44  (Previous Conference, North Division)         12 non-null     object \n",
      " 45  (Unnamed: 5_level_0, North Division)          1 non-null      object \n",
      " 46  (Unnamed: 6_level_0, North Division)          1 non-null      object \n",
      " 47  (School, Red Division)                        15 non-null     object \n",
      " 48  (Nickname, Red Division)                      15 non-null     object \n",
      " 49  (Location, Red Division)                      15 non-null     object \n",
      " 50  (Joined, Red Division)                        15 non-null     object \n",
      " 51  (Enrollment, Red Division)                    15 non-null     object \n",
      " 52  (Class, Red Division)                         15 non-null     object \n",
      " 53  (Colors, Red Division)                        15 non-null     object \n",
      " 54  (Previous Conference, Red Division)           15 non-null     object \n",
      " 55  School[1]                                     28 non-null     object \n",
      " 56  Year Joined                                   20 non-null     object \n",
      " 57  District Website                              28 non-null     object \n",
      " 58  0                                             63 non-null     object \n",
      " 59  1                                             63 non-null     object \n",
      " 60  2                                             63 non-null     object \n",
      " 61  3                                             63 non-null     object \n",
      " 62  4                                             63 non-null     object \n",
      " 63  5                                             63 non-null     object \n",
      " 64  6                                             63 non-null     object \n",
      " 65  7                                             3 non-null      object \n",
      " 66  Sports Division                               27 non-null     object \n",
      " 67  Football Division                             12 non-null     object \n",
      " 68  Team                                          29 non-null     object \n",
      " 69  Address                                       8 non-null      object \n",
      " 70  Unnamed: 5                                    0 non-null      float64\n",
      " 71  Unnamed: 6                                    0 non-null      float64\n",
      " 72  Unnamed: 7                                    0 non-null      float64\n",
      " 73  School[3]                                     8 non-null      object \n",
      " 74  Enrollment[a]                                 8 non-null      float64\n",
      " 75  Year Joined [2]                               8 non-null      object \n",
      " 76  School[5]                                     16 non-null     object \n",
      " 77  MHSAAClass                                    8 non-null      object \n",
      " 78  Team & Mascot                                 8 non-null      object \n",
      " 79  Boys Champ                                    8 non-null      float64\n",
      " 80  Girls Champ                                   8 non-null      float64\n",
      " 81  Total Champ                                   8 non-null      float64\n",
      " 82  Year                                          10 non-null     float64\n",
      " 83  Conference Champion(s)                        4 non-null      object \n",
      " 84  Year.1                                        10 non-null     float64\n",
      " 85  Conference Champion(s).1                      10 non-null     object \n",
      " 86  Year.2                                        10 non-null     float64\n",
      " 87  Conference Champion(s).2                      10 non-null     object \n",
      " 88  Year.3                                        10 non-null     float64\n",
      " 89  Conference Champion(s).3                      9 non-null      object \n",
      "dtypes: float64(15), object(75)\n",
      "memory usage: 494.8+ KB\n"
     ]
    }
   ],
   "source": [
    "### Use the list of conferences and relative links to get a table of all the teams in the conference\n",
    "\n",
    "## Link to conference pages will be built like this\n",
    "\n",
    "## https://en.wikipedia.org + link\n",
    "\n",
    "## Example: https://en.wikipedia.org/wiki/Big_Sky_Conference\n",
    "\n",
    "conference_html = []\n",
    "conference_url = []\n",
    "dfs = []\n",
    "\n",
    "for each in range(len(df)):\n",
    "    try:\n",
    "        \n",
    "        link = df['link'][each]\n",
    "        \n",
    "        conference_url = 'https://en.wikipedia.org' + link\n",
    "        \n",
    "        conference_name = df['name'][each]\n",
    "\n",
    "        conference_html = urlopen(conference_url)\n",
    "\n",
    "        soup = BeautifulSoup(conference_html, 'html.parser')\n",
    "\n",
    "        table = soup.find('table',{'class':'wikitable'})\n",
    "\n",
    "        ## create a dataframe from the table with the name of the conference added as a column\n",
    "\n",
    "        df2 = pd.read_html(str(table))\n",
    "\n",
    "        df2 = pd.DataFrame(df2[0])\n",
    "\n",
    "        df2['conference'] = conference_name\n",
    "\n",
    "        ## append the dataframe to a list\n",
    "\n",
    "        dfs.append(df2)\n",
    "    ### print out the conference name if there is an error\n",
    "    except:\n",
    "        print\n",
    "        continue\n",
    "\n",
    "\n",
    "### Concatenate all the dataframes in the list into one dataframe\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "df.info()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wednesday 12-15 work below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Output csv to review the data\n",
    "\n",
    "df.to_csv('TEMP/mhsaa_conferences.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'TEMP/temp_cleaned_conferences.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Justin\\Desktop\\Project\\BB_parks\\wiki_scrape.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/BB_parks/wiki_scrape.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m### open the manually cleaned conference list and clean up school names to make them easier to match\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/BB_parks/wiki_scrape.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m test_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mTEMP/temp_cleaned_conferences.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/BB_parks/wiki_scrape.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m test_df\u001b[39m.\u001b[39minfo()\n",
      "File \u001b[1;32mc:\\Users\\Justin\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Justin\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Justin\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Justin\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\Justin\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m     f,\n\u001b[0;32m   1219\u001b[0m     mode,\n\u001b[0;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1226\u001b[0m )\n\u001b[0;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Justin\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    790\u001b[0m             handle,\n\u001b[0;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'TEMP/temp_cleaned_conferences.csv'"
     ]
    }
   ],
   "source": [
    "### open the manually cleaned conference list and clean up school names to make them easier to match\n",
    "\n",
    "test_df = pd.read_csv('TEMP/temp_cleaned_conferences.csv')\n",
    "\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "### test scrape of the CAAC conference\n",
    "\n",
    "### download the page\n",
    "\n",
    "test_url = 'https://en.wikipedia.org/wiki/Capital_Area_Activities_Conference'\n",
    "\n",
    "soup = (BeautifulSoup(test_url, 'html.parser'))\n",
    "\n",
    "table_class='wikitable sortable jquery-tablesorter'\n",
    "\n",
    "response = requests.get(test_url)\n",
    "print(response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Parse the data from html\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "table_1 = soup.find('table',{'class':'wikitable'})\n",
    "table_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read the html into a dataframe\n",
    "\n",
    "df = pd.read_html(str(table_1))\n",
    "blue_df = pd.DataFrame(df[0])\n",
    "blue_df.info()\n",
    "\n",
    "## Output the data to a csv file\n",
    "blue_df.to_csv('TEMP/blue.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test scrape the Catholic High School League\n",
    "\n",
    "test_url = 'https://en.wikipedia.org/wiki/Catholic_High_School_League'\n",
    "\n",
    "response = requests.get(test_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "\n",
    "table = soup.find('table',{'class':'wikitable'})\n",
    "\n",
    "df = pd.read_html(str(table))\n",
    "catholic_df = pd.DataFrame(df[0])\n",
    "catholic_df.info()\n",
    "\n",
    "## Output to check data\n",
    "catholic_df.to_csv('TEMP/catholic.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3071ee50c89c1c794c04ecbcb4eb8f9585468a45756c3a74d8e9479e4a2bc436"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
