{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## New book to streamline the process of scraping data from the MHSAA website\n",
    "\n",
    "# Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "\n",
    "## Create the 2 functions that perform the parse\n",
    "\n",
    "# Function to parse game data\n",
    "def parse_game_data(data, game):\n",
    "    # Extract the team and league information\n",
    "    team_name = data[\"Record\"][\"TeamName\"]\n",
    "    team_id = data[\"Record\"][\"SchoolSportTeamId\"]\n",
    "    league_name = data[\"League\"][\"Name\"]\n",
    "\n",
    "    # Extract the opponentId and opponentName\n",
    "    opponent_id = game[\"Opponents\"][0][\"SportTeamId\"] if game[\"Opponents\"] else None\n",
    "    opponent_name = game[\"Opponents\"][0][\"PopularName\"] if game[\"Opponents\"] else None\n",
    "\n",
    "    # Extract the gameDate and gameTime\n",
    "    game_date = game[\"StartDate\"]\n",
    "    game_time = game[\"TimeText\"]\n",
    "\n",
    "    # Extract homeOrAway\n",
    "    home_or_away = game[\"HomeAwayCode\"]\n",
    "\n",
    "    # Extract location info\n",
    "    location = game[\"ContestLocationLink\"]\n",
    "\n",
    "    # Extract teamScore, opponentScore, and notes\n",
    "    team_score = None\n",
    "    opponent_score = None\n",
    "    notes = None\n",
    "    score_text = game[\"ScoreText\"]\n",
    "    if score_text:\n",
    "        # Use regular expression to find scores and notes\n",
    "        match = re.match(r\"(\\d+)-(\\d+)(.*)\", score_text)\n",
    "        if match:\n",
    "            team_score, opponent_score, notes = match.groups()\n",
    "            # Convert scores to integers\n",
    "            team_score = int(team_score)\n",
    "            opponent_score = int(opponent_score)\n",
    "            # Trim whitespace from notes\n",
    "            notes = notes.strip()\n",
    "\n",
    "    # Extract additional info\n",
    "    contest_type = game.get(\"ContestType\")\n",
    "    season_type = game.get(\"SeasonType\")\n",
    "    post_season_info = game.get(\"PostSeasonInfo\")\n",
    "    tournament_info = game.get(\"TournamentInfo\")\n",
    "    tournament_name = game.get(\"TournamentName\")\n",
    "    tournament_type = game.get(\"TournamentType\")\n",
    "    contest_name = game.get(\"ContestName\")\n",
    "    season_type_code = game.get(\"SeasonTypeCode\")\n",
    "\n",
    "    return {\n",
    "        \"teamName\": team_name,\n",
    "        \"teamId\": team_id,\n",
    "        \"leagueName\": league_name,\n",
    "        \"opponentName\": opponent_name,\n",
    "        \"opponentId\": opponent_id,\n",
    "        \"gameDate\": game_date,\n",
    "        \"gameTime\": game_time,\n",
    "        \"homeOrAway\": home_or_away,\n",
    "        \"location\": location,\n",
    "        \"teamScore\": team_score,\n",
    "        \"opponentScore\": opponent_score,\n",
    "        \"notes\": notes,\n",
    "        \"contestType\": contest_type,\n",
    "        \"seasonType\": season_type,\n",
    "        \"postSeasonInfo\": post_season_info,\n",
    "        \"tournamentInfo\": tournament_info,\n",
    "        \"tournamentName\": tournament_name,\n",
    "        \"tournamentType\": tournament_type,\n",
    "        \"contestName\": contest_name,\n",
    "        \"seasonTypeCode\": season_type_code\n",
    "    }\n",
    "\n",
    "\n",
    "def initialize_parsing(base_url, team_id_start, team_id_end, url_end):\n",
    "    # Initialize an empty list to hold the parsed data\n",
    "    parsed_data = []\n",
    "\n",
    "    # Loop over the range of team IDs\n",
    "    for i in range(team_id_start, team_id_end+1):\n",
    "        # Convert the id to a string\n",
    "        id_str = str(i)\n",
    "        # Build the URL\n",
    "        full_url = base_url + id_str + url_end\n",
    "        # Make the request\n",
    "        response = requests.get(full_url)\n",
    "\n",
    "        # Only proceed if the response status code is 200 (HTTP OK)\n",
    "        if response.status_code == 200:\n",
    "            # Convert the response to json\n",
    "            data = response.json()\n",
    "\n",
    "            # Check to see if the response is valid. If it is, parse the game data\n",
    "            if 'Contests' in data and data['Contests']:  # Check if 'Contests' key exists and its value is not empty\n",
    "                for game in data['Contests']:\n",
    "                    parsed_data.append(parse_game_data(data, game))\n",
    "\n",
    "    return parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2023 took 5 minutes and 12 seconds\n",
      "Total number of contests: 4298\n",
      "Year 2022 took 4 minutes and 56 seconds\n",
      "Total number of contests: 4081\n",
      "Year 2001 took 4 minutes and 30 seconds\n",
      "Total number of contests: 0\n",
      "Year 2019 took 4 minutes and 42 seconds\n",
      "Total number of contests: 3776\n",
      "Year 2018 took 4 minutes and 52 seconds\n",
      "Total number of contests: 3500\n",
      "Year 2017 took 4 minutes and 41 seconds\n",
      "Total number of contests: 3705\n",
      "Year 2016 took 6 minutes and 58 seconds\n",
      "Total number of contests: 3303\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "## Target years to scrape\n",
    "years = [2022, 2021, 2019, 2018, 2017,  2016, 2015, 2014, 2013, 2012, 2011, 2010, 2009 ]\n",
    "\n",
    "## url builder\n",
    "base_url = 'https://my.mhsaa.com/DesktopModules/MHSAA-Async-SportTeamSchedule/Endpoint.ashx?&method=schedules&orgID='\n",
    "mid_url = '&sportTypeCode=BA&gender=M&level=V&year='\n",
    "end_url = '&userid=-1'\n",
    "\n",
    "# Start of team IDs\n",
    "team_id_start = 3000\n",
    "# End of team IDs\n",
    "team_id_end = 3999\n",
    "\n",
    "# Initialize a timer for the total execution time\n",
    "total_start_time = time.time()\n",
    "\n",
    "# Create a dictionary to store dataframes\n",
    "df_dict = {}\n",
    "\n",
    "# Loop over the years\n",
    "for year in years:\n",
    "    # Initialize a timer for the year's execution time\n",
    "    year_start_time = time.time()\n",
    "\n",
    "    # Initialize the parsing for the given year and team ID range\n",
    "    parsed_data = initialize_parsing(base_url, team_id_start, team_id_end, mid_url + str(year) + end_url)\n",
    "\n",
    "    # store the parsed data as DataFrame\n",
    "    df = pd.DataFrame(parsed_data)\n",
    "\n",
    "    # Store a copy of the DataFrame in the dictionary\n",
    "    df_dict[year] = df.copy()\n",
    "   \n",
    "    # Generate timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "    # Save the DataFrame to a CSV file in /TEMP/ directory, using year+1 in filename and current timestamp\n",
    "    df.to_csv(f\"TEMP/{year+1}_{timestamp}.csv\", index=False)\n",
    "\n",
    "    # Print the year's execution time in minutes and seconds\n",
    "    print(f\"Year {year+1} took {int((time.time() - year_start_time)/60)} minutes and {int((time.time() - year_start_time)%60)} seconds\")\n",
    "    \n",
    "    # print the number of valid records for the year\n",
    "    # print(f\"Number of valid records: {len(df[df['teamName'].notnull()])}\")\n",
    "    # print total number of contests for the year\n",
    "    print(f\"Total number of contests: {len(df)}\")\n",
    "\n",
    "# Print the total execution time\n",
    "print(f\"Total time taken: {int((time.time() - total_start_time)/60)} minutes and {int((time.time() - total_start_time)%60)} seconds\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Target years to scrape\n",
    "years = [2021, 2020, 2018, 2017,  2016, 2015, 2014, 2013, 2012, 2011, 2010, 2009 ]\n",
    "\n",
    "# Seems to have less and less data as the years go back\n",
    "# Before 2008 the urls are still valid but there doesn't seem to be much or any data\n",
    "\n",
    "# For now just try to go back to 2008\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## url builder\n",
    "\n",
    "base_url = 'https://my.mhsaa.com/DesktopModules/MHSAA-Async-SportTeamSchedule/Endpoint.ashx?&method=schedules&orgID='\n",
    "# Then team ID\n",
    "\n",
    "mid_url = '&sportTypeCode=BA&gender=M&level=V&year='\n",
    "\n",
    "# Then year (year is going to corispond to the start of the school year 2021 will return the 2021-2022 school year)\n",
    "\n",
    "end_url = '&userid=-1'\n",
    "\n",
    "\n",
    "# Most if not all schools in michigan have ids from 3000 to 3999\n",
    "\n",
    "# There are gaps in the ids\n",
    "# There also may be some ids from out of state schools outside of that range\n",
    "# The team id identifies the same school for all years\n",
    "\n",
    "# Challenge when testing for valid IDs is that the site will return a response even if there is no data\n",
    "# It returns a record but the record is empty\n",
    "\n",
    "## Using Mason HS (id #3969) as a test case, data goes back to 2010 season (2009 school year)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
