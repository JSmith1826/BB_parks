{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### BOOK FOR WEATHER SCRAPPING\n",
    "\n",
    "### Using Open Weather's API - Free Account - Limited to 1000 free calls per day- only 2000 calls per day total\n",
    "### After 1000 in a day billed at $0.15 per 100 calls\n",
    "\n",
    "API_KEY = 'e85f2b341782ffd493fe2e354727db0b'\n",
    "\n",
    "### Link to docs https://openweathermap.org/api/one-call-3#history-how\n",
    "\n",
    "## File PATH\n",
    "\n",
    "## Scraped data for games with HR stats with full team names\n",
    "path = 'data/NCAA_D1/ESPN_HR_data_baseball_scrape.csv'\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical weather data\n",
    "To learn about how get access to historical weather data for any timestamp from 1st January 1979 till now, please use this section of the documentation.\n",
    "\n",
    "If you are interested in current weather data, forecasts and weather alerts please read the \"Current and forecast weather data\" section.\n",
    "If you are interested in daily aggregated historical weather data, please read the \"History Daily Aggregation\" section of documentation.\n",
    "\n",
    "## How to make an API call\n",
    "### API call\n",
    "\n",
    "https://api.openweathermap.org/data/3.0/onecall/timemachine?lat={lat}&lon={lon}&dt={time}&appid={API key}\n",
    "\n",
    "### Parameters\n",
    "#### lat\t\n",
    "required\tLatitude, decimal (-90; 90). If you need the geocoder to automatic convert city names and zip-codes to geo coordinates and the other way around, please use our Geocoding API\n",
    "\n",
    "#### lon\t\n",
    "required\tLongitude, decimal (-180; 180). If you need the geocoder to automatic convert city names and zip-codes to geo coordinates and the other way around, please use our Geocoding API\n",
    "\n",
    "#### dt\n",
    "\trequired\tTimestamp (Unix time, UTC time zone), e.g. dt=1586468027. Data is available from January 1st, 1979.\n",
    "\n",
    "#### appid\n",
    "\trequired\tYour unique API key (you can always find it on your account page under the \"API key\" tab)\n",
    "\n",
    "#### units\n",
    "\toptional\tUnits of measurement. standard, metric and imperial units are available. If you do not use the units parameter, standard units will be applied by default. Learn more\n",
    "#### lang\t\n",
    "    optional\tYou can use the lang parameter to get the output in your language. Learn more\n",
    "\n",
    "Please note that the one API response contains historical weather data for only one specified timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Libraries\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "## Load Data\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look up a game from Founders Park in the data\n",
    "\n",
    "# df.loc[df['location'] == 'Founders Park']\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change the names of the problem parks that couldn't be found in the google api\n",
    "# Assuming your DataFrame is named 'df'\n",
    "substitutions = {\n",
    "    'Mac Nease Baseball Park': 'Russ Chandler Stadium',\n",
    "    'Jim Patterson Stadium': 'Jim Patterson Stadium Louisville',\n",
    "    'Founders Park': 'Founders Park South Carolina',\n",
    "    'Eddie Pellagrini Baseball Diamond': 'John Shea Field (Demolished)',\n",
    "    'FedExPark Avron Fogelman Field': 'FedEx Park Memphis',\n",
    "    'Riders Field': 'Riders Field Frisco'\n",
    "}\n",
    "\n",
    "df['location'] = df['location'].replace(substitutions)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df['location'].unique()))\n",
    "\n",
    "df['location'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "\n",
    "## Convert date, time and year columns into the correct format\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Assuming your DataFrame is named 'df'\n",
    "df['datetime'] = pd.to_datetime(df['year'].astype(str) + ' ' + df['date'] + ' ' + df['time'])\n",
    "df['unix_timestamp'] = df['datetime'].apply(lambda x: int(x.timestamp()))\n",
    "\n",
    "# Alternatively, if you only want the date, year, and time columns as Unix timestamp\n",
    "# without creating a new 'datetime' column, you can use the following code:\n",
    "# df['unix_timestamp'] = pd.to_datetime(df['year'].astype(str) + ' ' + df['date'] + ' ' + df['time']).apply(lambda x: int(x.timestamp()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get a list of all of the locations in the HR dataset and use google api to get a lat and long for each location\n",
    "\n",
    "## get all unique locations\n",
    "locations = df['location'].unique()\n",
    "\n",
    "len(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import googlemaps\n",
    "\n",
    "# Your API Key goes here\n",
    "gmaps = googlemaps.Client(key='AIzaSyA_BhlTupRdBPBhRptQuR6pYorMVYQnRMA')\n",
    "\n",
    "\n",
    "# Create a list to store the results\n",
    "results = []\n",
    "\n",
    "# Loop through all locations\n",
    "for location in tqdm(locations):\n",
    "    # Geocode location\n",
    "    geocode_result = gmaps.geocode(location)\n",
    "    # If a result was returned, append the result as a dictionary to the results list\n",
    "    if geocode_result:\n",
    "        latitude = geocode_result[0]['geometry']['location']['lat']\n",
    "        longitude = geocode_result[0]['geometry']['location']['lng']\n",
    "        results.append({'location': location, 'latitude': latitude, 'longitude': longitude})\n",
    "    else:\n",
    "        print(f\"Could not find coordinates for {location}.\")\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "df_locations = pd.DataFrame(results)\n",
    "\n",
    "# Print the DataFrame\n",
    "\n",
    "print(df_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['latitude'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge the lat and long data with the original dataset\n",
    "df = df.merge(df_locations, on='location', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['latitude'].isnull().sum()\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filter the dataframe to create a sample to send throught he API call\n",
    "## drop any rows with not lat or long\n",
    "df = df.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "# df = df.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1039\n",
      "695\n"
     ]
    }
   ],
   "source": [
    "### TEMPORARY BLOCK - Load the partially filled dataframe, filter for those that don't have results and then run the API call on those rows\n",
    "## Load the partial file\n",
    "\n",
    "## jbancroftsmith - API KEY\n",
    "# API_KEY = '9e69059f84d17c13de92f5bb94f4fb8'\n",
    "df = pd.read_csv('data/NCAA_D1/ESPN_HR_data_baseball_scrape_with_weather_partial_v1.csv')\n",
    "\n",
    "# df.columns\n",
    "## Split into dataframes with reults and without\n",
    "df_with_results = df.dropna(subset=['weather_data'])\n",
    "\n",
    "print(len(df_with_results))\n",
    "\n",
    "df_without_results = df[df['weather_data'].isnull()]\n",
    "print(len(df_without_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rename the frame with no results to the default name to pass to the API call\n",
    "df = df_without_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "695it [15:32,  1.34s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>team_1</th>\n",
       "      <th>team_2</th>\n",
       "      <th>runs_1</th>\n",
       "      <th>hits_1</th>\n",
       "      <th>errors_1</th>\n",
       "      <th>home_runs_1</th>\n",
       "      <th>runs_2</th>\n",
       "      <th>hits_2</th>\n",
       "      <th>errors_2</th>\n",
       "      <th>home_runs_2</th>\n",
       "      <th>home_runs</th>\n",
       "      <th>year</th>\n",
       "      <th>datetime</th>\n",
       "      <th>unix_timestamp</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>weather_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>Florida Ballpark at Alfred A. McKethan Field</td>\n",
       "      <td>June 3</td>\n",
       "      <td>1:00 PM</td>\n",
       "      <td>Liberty Flames</td>\n",
       "      <td>Oklahoma Sooners</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-06-03 13:00:00</td>\n",
       "      <td>1654261200</td>\n",
       "      <td>27.664827</td>\n",
       "      <td>-81.515754</td>\n",
       "      <td>{'lat': 27.6648, 'lon': -81.5158, 'timezone': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>Baum-Walker Stadium</td>\n",
       "      <td>June 2</td>\n",
       "      <td>8:00 PM</td>\n",
       "      <td>Arkansas Razorbacks</td>\n",
       "      <td>Southern Miss Golden Eagles</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-06-02 20:00:00</td>\n",
       "      <td>1527969600</td>\n",
       "      <td>36.049888</td>\n",
       "      <td>-94.182241</td>\n",
       "      <td>{'lat': 36.0499, 'lon': -94.1822, 'timezone': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>Jack Coombs Field</td>\n",
       "      <td>May 12</td>\n",
       "      <td>6:00 PM</td>\n",
       "      <td>Georgia Tech Yellow Jackets</td>\n",
       "      <td>Duke Blue Devils</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-05-12 18:00:00</td>\n",
       "      <td>1683914400</td>\n",
       "      <td>35.998086</td>\n",
       "      <td>-78.944236</td>\n",
       "      <td>{'lat': 35.9981, 'lon': -78.9442, 'timezone': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>Hawkins Field</td>\n",
       "      <td>April 28</td>\n",
       "      <td>7:00 PM</td>\n",
       "      <td>Kentucky Wildcats</td>\n",
       "      <td>Vanderbilt Commodores</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-04-28 19:00:00</td>\n",
       "      <td>1682708400</td>\n",
       "      <td>36.143398</td>\n",
       "      <td>-86.807393</td>\n",
       "      <td>{'lat': 36.1434, 'lon': -86.8074, 'timezone': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>Hawkins Field</td>\n",
       "      <td>April 11</td>\n",
       "      <td>7:00 PM</td>\n",
       "      <td>North Alabama Lions</td>\n",
       "      <td>Vanderbilt Commodores</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-04-11 19:00:00</td>\n",
       "      <td>1681239600</td>\n",
       "      <td>36.143398</td>\n",
       "      <td>-86.807393</td>\n",
       "      <td>{'lat': 36.1434, 'lon': -86.8074, 'timezone': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          location       date     time  \\\n",
       "1039  Florida Ballpark at Alfred A. McKethan Field     June 3  1:00 PM   \n",
       "1040                           Baum-Walker Stadium     June 2  8:00 PM   \n",
       "1041                             Jack Coombs Field     May 12  6:00 PM   \n",
       "1042                                 Hawkins Field   April 28  7:00 PM   \n",
       "1043                                 Hawkins Field   April 11  7:00 PM   \n",
       "\n",
       "                           team_1                       team_2  runs_1  \\\n",
       "1039               Liberty Flames             Oklahoma Sooners       3   \n",
       "1040          Arkansas Razorbacks  Southern Miss Golden Eagles      10   \n",
       "1041  Georgia Tech Yellow Jackets             Duke Blue Devils       8   \n",
       "1042            Kentucky Wildcats        Vanderbilt Commodores       4   \n",
       "1043          North Alabama Lions        Vanderbilt Commodores       2   \n",
       "\n",
       "      hits_1  errors_1  home_runs_1  runs_2  hits_2  errors_2  home_runs_2  \\\n",
       "1039      10         2            0      16      17         0            3   \n",
       "1040      13         1            2       2       5         1            1   \n",
       "1041       9         1            3       5      10         0            1   \n",
       "1042       6         0            0       6       9         0            1   \n",
       "1043       2         1            0      14      13         1            0   \n",
       "\n",
       "      home_runs  year             datetime  unix_timestamp   latitude  \\\n",
       "1039        3.0  2022  2022-06-03 13:00:00      1654261200  27.664827   \n",
       "1040        3.0  2018  2018-06-02 20:00:00      1527969600  36.049888   \n",
       "1041        4.0  2023  2023-05-12 18:00:00      1683914400  35.998086   \n",
       "1042        1.0  2023  2023-04-28 19:00:00      1682708400  36.143398   \n",
       "1043        0.0  2023  2023-04-11 19:00:00      1681239600  36.143398   \n",
       "\n",
       "      longitude                                       weather_data  \n",
       "1039 -81.515754  {'lat': 27.6648, 'lon': -81.5158, 'timezone': ...  \n",
       "1040 -94.182241  {'lat': 36.0499, 'lon': -94.1822, 'timezone': ...  \n",
       "1041 -78.944236  {'lat': 35.9981, 'lon': -78.9442, 'timezone': ...  \n",
       "1042 -86.807393  {'lat': 36.1434, 'lon': -86.8074, 'timezone': ...  \n",
       "1043 -86.807393  {'lat': 36.1434, 'lon': -86.8074, 'timezone': ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Make an API call to get the weather data\n",
    "from time import sleep\n",
    "import time\n",
    "\n",
    "## Create a list to store the results\n",
    "results = []\n",
    "\n",
    "# Loop through all locations\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    ## Delay to limit rate of API calls\n",
    "    time.sleep(.25)\n",
    "    # Get the latitude and longitude for the current row\n",
    "    latitude = row['latitude']\n",
    "    longitude = row['longitude']\n",
    "    # Get the Unix timestamp for the current row\n",
    "    unix_timestamp = row['unix_timestamp']\n",
    "    # Create the API request URL\n",
    "    url = f'https://api.openweathermap.org/data/3.0/onecall/timemachine?lat={latitude}&lon={longitude}&dt={unix_timestamp}&appid={API_KEY}&units=imperial'\n",
    "    # Make the API request\n",
    "    response = requests.get(url)\n",
    "    # If the response was successful, append the JSON object to the results list\n",
    "    if response.status_code == 200:\n",
    "        results.append(response.json())\n",
    "    # If the response was unsuccessful, print the response code\n",
    "    else:\n",
    "        results.append('failed')\n",
    "        print(f\"Could not get data for row {index}. Response code: {response.status_code}\")\n",
    "        print(response.text)\n",
    "\n",
    "    # Store the reults in original dataframe\n",
    "df['weather_data'] = results\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "695\n",
      "695\n"
     ]
    }
   ],
   "source": [
    "print(len(results))\n",
    "\n",
    "# Assuming the API calls were successful for the first 1039 rows\n",
    "\n",
    "# Check the length of the results\n",
    "print(len(results))\n",
    "\n",
    "## Apply the reults to the dataframe\n",
    "df['weather_data'] = results\n",
    "\n",
    "# Apply the results to the corresponding subset of rows in the DataFrame\n",
    "# df.loc[:1038, 'weather_data'] = results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_7664\\2335409679.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df_with_results)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1734"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### append the dataframe with new results to the one that already has them \n",
    "df = df.append(df_with_results)\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1734 entries, 1039 to 1038\n",
      "Data columns (total 30 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   location         1734 non-null   object \n",
      " 1   date             1734 non-null   object \n",
      " 2   time             1734 non-null   object \n",
      " 3   team_1           1734 non-null   object \n",
      " 4   team_2           1734 non-null   object \n",
      " 5   runs_1           1734 non-null   int64  \n",
      " 6   hits_1           1734 non-null   int64  \n",
      " 7   errors_1         1734 non-null   int64  \n",
      " 8   home_runs_1      1734 non-null   int64  \n",
      " 9   runs_2           1734 non-null   int64  \n",
      " 10  hits_2           1734 non-null   int64  \n",
      " 11  errors_2         1734 non-null   int64  \n",
      " 12  home_runs_2      1734 non-null   int64  \n",
      " 13  home_runs        1734 non-null   float64\n",
      " 14  year             1734 non-null   int64  \n",
      " 15  datetime         1734 non-null   object \n",
      " 16  unix_timestamp   1734 non-null   int64  \n",
      " 17  latitude         1734 non-null   float64\n",
      " 18  longitude        1734 non-null   float64\n",
      " 19  weather_data     1734 non-null   object \n",
      " 20  lat              695 non-null    float64\n",
      " 21  lon              695 non-null    float64\n",
      " 22  timezone         695 non-null    object \n",
      " 23  timezone_offset  695 non-null    float64\n",
      " 24  data             695 non-null    object \n",
      " 25  lat              695 non-null    float64\n",
      " 26  lon              695 non-null    float64\n",
      " 27  timezone         695 non-null    object \n",
      " 28  timezone_offset  695 non-null    float64\n",
      " 29  data             695 non-null    object \n",
      "dtypes: float64(9), int64(10), object(11)\n",
      "memory usage: 420.0+ KB\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Justin\\Desktop\\Project\\BB_parks\\Weather_Scraper_Book.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/BB_parks/Weather_Scraper_Book.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df\u001b[39m.\u001b[39minfo()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/BB_parks/Weather_Scraper_Book.ipynb#X46sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Extract the 'data' column from the 'weather_data' dictionary\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/BB_parks/Weather_Scraper_Book.ipynb#X46sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mweather_data\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: x[\u001b[39m'\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/BB_parks/Weather_Scraper_Book.ipynb#X46sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Normalize the 'data' column\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/BB_parks/Weather_Scraper_Book.ipynb#X46sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m normalized_data \u001b[39m=\u001b[39m json_normalize(df[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Justin\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\Justin\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1079\u001b[0m     \u001b[39m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m-> 1082\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\Justin\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m   1132\u001b[0m         \u001b[39m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[39m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[39m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[39m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[39m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1138\u001b[0m             values,\n\u001b[0;32m   1139\u001b[0m             f,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1140\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1141\u001b[0m         )\n\u001b[0;32m   1143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1144\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\Justin\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Justin\\Desktop\\Project\\BB_parks\\Weather_Scraper_Book.ipynb Cell 26\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/BB_parks/Weather_Scraper_Book.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df\u001b[39m.\u001b[39minfo()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/BB_parks/Weather_Scraper_Book.ipynb#X46sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Extract the 'data' column from the 'weather_data' dictionary\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/BB_parks/Weather_Scraper_Book.ipynb#X46sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mweather_data\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m'\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/BB_parks/Weather_Scraper_Book.ipynb#X46sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Normalize the 'data' column\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Justin/Desktop/Project/BB_parks/Weather_Scraper_Book.ipynb#X46sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m normalized_data \u001b[39m=\u001b[39m json_normalize(df[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data\": [\n",
      "        {\n",
      "            \"clouds\": 75,\n",
      "            \"dew_point\": 73.29,\n",
      "            \"dt\": 1527969600,\n",
      "            \"feels_like\": 95.31,\n",
      "            \"humidity\": 63,\n",
      "            \"pressure\": 1013,\n",
      "            \"sunrise\": 1527937264,\n",
      "            \"sunset\": 1527989325,\n",
      "            \"temp\": 87.44,\n",
      "            \"visibility\": 10000,\n",
      "            \"weather\": [\n",
      "                {\n",
      "                    \"description\": \"haze\",\n",
      "                    \"icon\": \"50d\",\n",
      "                    \"id\": 721,\n",
      "                    \"main\": \"Haze\"\n",
      "                }\n",
      "            ],\n",
      "            \"wind_deg\": 30,\n",
      "            \"wind_speed\": 9.22\n",
      "        }\n",
      "    ],\n",
      "    \"lat\": 36.0499,\n",
      "    \"lon\": -94.1822,\n",
      "    \"timezone\": \"America/Chicago\",\n",
      "    \"timezone_offset\": -18000\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "## Show one of the weather data objects\n",
    "\n",
    "print(json.dumps(results[1], indent=4, sort_keys=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the Dataframe to a csv file witht he results column as a json object\n",
    "df.to_csv('data/NCAA_D1/ESPN_HR_data_baseball_scrape_with_weather.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the Dataframe to a csv apfter trying to parse the weather data\n",
    "df.to_csv('data/NCAA_D1/ESPN_HR_data_baseball_scrape_with_weather_parsed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
