{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dependencies\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start timer\n",
    "start_time = time.time()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is for extracting the data from the original kml file and outputing a JSON that will be easy to use with Google Maps API\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD BLOCK###\n",
    "#### Load data from kml file exported from Google Earth\n",
    "\n",
    "file_path = ('data/kml/ballparks.kml') # file path to kml file\n",
    "\n",
    "with open(file_path) as file:\n",
    "\n",
    "    xml_data = file.read()\n",
    "\n",
    "\n",
    "\n",
    "# Initialize soup variables for parsing file\n",
    "soup = BeautifulSoup(xml_data, 'xml')\n",
    "folders = soup.Document.Folder\n",
    "list = soup.Document.Folder.find_all('Folder')\n",
    "\n",
    "## Create a dataframe to hold the data parsed from xml\n",
    "df = pd.DataFrame(columns=['field', 'foul', 'fop'])\n",
    "\n",
    "failed = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing folder: Progressive Field - Cleveland - MLB. Error message: list index out of range\n",
      "Failed to process 1 folders: Progressive Field - Cleveland - MLB\n"
     ]
    }
   ],
   "source": [
    "#### EXTRACTION BLOCK ####\n",
    "#### Extract data from kml file\n",
    "\n",
    "# Create an empty list to store the rows to append to the DataFrame\n",
    "rows = []\n",
    "\n",
    "# Loop through the folders and extract the data\n",
    "for folder in list:\n",
    "    try:\n",
    "        field_name = folder.find('name').text\n",
    "        foul = folder.find_all('coordinates')[0].text\n",
    "        fop = folder.find_all('coordinates')[1].text\n",
    "\n",
    "        row = {\n",
    "            'field': field_name,\n",
    "            'foul': foul,\n",
    "            'fop': fop\n",
    "        }\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Add name of folder to a list of failed folders\n",
    "        failed.append(folder.find('name').text)\n",
    "        print(f\"Error processing folder: {folder.find('name').text}. Error message: {str(e)}\")\n",
    "\n",
    "# Convert the list of rows to a DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Print a list of failed folders\n",
    "print(f\"Failed to process {len(failed)} folders: {', '.join(failed)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary that maps level indicators to levels and size factors\n",
    "level_dict = {\n",
    "    'International': 'international',\n",
    "    'Major Leagues': 'mlb', \n",
    "    'Professional': 'pro', \n",
    "    'College': 'college', \n",
    "    'High School': 'high_school',\n",
    "    'Youth': 'youth',\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the original DataFrame\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "# Remove new line and space characters from coordinates\n",
    "df_cleaned = df_cleaned.replace(r'\\n','', regex=True) \n",
    "df_cleaned = df_cleaned.replace(r'\\t','', regex=True) \n",
    "\n",
    "# Drop any duplicate rows\n",
    "df_cleaned = df_cleaned.drop_duplicates(subset=['field'], keep='first')\n",
    "\n",
    "# Drop any rows with empty fields\n",
    "df_cleaned = df_cleaned[(df_cleaned != 0).all(1)]\n",
    "\n",
    "# Define the regex patterns for each level\n",
    "re_mlb = re.compile(r'mlb', re.IGNORECASE)\n",
    "re_pro = re.compile(r'pro|semi[-\\s]*pro', re.IGNORECASE)\n",
    "re_college = re.compile(r'college', re.IGNORECASE)\n",
    "re_high_school = re.compile(r'high school|hs', re.IGNORECASE)  # Include the abbreviation 'hs'\n",
    "re_youth = re.compile(r'youth', re.IGNORECASE)\n",
    "re_muni = re.compile(r'muni', re.IGNORECASE)\n",
    "re_international = re.compile(r'international', re.IGNORECASE)\n",
    "\n",
    "# Define a function to classify the fields based on the regex patterns\n",
    "def classify_field(field_name):\n",
    "    if re_mlb.search(field_name):\n",
    "        return 'Major League'\n",
    "    elif re_pro.search(field_name):\n",
    "        return 'Professional'\n",
    "    elif re_college.search(field_name):\n",
    "        return 'College'\n",
    "    elif re_high_school.search(field_name):\n",
    "        return 'High School'\n",
    "    elif re_youth.search(field_name):\n",
    "        return 'Youth'\n",
    "    elif re_muni.search(field_name):\n",
    "        return 'State / County / Municipal'\n",
    "    elif re_international.search(field_name):\n",
    "        return 'International'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "# Apply the classify_field function to the 'field' column\n",
    "df_cleaned['level'] = df_cleaned['field'].apply(classify_field)\n",
    "\n",
    "# Clean up the 'field' column by removing the level indicator and any trailing '-' characters\n",
    "level_regex = r'\\s*(%s)\\s*' % '|'.join(re.escape(level) for level in level_dict.values())\n",
    "df_cleaned['field'] = df_cleaned['field'].str.replace(level_regex, '', regex=True, flags=re.IGNORECASE)\n",
    "df_cleaned['field'] = df_cleaned['field'].str.replace(r'-\\s*$', '', regex=True)\n",
    "\n",
    "# Rename field column to park_name to avoid confusion down the line\n",
    "df_cleaned = df_cleaned.rename(columns={'field': 'park_name'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>park_name</th>\n",
       "      <th>foul</th>\n",
       "      <th>fop</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Day Air Ballpark - Dayton Dragons</td>\n",
       "      <td>-84.18557,39.7642091,0 -84.18494440000001,39.7...</td>\n",
       "      <td>-84.18557,39.7642091,0 -84.18460640000001,39.7...</td>\n",
       "      <td>Professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parkview Field - Fort Wayne TinCaps</td>\n",
       "      <td>-85.14299819999999,41.0741133,0 -85.1432207999...</td>\n",
       "      <td>-85.14299819999999,41.0741133,0 -85.1418776999...</td>\n",
       "      <td>Professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Classic Park- Lake County Captains</td>\n",
       "      <td>-81.43620009999999,41.6407581,0 -81.4362007999...</td>\n",
       "      <td>-81.43620009999999,41.6407581,0 -81.4350347,41...</td>\n",
       "      <td>Professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABC Supply Stadium - Beloit Sky Carp</td>\n",
       "      <td>-89.0406651,42.4971349,0 -89.0408006,42.498079...</td>\n",
       "      <td>-89.0406651,42.4971349,0 -89.03947290000001,42...</td>\n",
       "      <td>Professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Veterans Memorial Stadium - Cedar Rapids Kernels</td>\n",
       "      <td>-91.6867962,41.9677456,0 -91.68678009999999,41...</td>\n",
       "      <td>-91.6867962,41.9677456,0 -91.6856006,41.967735...</td>\n",
       "      <td>Professional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           park_name  \\\n",
       "0                 Day Air Ballpark - Dayton Dragons    \n",
       "1               Parkview Field - Fort Wayne TinCaps    \n",
       "2                Classic Park- Lake County Captains    \n",
       "3              ABC Supply Stadium - Beloit Sky Carp    \n",
       "4  Veterans Memorial Stadium - Cedar Rapids Kernels    \n",
       "\n",
       "                                                foul  \\\n",
       "0  -84.18557,39.7642091,0 -84.18494440000001,39.7...   \n",
       "1  -85.14299819999999,41.0741133,0 -85.1432207999...   \n",
       "2  -81.43620009999999,41.6407581,0 -81.4362007999...   \n",
       "3  -89.0406651,42.4971349,0 -89.0408006,42.498079...   \n",
       "4  -91.6867962,41.9677456,0 -91.68678009999999,41...   \n",
       "\n",
       "                                                 fop         level  \n",
       "0  -84.18557,39.7642091,0 -84.18460640000001,39.7...  Professional  \n",
       "1  -85.14299819999999,41.0741133,0 -85.1418776999...  Professional  \n",
       "2  -81.43620009999999,41.6407581,0 -81.4350347,41...  Professional  \n",
       "3  -89.0406651,42.4971349,0 -89.03947290000001,42...  Professional  \n",
       "4  -91.6867962,41.9677456,0 -91.6856006,41.967735...  Professional  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()\n",
    "\n",
    "## print a list of all the values in the level column\n",
    "# print(df_cleaned['level'].unique())\n",
    "\n",
    "## Print the two the headers and two rows of data to a txt file for reference\n",
    "\n",
    "\n",
    "# with open('data/rows.txt', 'w') as f:\n",
    "#     f.write(df_cleaned.iloc[0].to_string())\n",
    "#     f.write(df_cleaned.iloc[1].to_string())\n",
    "#     f.write(df_cleaned.iloc[14].to_string())\n",
    "    \n",
    "\n",
    "# print(df_cleaned.iloc[15].to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Clean up polygon data and create a new home_plate column\n",
    "\n",
    "def parse_coordinates(coord_string):\n",
    "    coords = coord_string.split()\n",
    "    parsed_coords = [tuple(map(float, coord.split(',')[:2])) for coord in coords]\n",
    "    return parsed_coords\n",
    "\n",
    "# Create a new column for the home_plate location using the first set of coordinates in the 'fop' column\n",
    "df_cleaned['home_plate'] = df_cleaned['fop'].apply(lambda x: parse_coordinates(x)[0])\n",
    "\n",
    "# Apply the parse_coordinates function to the 'foul' and 'fop' columns\n",
    "df_cleaned['foul'] = df_cleaned['foul'].apply(parse_coordinates)\n",
    "df_cleaned['fop'] = df_cleaned['fop'].apply(parse_coordinates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Doesn't seem to be returning useful data - will need to revisit\n",
    "\n",
    "# def determine_direction(coordinates):\n",
    "#     num_points = len(coordinates)\n",
    "#     if num_points < 2:\n",
    "#         return \"Not enough points\"\n",
    "\n",
    "#     # Get the latitude (y-coordinate) values\n",
    "#     latitudes = [point[1] for point in coordinates]\n",
    "\n",
    "#     # Check the change in latitude values\n",
    "#     increasing_latitudes = all(latitudes[i] <= latitudes[i+1] for i in range(num_points-1))\n",
    "#     decreasing_latitudes = all(latitudes[i] >= latitudes[i+1] for i in range(num_points-1))\n",
    "\n",
    "#     if increasing_latitudes:\n",
    "#         return \"Left Field\"\n",
    "#     elif decreasing_latitudes:\n",
    "#         return \"Right Field\"\n",
    "#     else:\n",
    "#         return \"Collinear\"\n",
    "\n",
    "# # Apply the determine_direction function to the 'fop' and 'foul' columns\n",
    "# df_cleaned['fop_direction'] = df_cleaned['fop'].apply(determine_direction)\n",
    "# df_cleaned['foul_direction'] = df_cleaned['foul'].apply(determine_direction)\n",
    "\n",
    "# # Print the updated DataFrame\n",
    "# print(df_cleaned)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>park_name</th>\n",
       "      <th>foul</th>\n",
       "      <th>fop</th>\n",
       "      <th>level</th>\n",
       "      <th>home_plate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Day Air Ballpark - Dayton Dragons</td>\n",
       "      <td>[(-84.18557, 39.7642091), (-84.1849444, 39.764...</td>\n",
       "      <td>[(-84.18557, 39.7642091), (-84.1846064, 39.763...</td>\n",
       "      <td>Professional</td>\n",
       "      <td>(-84.18557, 39.7642091)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parkview Field - Fort Wayne TinCaps</td>\n",
       "      <td>[(-85.1429982, 41.0741133), (-85.1432208, 41.0...</td>\n",
       "      <td>[(-85.1429982, 41.0741133), (-85.1418777, 41.0...</td>\n",
       "      <td>Professional</td>\n",
       "      <td>(-85.1429982, 41.0741133)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Classic Park- Lake County Captains</td>\n",
       "      <td>[(-81.4362001, 41.6407581), (-81.4362008, 41.6...</td>\n",
       "      <td>[(-81.4362001, 41.6407581), (-81.4350347, 41.6...</td>\n",
       "      <td>Professional</td>\n",
       "      <td>(-81.4362001, 41.6407581)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABC Supply Stadium - Beloit Sky Carp</td>\n",
       "      <td>[(-89.0406651, 42.4971349), (-89.0408006, 42.4...</td>\n",
       "      <td>[(-89.0406651, 42.4971349), (-89.0394729, 42.4...</td>\n",
       "      <td>Professional</td>\n",
       "      <td>(-89.0406651, 42.4971349)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Veterans Memorial Stadium - Cedar Rapids Kernels</td>\n",
       "      <td>[(-91.6867962, 41.9677456), (-91.6867801, 41.9...</td>\n",
       "      <td>[(-91.6867962, 41.9677456), (-91.6856006, 41.9...</td>\n",
       "      <td>Professional</td>\n",
       "      <td>(-91.6867962, 41.9677456)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           park_name  \\\n",
       "0                 Day Air Ballpark - Dayton Dragons    \n",
       "1               Parkview Field - Fort Wayne TinCaps    \n",
       "2                Classic Park- Lake County Captains    \n",
       "3              ABC Supply Stadium - Beloit Sky Carp    \n",
       "4  Veterans Memorial Stadium - Cedar Rapids Kernels    \n",
       "\n",
       "                                                foul  \\\n",
       "0  [(-84.18557, 39.7642091), (-84.1849444, 39.764...   \n",
       "1  [(-85.1429982, 41.0741133), (-85.1432208, 41.0...   \n",
       "2  [(-81.4362001, 41.6407581), (-81.4362008, 41.6...   \n",
       "3  [(-89.0406651, 42.4971349), (-89.0408006, 42.4...   \n",
       "4  [(-91.6867962, 41.9677456), (-91.6867801, 41.9...   \n",
       "\n",
       "                                                 fop         level  \\\n",
       "0  [(-84.18557, 39.7642091), (-84.1846064, 39.763...  Professional   \n",
       "1  [(-85.1429982, 41.0741133), (-85.1418777, 41.0...  Professional   \n",
       "2  [(-81.4362001, 41.6407581), (-81.4350347, 41.6...  Professional   \n",
       "3  [(-89.0406651, 42.4971349), (-89.0394729, 42.4...  Professional   \n",
       "4  [(-91.6867962, 41.9677456), (-91.6856006, 41.9...  Professional   \n",
       "\n",
       "                  home_plate  \n",
       "0    (-84.18557, 39.7642091)  \n",
       "1  (-85.1429982, 41.0741133)  \n",
       "2  (-81.4362001, 41.6407581)  \n",
       "3  (-89.0406651, 42.4971349)  \n",
       "4  (-91.6867962, 41.9677456)  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()\n",
    "\n",
    "## Value counts for the fop_direction column\n",
    "df_cleaned['level'].value_counts()\n",
    "\n",
    "## Value counts for the foul_direction column\n",
    "# df_cleaned['foul_direction'].value_counts()\n",
    "\n",
    "df_cleaned.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import transform\n",
    "\n",
    "\n",
    "def calculate_area(coords):\n",
    "    # Create a Polygon object from the coordinates\n",
    "    polygon = Polygon(coords)\n",
    "\n",
    "    # Calculate the centroid of the polygon\n",
    "    centroid = polygon.centroid\n",
    "\n",
    "    # Create a custom LAEA projection centered on the centroid\n",
    "    custom_projection = f\"+proj=laea +lat_0={centroid.y} +lon_0={centroid.x} +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs\"\n",
    "\n",
    "    # Create a transformer for converting coordinates to the custom LAEA projection\n",
    "    transformer = pyproj.Transformer.from_crs(\n",
    "        pyproj.CRS(\"EPSG:4326\"),  # WGS 84 (latitude and longitude)\n",
    "        pyproj.CRS(custom_projection),  # Custom LAEA projection\n",
    "        always_xy=True\n",
    "    )\n",
    "\n",
    "    # Define a function to transform coordinates using the transformer\n",
    "    def transform_coordinates(x, y):\n",
    "        return transformer.transform(x, y)\n",
    "\n",
    "    # Convert the coordinates to the custom LAEA projection\n",
    "    polygon_laea = transform(transform_coordinates, polygon)\n",
    "\n",
    "    # Calculate the area in square meters\n",
    "    area_sqm = polygon_laea.area\n",
    "\n",
    "    # Convert the area to square feet (1 square meter = 10.764 square feet)\n",
    "    area_sqft = area_sqm * 10.764\n",
    "\n",
    "    return area_sqft\n",
    "\n",
    "\n",
    "\n",
    "### Call Function and add to dataframe\n",
    "df_cleaned['foul_area_sqft'] = df_cleaned['foul'].apply(calculate_area)\n",
    "df_cleaned['fop_area_sqft'] = df_cleaned['fop'].apply(calculate_area)\n",
    "\n",
    "## Calculate the total area of the field and the ratio of foul area to field area\n",
    "df_cleaned['field_area_sqft'] = df_cleaned['foul_area_sqft'] + df_cleaned['fop_area_sqft']\n",
    "## Percentage foul area\n",
    "df_cleaned['foul_area_per'] = df_cleaned['foul_area_sqft'] / df_cleaned['field_area_sqft']\n",
    "## Fair to Foul Ratio\n",
    "df_cleaned['fair_to_foul'] = df_cleaned['fop_area_sqft'] / df_cleaned['foul_area_sqft']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import great_circle\n",
    "import numpy as np\n",
    "\n",
    "def interpolate_points(start, end, length_ratio):\n",
    "    start_np = np.array(start)\n",
    "    end_np = np.array(end)\n",
    "    return tuple(start_np + (end_np - start_np) * length_ratio)\n",
    "\n",
    "def calculate_distances(home_plate, outfield_coords, num_points=30):\n",
    "    def is_same_point(point1, point2, tolerance=1e-6):\n",
    "        return abs(point1[0] - point2[0]) < tolerance and abs(point1[1] - point2[1]) < tolerance\n",
    "\n",
    "    home_plate_lat_lon = (home_plate[1], home_plate[0])\n",
    "    distances = []\n",
    "\n",
    "    # Calculate total line length\n",
    "    total_length = 0\n",
    "    segments = []\n",
    "    for i in range(len(outfield_coords) - 1):\n",
    "        start = outfield_coords[i]\n",
    "        end = outfield_coords[i + 1]\n",
    "        if not is_same_point(home_plate, start) and not is_same_point(home_plate, end):\n",
    "            segment_length = great_circle((start[1], start[0]), (end[1], end[0])).feet\n",
    "            segments.append((start, end, segment_length))\n",
    "            total_length += segment_length\n",
    "\n",
    "    # Calculate the distance between equally spaced points\n",
    "    spacing = total_length / (num_points - 1)\n",
    "\n",
    "    # Interpolate points and calculate distances\n",
    "    current_length = 0\n",
    "    segment_index = 0\n",
    "    for i in range(num_points):\n",
    "        while segment_index < len(segments) - 1 and current_length > segments[segment_index][2]:\n",
    "            current_length -= segments[segment_index][2]\n",
    "            segment_index += 1\n",
    "\n",
    "        start, end, segment_length = segments[segment_index]\n",
    "        length_ratio = current_length / segment_length\n",
    "        point = interpolate_points(start, end, length_ratio)\n",
    "        distance = round(great_circle(home_plate_lat_lon, (point[1], point[0])).feet)\n",
    "        distances.append(distance)\n",
    "\n",
    "        current_length += spacing\n",
    "\n",
    "    return distances\n",
    "\n",
    "# Calculate distances for each row\n",
    "df_cleaned['distances'] = df_cleaned.apply(lambda row: calculate_distances(row['home_plate'], row['fop']), axis=1)\n",
    "\n",
    "# Calculate max, min, and average distances for each row\n",
    "df_cleaned['max_distance'] = df_cleaned['distances'].apply(max)\n",
    "df_cleaned['min_distance'] = df_cleaned['distances'].apply(min)\n",
    "df_cleaned['avg_distance'] = df_cleaned['distances'].apply(lambda distances: sum(distances) / len(distances))\n",
    "# get the median distance\n",
    "df_cleaned['median_distance'] = df_cleaned['distances'].apply(lambda distances: np.median(distances))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30    716\n",
       "Name: num_distances, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Figure out how long the distance list is for each row\n",
    "df_cleaned['num_distances'] = df_cleaned['distances'].apply(len)\n",
    "\n",
    "## Print the value counts for the 'num_distances' column\n",
    "df_cleaned['num_distances'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Calculate Ranks for each field\n",
    "### Grouped by level\n",
    "\n",
    "def rank_fields(df):\n",
    "    # Calculate the rank for each category\n",
    "    df['max_distance_rank'] = df['max_distance'].rank(ascending=False, method='min')\n",
    "    df['min_distance_rank'] = df['min_distance'].rank(ascending=False, method='min')\n",
    "    df['avg_distance_rank'] = df['avg_distance'].rank(ascending=False, method='min')\n",
    "    df['field_area_rank'] = df['field_area_sqft'].rank(ascending=False, method='min')\n",
    "    df['ratio_rank'] = df['fair_to_foul'].rank(ascending=False, method='min')\n",
    "\n",
    "    return df\n",
    "\n",
    "# Group the DataFrame by level and apply the rank_fields function to each group\n",
    "df_ranked = df_cleaned.groupby('level').apply(rank_fields)\n",
    "\n",
    "# Reset the index to get the original DataFrame structure\n",
    "df_ranked.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>park_name</th>\n",
       "      <th>foul</th>\n",
       "      <th>fop</th>\n",
       "      <th>level</th>\n",
       "      <th>home_plate</th>\n",
       "      <th>foul_area_sqft</th>\n",
       "      <th>fop_area_sqft</th>\n",
       "      <th>field_area_sqft</th>\n",
       "      <th>foul_area_per</th>\n",
       "      <th>fair_to_foul</th>\n",
       "      <th>...</th>\n",
       "      <th>max_distance</th>\n",
       "      <th>min_distance</th>\n",
       "      <th>avg_distance</th>\n",
       "      <th>median_distance</th>\n",
       "      <th>num_distances</th>\n",
       "      <th>max_distance_rank</th>\n",
       "      <th>min_distance_rank</th>\n",
       "      <th>avg_distance_rank</th>\n",
       "      <th>field_area_rank</th>\n",
       "      <th>ratio_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [park_name, foul, fop, level, home_plate, foul_area_sqft, fop_area_sqft, field_area_sqft, foul_area_per, fair_to_foul, distances, max_distance, min_distance, avg_distance, median_distance, num_distances, max_distance_rank, min_distance_rank, avg_distance_rank, field_area_rank, ratio_rank]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Rename df bnack to df_cleaned\n",
    "df_cleaned = df_ranked\n",
    "\n",
    "## Show samples of the data from each level\n",
    "\n",
    "df_ranked[df_ranked['level'] == 'high_school'].head(10)\n",
    "\n",
    "# df_ranked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Orienting the map to the home plate location ####\n",
    "\n",
    "### Find the center of the field\n",
    "def calculate_centroid(coords):\n",
    "    x_coords = [coord[0] for coord in coords]\n",
    "    y_coords = [coord[1] for coord in coords]\n",
    "    centroid_x = sum(x_coords) / len(coords)\n",
    "    centroid_y = sum(y_coords) / len(coords)\n",
    "    return (centroid_x, centroid_y)\n",
    "\n",
    "\n",
    "## Find the bearing between the home plate and the center of the field\n",
    "import math\n",
    "\n",
    "def calculate_bearing(point1, point2):\n",
    "    lat1, lon1 = math.radians(point1[1]), math.radians(point1[0])\n",
    "    lat2, lon2 = math.radians(point2[1]), math.radians(point2[0])\n",
    "\n",
    "    d_lon = lon2 - lon1\n",
    "\n",
    "    x = math.cos(lat2) * math.sin(d_lon)\n",
    "    y = math.cos(lat1) * math.sin(lat2) - math.sin(lat1) * math.cos(lat2) * math.cos(d_lon)\n",
    "\n",
    "    bearing = math.degrees(math.atan2(x, y))\n",
    "    bearing = (bearing + 360) % 360  # Normalize the bearing to the range [0, 360)\n",
    "\n",
    "    return bearing\n",
    "\n",
    "### Function to classify direction in laymans terms North, South, East, West, ect\n",
    "def degrees_to_cardinal_direction(degrees):\n",
    "    directions = ['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW', 'N']\n",
    "    index = round(degrees / 45)\n",
    "    return directions[index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the centroid of the outfield fence coordinates for each row\n",
    "df_cleaned['fop_centroid'] = df_cleaned['fop'].apply(lambda coords: calculate_centroid(coords[1:]))\n",
    "\n",
    "# Calculate the bearing between home plate and the centroid for each row\n",
    "df_cleaned['field_orientation'] = df_cleaned.apply(lambda row: calculate_bearing(row['home_plate'], row['fop_centroid']), axis=1)\n",
    "\n",
    "# Convert the bearing to a cardinal direction\n",
    "df_cleaned['field_cardinal_direction'] = df_cleaned['field_orientation'].apply(degrees_to_cardinal_direction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rename the Cleaned Dataframe back to the default name\n",
    "# df = df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### In the fop, foul and home_plate columns, the coordinates are in the format (longitude, latitude).\n",
    "# ### This is the opposite of the format that is used in Google Maps, so we need to reverse the order of the coordinates.\n",
    "\n",
    "# df['fop'] = df['fop'].apply(lambda coords: [(coord[1], coord[0]) for coord in coords])\n",
    "# df['foul'] = df['foul'].apply(lambda coords: [(coord[1], coord[0]) for coord in coords])\n",
    "# df['home_plate'] = df['home_plate'].apply(lambda coord: (coord[1], coord[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing coordinates: 100%|██████████| 716/716 [05:58<00:00,  2.00it/s]\n"
     ]
    }
   ],
   "source": [
    "### Get Geolocation of each field based on home plate coordinates and return state and country\n",
    "### This block takes a long time to run - will need to revisit\n",
    "## up to ten minutes\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut, GeocoderServiceError\n",
    "from tqdm import tqdm\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"baseball_field_locator\")\n",
    "\n",
    "# Function to get location information\n",
    "def get_location_info(lng, lat):\n",
    "    try:\n",
    "        location = geolocator.reverse((lat, lng), timeout=10)\n",
    "        state = location.raw['address'].get('state', None)\n",
    "        country = location.raw['address'].get('country', None)\n",
    "        return state, country\n",
    "    except GeocoderTimedOut:\n",
    "        print(f\"GeocoderTimedOut error for coordinates: ({lng}, {lat})\")\n",
    "        return None, None\n",
    "    except GeocoderServiceError:\n",
    "        print(f\"GeocoderServiceError for coordinates: ({lng}, {lat})\")\n",
    "        return None, None\n",
    "\n",
    "# Extract the first coordinate for each field\n",
    "df_cleaned['lng'], df_cleaned['lat'] = zip(*df_cleaned['home_plate'].apply(lambda x: x))\n",
    "\n",
    "# Wrap the DataFrame apply function with tqdm for progress indication\n",
    "tqdm.pandas(desc=\"Processing coordinates\")\n",
    "\n",
    "# Get state and country information for each field\n",
    "df_cleaned[['state', 'country']] = df_cleaned.progress_apply(lambda row: get_location_info(row['lng'], row['lat']), axis=1, result_type='expand')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>park_name</th>\n",
       "      <th>foul</th>\n",
       "      <th>fop</th>\n",
       "      <th>level</th>\n",
       "      <th>home_plate</th>\n",
       "      <th>foul_area_sqft</th>\n",
       "      <th>fop_area_sqft</th>\n",
       "      <th>field_area_sqft</th>\n",
       "      <th>foul_area_per</th>\n",
       "      <th>fair_to_foul</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_distance_rank</th>\n",
       "      <th>field_area_rank</th>\n",
       "      <th>ratio_rank</th>\n",
       "      <th>fop_centroid</th>\n",
       "      <th>field_orientation</th>\n",
       "      <th>field_cardinal_direction</th>\n",
       "      <th>lng</th>\n",
       "      <th>lat</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Day Air Ballpark - Dayton Dragons</td>\n",
       "      <td>[(-84.18557, 39.7642091), (-84.1849444, 39.764...</td>\n",
       "      <td>[(-84.18557, 39.7642091), (-84.1846064, 39.763...</td>\n",
       "      <td>Professional</td>\n",
       "      <td>(-84.18557, 39.7642091)</td>\n",
       "      <td>21024.772229</td>\n",
       "      <td>105045.871336</td>\n",
       "      <td>126070.643565</td>\n",
       "      <td>0.166770</td>\n",
       "      <td>4.996291</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(-84.18450286190476, 39.76433504761904)</td>\n",
       "      <td>81.270617</td>\n",
       "      <td>E</td>\n",
       "      <td>-84.185570</td>\n",
       "      <td>39.764209</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parkview Field - Fort Wayne TinCaps</td>\n",
       "      <td>[(-85.1429982, 41.0741133), (-85.1432208, 41.0...</td>\n",
       "      <td>[(-85.1429982, 41.0741133), (-85.1418777, 41.0...</td>\n",
       "      <td>Professional</td>\n",
       "      <td>(-85.1429982, 41.0741133)</td>\n",
       "      <td>18930.688419</td>\n",
       "      <td>106347.552434</td>\n",
       "      <td>125278.240854</td>\n",
       "      <td>0.151109</td>\n",
       "      <td>5.617733</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(-85.14238439622642, 41.074847907547166)</td>\n",
       "      <td>32.206090</td>\n",
       "      <td>NE</td>\n",
       "      <td>-85.142998</td>\n",
       "      <td>41.074113</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Classic Park- Lake County Captains</td>\n",
       "      <td>[(-81.4362001, 41.6407581), (-81.4362008, 41.6...</td>\n",
       "      <td>[(-81.4362001, 41.6407581), (-81.4350347, 41.6...</td>\n",
       "      <td>Professional</td>\n",
       "      <td>(-81.4362001, 41.6407581)</td>\n",
       "      <td>28482.877660</td>\n",
       "      <td>100156.404502</td>\n",
       "      <td>128639.282163</td>\n",
       "      <td>0.221417</td>\n",
       "      <td>3.516372</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>(-81.4353300611111, 41.641280155555556)</td>\n",
       "      <td>51.238183</td>\n",
       "      <td>NE</td>\n",
       "      <td>-81.436200</td>\n",
       "      <td>41.640758</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABC Supply Stadium - Beloit Sky Carp</td>\n",
       "      <td>[(-89.0406651, 42.4971349), (-89.0408006, 42.4...</td>\n",
       "      <td>[(-89.0406651, 42.4971349), (-89.0394729, 42.4...</td>\n",
       "      <td>Professional</td>\n",
       "      <td>(-89.0406651, 42.4971349)</td>\n",
       "      <td>21821.073825</td>\n",
       "      <td>108881.945101</td>\n",
       "      <td>130703.018927</td>\n",
       "      <td>0.166952</td>\n",
       "      <td>4.989761</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(-89.03980635652174, 42.49780626086957)</td>\n",
       "      <td>43.322268</td>\n",
       "      <td>NE</td>\n",
       "      <td>-89.040665</td>\n",
       "      <td>42.497135</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Veterans Memorial Stadium - Cedar Rapids Kernels</td>\n",
       "      <td>[(-91.6867962, 41.9677456), (-91.6867801, 41.9...</td>\n",
       "      <td>[(-91.6867962, 41.9677456), (-91.6856006, 41.9...</td>\n",
       "      <td>Professional</td>\n",
       "      <td>(-91.6867962, 41.9677456)</td>\n",
       "      <td>23059.618818</td>\n",
       "      <td>107463.184238</td>\n",
       "      <td>130522.803056</td>\n",
       "      <td>0.176671</td>\n",
       "      <td>4.660232</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>(-91.68599359999999, 41.96836619130434)</td>\n",
       "      <td>43.877626</td>\n",
       "      <td>NE</td>\n",
       "      <td>-91.686796</td>\n",
       "      <td>41.967746</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dozer Park - Peoria Chiefs</td>\n",
       "      <td>[(-89.5982058, 40.687291), (-89.5981066, 40.68...</td>\n",
       "      <td>[(-89.5982058, 40.687291), (-89.5970934, 40.68...</td>\n",
       "      <td>Professional</td>\n",
       "      <td>(-89.5982058, 40.687291)</td>\n",
       "      <td>28117.804689</td>\n",
       "      <td>104957.227655</td>\n",
       "      <td>133075.032345</td>\n",
       "      <td>0.211293</td>\n",
       "      <td>3.732768</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(-89.5973700285714, 40.68782854285715)</td>\n",
       "      <td>49.695115</td>\n",
       "      <td>NE</td>\n",
       "      <td>-89.598206</td>\n",
       "      <td>40.687291</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Modern Woodmen Park - Quad Cities River Bandits</td>\n",
       "      <td>[(-90.5822843, 41.5187795), (-90.5810317, 41.5...</td>\n",
       "      <td>[(-90.5822843, 41.5187795), (-90.582236, 41.51...</td>\n",
       "      <td>Professional</td>\n",
       "      <td>(-90.5822843, 41.5187795)</td>\n",
       "      <td>29069.390702</td>\n",
       "      <td>104807.276722</td>\n",
       "      <td>133876.667424</td>\n",
       "      <td>0.217136</td>\n",
       "      <td>3.605417</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>(-90.58147389999999, 41.51813110357143)</td>\n",
       "      <td>136.898692</td>\n",
       "      <td>SE</td>\n",
       "      <td>-90.582284</td>\n",
       "      <td>41.518780</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Four Winds Field - South Bend Cubs</td>\n",
       "      <td>[(-86.255784, 41.6701882), (-86.2558001, 41.67...</td>\n",
       "      <td>[(-86.255784, 41.6701882), (-86.2545408, 41.67...</td>\n",
       "      <td>Professional</td>\n",
       "      <td>(-86.255784, 41.6701882)</td>\n",
       "      <td>26982.658345</td>\n",
       "      <td>107096.790783</td>\n",
       "      <td>134079.449128</td>\n",
       "      <td>0.201244</td>\n",
       "      <td>3.969097</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>(-86.254978525, 41.67087549285714)</td>\n",
       "      <td>41.199472</td>\n",
       "      <td>NE</td>\n",
       "      <td>-86.255784</td>\n",
       "      <td>41.670188</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Neuroscience Group Field - Wisconsin Timber Ra...</td>\n",
       "      <td>[(-88.4690216, 44.2831851), (-88.4689948, 44.2...</td>\n",
       "      <td>[(-88.4690216, 44.2831851), (-88.4677824, 44.2...</td>\n",
       "      <td>Professional</td>\n",
       "      <td>(-88.4690216, 44.2831851)</td>\n",
       "      <td>25294.513182</td>\n",
       "      <td>104915.209954</td>\n",
       "      <td>130209.723136</td>\n",
       "      <td>0.194260</td>\n",
       "      <td>4.147746</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>(-88.46810904285715, 44.28370243809523)</td>\n",
       "      <td>51.624299</td>\n",
       "      <td>NE</td>\n",
       "      <td>-88.469022</td>\n",
       "      <td>44.283185</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Harvard university</td>\n",
       "      <td>[(-71.1288446, 42.3665934), (-71.1294125, 42.3...</td>\n",
       "      <td>[(-71.1288446, 42.3665934), (-71.1277583, 42.3...</td>\n",
       "      <td>College</td>\n",
       "      <td>(-71.1288446, 42.3665934)</td>\n",
       "      <td>29575.202639</td>\n",
       "      <td>104919.949915</td>\n",
       "      <td>134495.152554</td>\n",
       "      <td>0.219898</td>\n",
       "      <td>3.547565</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>(-71.12852331428572, 42.36741510952381)</td>\n",
       "      <td>16.113125</td>\n",
       "      <td>N</td>\n",
       "      <td>-71.128845</td>\n",
       "      <td>42.366593</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Indiana State</td>\n",
       "      <td>[(-87.4163927, 39.4786288), (-87.4164034, 39.4...</td>\n",
       "      <td>[(-87.4163927, 39.4786288), (-87.4152138, 39.4...</td>\n",
       "      <td>College</td>\n",
       "      <td>(-87.4163927, 39.4786288)</td>\n",
       "      <td>31868.040960</td>\n",
       "      <td>104324.637931</td>\n",
       "      <td>136192.678891</td>\n",
       "      <td>0.233992</td>\n",
       "      <td>3.273645</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>(-87.41569439166666, 39.47926414166667)</td>\n",
       "      <td>40.309541</td>\n",
       "      <td>NE</td>\n",
       "      <td>-87.416393</td>\n",
       "      <td>39.478629</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wake Forrest</td>\n",
       "      <td>[(-80.2524122, 36.129499), (-80.2524411, 36.13...</td>\n",
       "      <td>[(-80.2524122, 36.129499), (-80.2513896, 36.12...</td>\n",
       "      <td>College</td>\n",
       "      <td>(-80.2524122, 36.129499)</td>\n",
       "      <td>32279.377357</td>\n",
       "      <td>97332.813316</td>\n",
       "      <td>129612.190673</td>\n",
       "      <td>0.249046</td>\n",
       "      <td>3.015325</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>(-80.25173832307692, 36.13009030769231)</td>\n",
       "      <td>42.628344</td>\n",
       "      <td>NE</td>\n",
       "      <td>-80.252412</td>\n",
       "      <td>36.129499</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>U of South Carolina</td>\n",
       "      <td>[(-81.0428983, 33.9859967), (-81.0433355, 33.9...</td>\n",
       "      <td>[(-81.0428983, 33.9859967), (-81.0419112, 33.9...</td>\n",
       "      <td>College</td>\n",
       "      <td>(-81.0428983, 33.9859967)</td>\n",
       "      <td>23135.578200</td>\n",
       "      <td>101712.273767</td>\n",
       "      <td>124847.851966</td>\n",
       "      <td>0.185310</td>\n",
       "      <td>4.396358</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>(-81.04255204705882, 33.986810211764706)</td>\n",
       "      <td>19.438738</td>\n",
       "      <td>N</td>\n",
       "      <td>-81.042898</td>\n",
       "      <td>33.985997</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Monongalia County Ballpark - WV Black Bears</td>\n",
       "      <td>[(-79.9964328, 39.6443268), (-79.9952821, 39.6...</td>\n",
       "      <td>[(-79.9964328, 39.6443268), (-79.9965709, 39.6...</td>\n",
       "      <td>College</td>\n",
       "      <td>(-79.9964328, 39.6443268)</td>\n",
       "      <td>20755.447256</td>\n",
       "      <td>107505.885742</td>\n",
       "      <td>128261.332998</td>\n",
       "      <td>0.161822</td>\n",
       "      <td>5.179647</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(-79.99565485789473, 39.64371364736842)</td>\n",
       "      <td>135.667082</td>\n",
       "      <td>SE</td>\n",
       "      <td>-79.996433</td>\n",
       "      <td>39.644327</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>U of Virginia</td>\n",
       "      <td>[(-78.5141847, 38.0457835), (-78.5133961, 38.0...</td>\n",
       "      <td>[(-78.5141847, 38.0457835), (-78.5133371, 38.0...</td>\n",
       "      <td>College</td>\n",
       "      <td>(-78.5141847, 38.0457835)</td>\n",
       "      <td>19922.292990</td>\n",
       "      <td>107109.980994</td>\n",
       "      <td>127032.273985</td>\n",
       "      <td>0.156829</td>\n",
       "      <td>5.376388</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>(-78.51302542592592, 38.045753770370375)</td>\n",
       "      <td>91.864784</td>\n",
       "      <td>E</td>\n",
       "      <td>-78.514185</td>\n",
       "      <td>38.045783</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Boston C.</td>\n",
       "      <td>[(-71.1603978, 42.3443347), (-71.1591854, 42.3...</td>\n",
       "      <td>[(-71.1603978, 42.3443347), (-71.1603146, 42.3...</td>\n",
       "      <td>College</td>\n",
       "      <td>(-71.1603978, 42.3443347)</td>\n",
       "      <td>27596.655702</td>\n",
       "      <td>108520.343491</td>\n",
       "      <td>136116.999193</td>\n",
       "      <td>0.202742</td>\n",
       "      <td>3.932373</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>(-71.15945230714286, 42.343707471428566)</td>\n",
       "      <td>131.909089</td>\n",
       "      <td>SE</td>\n",
       "      <td>-71.160398</td>\n",
       "      <td>42.344335</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Oregon University</td>\n",
       "      <td>[(-123.0659956, 44.0593731), (-123.0647276, 44...</td>\n",
       "      <td>[(-123.0659956, 44.0593731), (-123.0658863, 44...</td>\n",
       "      <td>College</td>\n",
       "      <td>(-123.0659956, 44.0593731)</td>\n",
       "      <td>22666.475382</td>\n",
       "      <td>107679.700890</td>\n",
       "      <td>130346.176271</td>\n",
       "      <td>0.173894</td>\n",
       "      <td>4.750615</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>(-123.06507869411764, 44.05885924705883)</td>\n",
       "      <td>127.948702</td>\n",
       "      <td>SE</td>\n",
       "      <td>-123.065996</td>\n",
       "      <td>44.059373</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Costal Carolina</td>\n",
       "      <td>[(-79.0154049, 33.7935777), (-79.014391, 33.79...</td>\n",
       "      <td>[(-79.0154049, 33.7935777), (-79.015185, 33.79...</td>\n",
       "      <td>College</td>\n",
       "      <td>(-79.0154049, 33.7935777)</td>\n",
       "      <td>24333.208254</td>\n",
       "      <td>97282.766200</td>\n",
       "      <td>121615.974454</td>\n",
       "      <td>0.200082</td>\n",
       "      <td>3.997942</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>(-79.0145578318182, 33.793129718181824)</td>\n",
       "      <td>122.471556</td>\n",
       "      <td>SE</td>\n",
       "      <td>-79.015405</td>\n",
       "      <td>33.793578</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Duke - Jack Coombs Field</td>\n",
       "      <td>[(-78.9439974, 35.9975897), (-78.9449925, 35.9...</td>\n",
       "      <td>[(-78.9439974, 35.9975897), (-78.9435166, 35.9...</td>\n",
       "      <td>College</td>\n",
       "      <td>(-78.9439974, 35.9975897)</td>\n",
       "      <td>25673.876201</td>\n",
       "      <td>111627.386448</td>\n",
       "      <td>137301.262649</td>\n",
       "      <td>0.186989</td>\n",
       "      <td>4.347898</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>(-78.94438305961538, 35.99846048461538)</td>\n",
       "      <td>340.286878</td>\n",
       "      <td>N</td>\n",
       "      <td>-78.943997</td>\n",
       "      <td>35.997590</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Stanford - Klein Field</td>\n",
       "      <td>[(-122.1587602, 37.4321552), (-122.157989, 37....</td>\n",
       "      <td>[(-122.1587602, 37.4321552), (-122.1596171, 37...</td>\n",
       "      <td>College</td>\n",
       "      <td>(-122.1587602, 37.4321552)</td>\n",
       "      <td>34315.496536</td>\n",
       "      <td>105725.992275</td>\n",
       "      <td>140041.488811</td>\n",
       "      <td>0.245038</td>\n",
       "      <td>3.080998</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>(-122.15886702142856, 37.43123528214285)</td>\n",
       "      <td>185.268315</td>\n",
       "      <td>S</td>\n",
       "      <td>-122.158760</td>\n",
       "      <td>37.432155</td>\n",
       "      <td>California</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            park_name  \\\n",
       "0                  Day Air Ballpark - Dayton Dragons    \n",
       "1                Parkview Field - Fort Wayne TinCaps    \n",
       "2                 Classic Park- Lake County Captains    \n",
       "3               ABC Supply Stadium - Beloit Sky Carp    \n",
       "4   Veterans Memorial Stadium - Cedar Rapids Kernels    \n",
       "5                         Dozer Park - Peoria Chiefs    \n",
       "6    Modern Woodmen Park - Quad Cities River Bandits    \n",
       "7                 Four Winds Field - South Bend Cubs    \n",
       "8   Neuroscience Group Field - Wisconsin Timber Ra...   \n",
       "9                                 Harvard university    \n",
       "10                                     Indiana State    \n",
       "11                                      Wake Forrest    \n",
       "12                               U of South Carolina    \n",
       "13       Monongalia County Ballpark - WV Black Bears    \n",
       "14                                     U of Virginia    \n",
       "15                                         Boston C.    \n",
       "16                                 Oregon University    \n",
       "17                                   Costal Carolina    \n",
       "18                          Duke - Jack Coombs Field    \n",
       "19                            Stanford - Klein Field    \n",
       "\n",
       "                                                 foul  \\\n",
       "0   [(-84.18557, 39.7642091), (-84.1849444, 39.764...   \n",
       "1   [(-85.1429982, 41.0741133), (-85.1432208, 41.0...   \n",
       "2   [(-81.4362001, 41.6407581), (-81.4362008, 41.6...   \n",
       "3   [(-89.0406651, 42.4971349), (-89.0408006, 42.4...   \n",
       "4   [(-91.6867962, 41.9677456), (-91.6867801, 41.9...   \n",
       "5   [(-89.5982058, 40.687291), (-89.5981066, 40.68...   \n",
       "6   [(-90.5822843, 41.5187795), (-90.5810317, 41.5...   \n",
       "7   [(-86.255784, 41.6701882), (-86.2558001, 41.67...   \n",
       "8   [(-88.4690216, 44.2831851), (-88.4689948, 44.2...   \n",
       "9   [(-71.1288446, 42.3665934), (-71.1294125, 42.3...   \n",
       "10  [(-87.4163927, 39.4786288), (-87.4164034, 39.4...   \n",
       "11  [(-80.2524122, 36.129499), (-80.2524411, 36.13...   \n",
       "12  [(-81.0428983, 33.9859967), (-81.0433355, 33.9...   \n",
       "13  [(-79.9964328, 39.6443268), (-79.9952821, 39.6...   \n",
       "14  [(-78.5141847, 38.0457835), (-78.5133961, 38.0...   \n",
       "15  [(-71.1603978, 42.3443347), (-71.1591854, 42.3...   \n",
       "16  [(-123.0659956, 44.0593731), (-123.0647276, 44...   \n",
       "17  [(-79.0154049, 33.7935777), (-79.014391, 33.79...   \n",
       "18  [(-78.9439974, 35.9975897), (-78.9449925, 35.9...   \n",
       "19  [(-122.1587602, 37.4321552), (-122.157989, 37....   \n",
       "\n",
       "                                                  fop         level  \\\n",
       "0   [(-84.18557, 39.7642091), (-84.1846064, 39.763...  Professional   \n",
       "1   [(-85.1429982, 41.0741133), (-85.1418777, 41.0...  Professional   \n",
       "2   [(-81.4362001, 41.6407581), (-81.4350347, 41.6...  Professional   \n",
       "3   [(-89.0406651, 42.4971349), (-89.0394729, 42.4...  Professional   \n",
       "4   [(-91.6867962, 41.9677456), (-91.6856006, 41.9...  Professional   \n",
       "5   [(-89.5982058, 40.687291), (-89.5970934, 40.68...  Professional   \n",
       "6   [(-90.5822843, 41.5187795), (-90.582236, 41.51...  Professional   \n",
       "7   [(-86.255784, 41.6701882), (-86.2545408, 41.67...  Professional   \n",
       "8   [(-88.4690216, 44.2831851), (-88.4677824, 44.2...  Professional   \n",
       "9   [(-71.1288446, 42.3665934), (-71.1277583, 42.3...       College   \n",
       "10  [(-87.4163927, 39.4786288), (-87.4152138, 39.4...       College   \n",
       "11  [(-80.2524122, 36.129499), (-80.2513896, 36.12...       College   \n",
       "12  [(-81.0428983, 33.9859967), (-81.0419112, 33.9...       College   \n",
       "13  [(-79.9964328, 39.6443268), (-79.9965709, 39.6...       College   \n",
       "14  [(-78.5141847, 38.0457835), (-78.5133371, 38.0...       College   \n",
       "15  [(-71.1603978, 42.3443347), (-71.1603146, 42.3...       College   \n",
       "16  [(-123.0659956, 44.0593731), (-123.0658863, 44...       College   \n",
       "17  [(-79.0154049, 33.7935777), (-79.015185, 33.79...       College   \n",
       "18  [(-78.9439974, 35.9975897), (-78.9435166, 35.9...       College   \n",
       "19  [(-122.1587602, 37.4321552), (-122.1596171, 37...       College   \n",
       "\n",
       "                    home_plate  foul_area_sqft  fop_area_sqft  \\\n",
       "0      (-84.18557, 39.7642091)    21024.772229  105045.871336   \n",
       "1    (-85.1429982, 41.0741133)    18930.688419  106347.552434   \n",
       "2    (-81.4362001, 41.6407581)    28482.877660  100156.404502   \n",
       "3    (-89.0406651, 42.4971349)    21821.073825  108881.945101   \n",
       "4    (-91.6867962, 41.9677456)    23059.618818  107463.184238   \n",
       "5     (-89.5982058, 40.687291)    28117.804689  104957.227655   \n",
       "6    (-90.5822843, 41.5187795)    29069.390702  104807.276722   \n",
       "7     (-86.255784, 41.6701882)    26982.658345  107096.790783   \n",
       "8    (-88.4690216, 44.2831851)    25294.513182  104915.209954   \n",
       "9    (-71.1288446, 42.3665934)    29575.202639  104919.949915   \n",
       "10   (-87.4163927, 39.4786288)    31868.040960  104324.637931   \n",
       "11    (-80.2524122, 36.129499)    32279.377357   97332.813316   \n",
       "12   (-81.0428983, 33.9859967)    23135.578200  101712.273767   \n",
       "13   (-79.9964328, 39.6443268)    20755.447256  107505.885742   \n",
       "14   (-78.5141847, 38.0457835)    19922.292990  107109.980994   \n",
       "15   (-71.1603978, 42.3443347)    27596.655702  108520.343491   \n",
       "16  (-123.0659956, 44.0593731)    22666.475382  107679.700890   \n",
       "17   (-79.0154049, 33.7935777)    24333.208254   97282.766200   \n",
       "18   (-78.9439974, 35.9975897)    25673.876201  111627.386448   \n",
       "19  (-122.1587602, 37.4321552)    34315.496536  105725.992275   \n",
       "\n",
       "    field_area_sqft  foul_area_per  fair_to_foul  ... avg_distance_rank  \\\n",
       "0     126070.643565       0.166770      4.996291  ...              10.0   \n",
       "1     125278.240854       0.151109      5.617733  ...               7.0   \n",
       "2     128639.282163       0.221417      3.516372  ...              15.0   \n",
       "3     130703.018927       0.166952      4.989761  ...               2.0   \n",
       "4     130522.803056       0.176671      4.660232  ...               6.0   \n",
       "5     133075.032345       0.211293      3.732768  ...              13.0   \n",
       "6     133876.667424       0.217136      3.605417  ...               9.0   \n",
       "7     134079.449128       0.201244      3.969097  ...               4.0   \n",
       "8     130209.723136       0.194260      4.147746  ...              11.0   \n",
       "9     134495.152554       0.219898      3.547565  ...              25.0   \n",
       "10    136192.678891       0.233992      3.273645  ...              28.0   \n",
       "11    129612.190673       0.249046      3.015325  ...              51.0   \n",
       "12    124847.851966       0.185310      4.396358  ...              34.0   \n",
       "13    128261.332998       0.161822      5.179647  ...              16.0   \n",
       "14    127032.273985       0.156829      5.376388  ...              17.0   \n",
       "15    136116.999193       0.202742      3.932373  ...              10.0   \n",
       "16    130346.176271       0.173894      4.750615  ...              14.0   \n",
       "17    121615.974454       0.200082      3.997942  ...              54.0   \n",
       "18    137301.262649       0.186989      4.347898  ...               1.0   \n",
       "19    140041.488811       0.245038      3.080998  ...              20.0   \n",
       "\n",
       "    field_area_rank  ratio_rank                              fop_centroid  \\\n",
       "0              16.0         2.0   (-84.18450286190476, 39.76433504761904)   \n",
       "1              17.0         1.0  (-85.14238439622642, 41.074847907547166)   \n",
       "2              13.0        12.0   (-81.4353300611111, 41.641280155555556)   \n",
       "3               9.0         3.0   (-89.03980635652174, 42.49780626086957)   \n",
       "4              11.0         4.0   (-91.68599359999999, 41.96836619130434)   \n",
       "5               8.0         8.0    (-89.5973700285714, 40.68782854285715)   \n",
       "6               7.0        11.0   (-90.58147389999999, 41.51813110357143)   \n",
       "7               6.0         7.0        (-86.254978525, 41.67087549285714)   \n",
       "8              12.0         6.0   (-88.46810904285715, 44.28370243809523)   \n",
       "9              24.0        34.0   (-71.12852331428572, 42.36741510952381)   \n",
       "10             20.0        42.0   (-87.41569439166666, 39.47926414166667)   \n",
       "11             36.0        48.0   (-80.25173832307692, 36.13009030769231)   \n",
       "12             43.0        15.0  (-81.04255204705882, 33.986810211764706)   \n",
       "13             37.0         8.0   (-79.99565485789473, 39.64371364736842)   \n",
       "14             39.0         6.0  (-78.51302542592592, 38.045753770370375)   \n",
       "15             21.0        23.0  (-71.15945230714286, 42.343707471428566)   \n",
       "16             34.0        11.0  (-123.06507869411764, 44.05885924705883)   \n",
       "17             48.0        21.0   (-79.0145578318182, 33.793129718181824)   \n",
       "18             18.0        16.0   (-78.94438305961538, 35.99846048461538)   \n",
       "19             10.0        46.0  (-122.15886702142856, 37.43123528214285)   \n",
       "\n",
       "    field_orientation  field_cardinal_direction         lng        lat  \\\n",
       "0           81.270617                         E  -84.185570  39.764209   \n",
       "1           32.206090                        NE  -85.142998  41.074113   \n",
       "2           51.238183                        NE  -81.436200  41.640758   \n",
       "3           43.322268                        NE  -89.040665  42.497135   \n",
       "4           43.877626                        NE  -91.686796  41.967746   \n",
       "5           49.695115                        NE  -89.598206  40.687291   \n",
       "6          136.898692                        SE  -90.582284  41.518780   \n",
       "7           41.199472                        NE  -86.255784  41.670188   \n",
       "8           51.624299                        NE  -88.469022  44.283185   \n",
       "9           16.113125                         N  -71.128845  42.366593   \n",
       "10          40.309541                        NE  -87.416393  39.478629   \n",
       "11          42.628344                        NE  -80.252412  36.129499   \n",
       "12          19.438738                         N  -81.042898  33.985997   \n",
       "13         135.667082                        SE  -79.996433  39.644327   \n",
       "14          91.864784                         E  -78.514185  38.045783   \n",
       "15         131.909089                        SE  -71.160398  42.344335   \n",
       "16         127.948702                        SE -123.065996  44.059373   \n",
       "17         122.471556                        SE  -79.015405  33.793578   \n",
       "18         340.286878                         N  -78.943997  35.997590   \n",
       "19         185.268315                         S -122.158760  37.432155   \n",
       "\n",
       "             state        country  \n",
       "0             Ohio  United States  \n",
       "1          Indiana  United States  \n",
       "2             Ohio  United States  \n",
       "3        Wisconsin  United States  \n",
       "4             Iowa  United States  \n",
       "5         Illinois  United States  \n",
       "6             Iowa  United States  \n",
       "7          Indiana  United States  \n",
       "8        Wisconsin  United States  \n",
       "9    Massachusetts  United States  \n",
       "10         Indiana  United States  \n",
       "11  North Carolina  United States  \n",
       "12  South Carolina  United States  \n",
       "13   West Virginia  United States  \n",
       "14        Virginia  United States  \n",
       "15   Massachusetts  United States  \n",
       "16          Oregon  United States  \n",
       "17  South Carolina  United States  \n",
       "18  North Carolina  United States  \n",
       "19      California  United States  \n",
       "\n",
       "[20 rows x 28 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the Cleaned Dataframe back to the default name\n",
    "df = df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['park_name', 'foul', 'fop', 'level', 'home_plate', 'foul_area_sqft',\n",
      "       'fop_area_sqft', 'field_area_sqft', 'foul_area_per', 'fair_to_foul',\n",
      "       'distances', 'max_distance', 'min_distance', 'avg_distance',\n",
      "       'median_distance', 'num_distances', 'max_distance_rank',\n",
      "       'min_distance_rank', 'avg_distance_rank', 'field_area_rank',\n",
      "       'ratio_rank', 'fop_centroid', 'field_orientation',\n",
      "       'field_cardinal_direction', 'lng', 'lat', 'state', 'country'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "### Create a dataframe of just high school fields in Michigan\n",
    "hs_df = df[df['level'] == 'High School']\n",
    "\n",
    "## Create a dataframe that is just fields in Michigan\n",
    "mi_df = df[df['state'] == 'Michigan']\n",
    "\n",
    "### Create a dataframe of all other fields\n",
    "other_df = df[df['level'] != 'High School']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### TOGGLE THIS TO CHANGE THE DATAFRAME USED FOR THE REST OF THE NOTEBOOK #########\n",
    "\n",
    "\n",
    "### Rename the michigan dataframe to df so it can be used in the rest of the notebook\n",
    "hs_df = mi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_14448\\3874162956.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hs_df[col] = hs_df['park_name'].apply(lambda x: mhsaa_df.loc[mhsaa_df['best_match'] == x, col].iloc[0] if not mhsaa_df.loc[mhsaa_df['best_match'] == x, col].empty else None)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_14448\\3874162956.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hs_df[col] = hs_df['park_name'].apply(lambda x: mhsaa_df.loc[mhsaa_df['best_match'] == x, col].iloc[0] if not mhsaa_df.loc[mhsaa_df['best_match'] == x, col].empty else None)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_14448\\3874162956.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hs_df[col] = hs_df['park_name'].apply(lambda x: mhsaa_df.loc[mhsaa_df['best_match'] == x, col].iloc[0] if not mhsaa_df.loc[mhsaa_df['best_match'] == x, col].empty else None)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_14448\\3874162956.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hs_df[col] = hs_df['park_name'].apply(lambda x: mhsaa_df.loc[mhsaa_df['best_match'] == x, col].iloc[0] if not mhsaa_df.loc[mhsaa_df['best_match'] == x, col].empty else None)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_14448\\3874162956.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hs_df[col] = hs_df['park_name'].apply(lambda x: name_color_df.loc[name_color_df['best_match'] == x, col].iloc[0] if not name_color_df.loc[name_color_df['best_match'] == x, col].empty else None)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_14448\\3874162956.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hs_df[col] = hs_df['park_name'].apply(lambda x: name_color_df.loc[name_color_df['best_match'] == x, col].iloc[0] if not name_color_df.loc[name_color_df['best_match'] == x, col].empty else None)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_14448\\3874162956.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hs_df[col] = hs_df['park_name'].apply(lambda x: name_color_df.loc[name_color_df['best_match'] == x, col].iloc[0] if not name_color_df.loc[name_color_df['best_match'] == x, col].empty else None)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_14448\\3874162956.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hs_df[col] = hs_df['park_name'].apply(lambda x: name_color_df.loc[name_color_df['best_match'] == x, col].iloc[0] if not name_color_df.loc[name_color_df['best_match'] == x, col].empty else None)\n",
      "C:\\Users\\Justin\\AppData\\Local\\Temp\\ipykernel_14448\\3874162956.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hs_df[col] = hs_df['park_name'].apply(lambda x: name_color_df.loc[name_color_df['best_match'] == x, col].iloc[0] if not name_color_df.loc[name_color_df['best_match'] == x, col].empty else None)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>park_name</th>\n",
       "      <th>foul</th>\n",
       "      <th>fop</th>\n",
       "      <th>level</th>\n",
       "      <th>home_plate</th>\n",
       "      <th>foul_area_sqft</th>\n",
       "      <th>fop_area_sqft</th>\n",
       "      <th>field_area_sqft</th>\n",
       "      <th>foul_area_per</th>\n",
       "      <th>fair_to_foul</th>\n",
       "      <th>...</th>\n",
       "      <th>country</th>\n",
       "      <th>school_id</th>\n",
       "      <th>school_name</th>\n",
       "      <th>students</th>\n",
       "      <th>division</th>\n",
       "      <th>Nickname</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>Color4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Soo High School</td>\n",
       "      <td>[(-84.36583, 46.4813183), (-84.3658206, 46.482...</td>\n",
       "      <td>[(-84.36583, 46.4813183), (-84.3645398, 46.481...</td>\n",
       "      <td>High School</td>\n",
       "      <td>(-84.36583, 46.4813183)</td>\n",
       "      <td>34451.384825</td>\n",
       "      <td>94783.943544</td>\n",
       "      <td>129235.328369</td>\n",
       "      <td>0.266579</td>\n",
       "      <td>2.751238</td>\n",
       "      <td>...</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Frankfort-Elberta Area HS</td>\n",
       "      <td>[(-86.2258505, 44.6344082), (-86.2258357, 44.6...</td>\n",
       "      <td>[(-86.2258505, 44.6344082), (-86.2270454, 44.6...</td>\n",
       "      <td>High School</td>\n",
       "      <td>(-86.2258505, 44.6344082)</td>\n",
       "      <td>25687.658559</td>\n",
       "      <td>86823.965374</td>\n",
       "      <td>112511.623933</td>\n",
       "      <td>0.228311</td>\n",
       "      <td>3.379988</td>\n",
       "      <td>...</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Ironwood HS</td>\n",
       "      <td>[(-90.1514578, 46.457154), (-90.1505766, 46.45...</td>\n",
       "      <td>[(-90.1514578, 46.457154), (-90.15234150000002...</td>\n",
       "      <td>High School</td>\n",
       "      <td>(-90.1514578, 46.457154)</td>\n",
       "      <td>37066.246977</td>\n",
       "      <td>95913.228498</td>\n",
       "      <td>132979.475475</td>\n",
       "      <td>0.278737</td>\n",
       "      <td>2.587616</td>\n",
       "      <td>...</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Red Devils</td>\n",
       "      <td>Red</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Onway Little League Field 2</td>\n",
       "      <td>[(-84.2327091, 45.36070109999999), (-84.232888...</td>\n",
       "      <td>[(-84.2327091, 45.36070109999999), (-84.231915...</td>\n",
       "      <td>Youth</td>\n",
       "      <td>(-84.2327091, 45.36070109999999)</td>\n",
       "      <td>10384.795715</td>\n",
       "      <td>35156.473366</td>\n",
       "      <td>45541.269081</td>\n",
       "      <td>0.228030</td>\n",
       "      <td>3.385379</td>\n",
       "      <td>...</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Morenci HS</td>\n",
       "      <td>[(-84.2069811, 41.7223814), (-84.2058371, 41.7...</td>\n",
       "      <td>[(-84.2069811, 41.7223814), (-84.2071112, 41.7...</td>\n",
       "      <td>High School</td>\n",
       "      <td>(-84.2069811, 41.7223814)</td>\n",
       "      <td>35463.259931</td>\n",
       "      <td>92763.241003</td>\n",
       "      <td>128226.500934</td>\n",
       "      <td>0.276567</td>\n",
       "      <td>2.615756</td>\n",
       "      <td>...</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Bulldogs</td>\n",
       "      <td>Maroon</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        park_name  \\\n",
       "60                Soo High School   \n",
       "61      Frankfort-Elberta Area HS   \n",
       "62                    Ironwood HS   \n",
       "100  Onway Little League Field 2    \n",
       "101                    Morenci HS   \n",
       "\n",
       "                                                  foul  \\\n",
       "60   [(-84.36583, 46.4813183), (-84.3658206, 46.482...   \n",
       "61   [(-86.2258505, 44.6344082), (-86.2258357, 44.6...   \n",
       "62   [(-90.1514578, 46.457154), (-90.1505766, 46.45...   \n",
       "100  [(-84.2327091, 45.36070109999999), (-84.232888...   \n",
       "101  [(-84.2069811, 41.7223814), (-84.2058371, 41.7...   \n",
       "\n",
       "                                                   fop        level  \\\n",
       "60   [(-84.36583, 46.4813183), (-84.3645398, 46.481...  High School   \n",
       "61   [(-86.2258505, 44.6344082), (-86.2270454, 44.6...  High School   \n",
       "62   [(-90.1514578, 46.457154), (-90.15234150000002...  High School   \n",
       "100  [(-84.2327091, 45.36070109999999), (-84.231915...        Youth   \n",
       "101  [(-84.2069811, 41.7223814), (-84.2071112, 41.7...  High School   \n",
       "\n",
       "                           home_plate  foul_area_sqft  fop_area_sqft  \\\n",
       "60            (-84.36583, 46.4813183)    34451.384825   94783.943544   \n",
       "61          (-86.2258505, 44.6344082)    25687.658559   86823.965374   \n",
       "62           (-90.1514578, 46.457154)    37066.246977   95913.228498   \n",
       "100  (-84.2327091, 45.36070109999999)    10384.795715   35156.473366   \n",
       "101         (-84.2069811, 41.7223814)    35463.259931   92763.241003   \n",
       "\n",
       "     field_area_sqft  foul_area_per  fair_to_foul  ...        country  \\\n",
       "60     129235.328369       0.266579      2.751238  ...  United States   \n",
       "61     112511.623933       0.228311      3.379988  ...  United States   \n",
       "62     132979.475475       0.278737      2.587616  ...  United States   \n",
       "100     45541.269081       0.228030      3.385379  ...  United States   \n",
       "101    128226.500934       0.276567      2.615756  ...  United States   \n",
       "\n",
       "     school_id  school_name  students  division    Nickname   Color1  Color2  \\\n",
       "60         NaN         None       NaN      None        None     None    None   \n",
       "61         NaN         None       NaN      None        None     None    None   \n",
       "62         NaN         None       NaN      None  Red Devils     Red    White   \n",
       "100        NaN         None       NaN      None        None     None    None   \n",
       "101        NaN         None       NaN      None    Bulldogs  Maroon    White   \n",
       "\n",
       "     Color3  Color4  \n",
       "60     None     NaN  \n",
       "61     None     NaN  \n",
       "62      NaN     NaN  \n",
       "100    None     NaN  \n",
       "101     NaN     NaN  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "def find_best_match(school_name, choices, score_cutoff=80):\n",
    "    best_match = process.extractOne(school_name, choices, scorer=fuzz.token_sort_ratio, score_cutoff=score_cutoff)\n",
    "    if best_match:\n",
    "        return best_match[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Read CSV files\n",
    "mhsaa_df = pd.read_csv('data/school_info/mhsaa_enrolment_2022.csv')\n",
    "name_color_df = pd.read_csv('data\\school_info\\mhsaa_school_nickname_color_2020.csv')\n",
    "\n",
    "# Get the list of park names from hs_df\n",
    "park_names = hs_df['park_name'].tolist()\n",
    "\n",
    "# Apply find_best_match function to create a new column 'best_match' in mhsaa_df\n",
    "mhsaa_df['best_match'] = mhsaa_df['school_name'].apply(find_best_match, choices=park_names, score_cutoff=90)\n",
    "\n",
    "## Pull the school_id, school_name, students, and division columns from mhsaa_df and add to hs_df\n",
    "columns_to_extract = ['school_id', 'school_name', 'students', 'division']\n",
    "for col in columns_to_extract:\n",
    "    hs_df[col] = hs_df['park_name'].apply(lambda x: mhsaa_df.loc[mhsaa_df['best_match'] == x, col].iloc[0] if not mhsaa_df.loc[mhsaa_df['best_match'] == x, col].empty else None)\n",
    "\n",
    "# Apply find_best_match function to create a new column 'best_match' in name_color_df\n",
    "name_color_df['best_match'] = name_color_df['School'].apply(find_best_match, choices=park_names, score_cutoff=80)\n",
    "\n",
    "## Pull the data from the name_color_df and add to hs_df (Nickname,Color1,Color2,Color3,Color4)\n",
    "columns_to_extract = ['Nickname', 'Color1', 'Color2', 'Color3', 'Color4']\n",
    "for col in columns_to_extract:\n",
    "    hs_df[col] = hs_df['park_name'].apply(lambda x: name_color_df.loc[name_color_df['best_match'] == x, col].iloc[0] if not name_color_df.loc[name_color_df['best_match'] == x, col].empty else None)\n",
    "\n",
    "# Drop the 'best_match' columns\n",
    "# hs_df.drop(columns=['best_match'], inplace=True)\n",
    "\n",
    "## Take a look at the new hs_df\n",
    "hs_df.head()\n",
    "\n",
    "\n",
    "\n",
    "# # Lookup the mhsaa_df['best_match'] in hs_df and return the columns: 'school_id', 'school_name', 'students', 'division'\n",
    "# columns_to_extract = ['school_id', 'school_name', 'students', 'division']\n",
    "# for col in columns_to_extract:\n",
    "#     mhsaa_df[col] = mhsaa_df['best_match'].apply(lambda x: hs_df.loc[hs_df['park_name'] == x, col].iloc[0] if not hs_df.loc[hs_df['park_name'] == x, col].empty else None)\n",
    "\n",
    "# # Apply find_best_match function to create a new column 'best_match' in name_color_df\n",
    "# name_color_df['best_match'] = name_color_df['School'].apply(find_best_match, choices=park_names, score_cutoff=80)\n",
    "\n",
    "# # Merge hs_df with mhsaa_df and name_color_df on the 'park_name' and 'best_match' columns\n",
    "# hs_df = hs_df.merge(mhsaa_df, left_on='park_name', right_on='best_match', how='left', suffixes=('', '_from_mhsaa'))\n",
    "# hs_df = hs_df.merge(name_color_df, left_on='park_name', right_on='best_match', how='left', suffixes=('', '_from_name_color'))\n",
    "\n",
    "# # Drop the 'best_match' columns\n",
    "# hs_df.drop(columns=['best_match_x', 'best_match_y'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 610 entries, 60 to 715\n",
      "Data columns (total 37 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   park_name                 610 non-null    object \n",
      " 1   foul                      610 non-null    object \n",
      " 2   fop                       610 non-null    object \n",
      " 3   level                     610 non-null    object \n",
      " 4   home_plate                610 non-null    object \n",
      " 5   foul_area_sqft            610 non-null    float64\n",
      " 6   fop_area_sqft             610 non-null    float64\n",
      " 7   field_area_sqft           610 non-null    float64\n",
      " 8   foul_area_per             610 non-null    float64\n",
      " 9   fair_to_foul              610 non-null    float64\n",
      " 10  distances                 610 non-null    object \n",
      " 11  max_distance              610 non-null    int64  \n",
      " 12  min_distance              610 non-null    int64  \n",
      " 13  avg_distance              610 non-null    float64\n",
      " 14  median_distance           610 non-null    float64\n",
      " 15  num_distances             610 non-null    int64  \n",
      " 16  max_distance_rank         610 non-null    float64\n",
      " 17  min_distance_rank         610 non-null    float64\n",
      " 18  avg_distance_rank         610 non-null    float64\n",
      " 19  field_area_rank           610 non-null    float64\n",
      " 20  ratio_rank                610 non-null    float64\n",
      " 21  fop_centroid              610 non-null    object \n",
      " 22  field_orientation         610 non-null    float64\n",
      " 23  field_cardinal_direction  610 non-null    object \n",
      " 24  lng                       610 non-null    float64\n",
      " 25  lat                       610 non-null    float64\n",
      " 26  state                     610 non-null    object \n",
      " 27  country                   610 non-null    object \n",
      " 28  school_id                 308 non-null    float64\n",
      " 29  school_name               308 non-null    object \n",
      " 30  students                  308 non-null    float64\n",
      " 31  division                  308 non-null    object \n",
      " 32  Nickname                  332 non-null    object \n",
      " 33  Color1                    332 non-null    object \n",
      " 34  Color2                    332 non-null    object \n",
      " 35  Color3                    17 non-null     object \n",
      " 36  Color4                    0 non-null      float64\n",
      "dtypes: float64(18), int64(3), object(16)\n",
      "memory usage: 181.1+ KB\n"
     ]
    }
   ],
   "source": [
    "### examine the output\n",
    "\n",
    "hs_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## MICHIGAN FIELDS ########\n",
    "########### TOGGLE THIS ON AND OFF TO OUTPUT THE DATAFRAME TO A json FILE ###########\n",
    "\n",
    "hs_df.to_json('data/michigan_fields.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# merge the two dataframes back to a single one (using append)\n",
    "\n",
    "# Merge the hs_df and other_df back together\n",
    "merged_df = pd.concat([hs_df, other_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df = df\n",
    "merged_df.head(10)\n",
    "\n",
    "# # Save the merged_df DataFrame as a JSON file\n",
    "merged_df.to_json('data/default_updated_output.json', orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = merged_df.columns\n",
    "print(column_list)\n",
    "\n",
    "# ## Print a list of ten high school field names to test mascot lookup\n",
    "# print(merged_df[merged_df['level'] == 'high_school']['park_name'].head(10).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Code to create report on the json file structure to be used as a reference later\n",
    "# import json\n",
    "# import pandas as pd\n",
    "# from collections import defaultdict\n",
    "# from builtins import list, dict\n",
    "\n",
    "# # Load the JSON data from the file\n",
    "# with open('data/updated_output_data.json', 'r') as file:\n",
    "#     data = json.load(file)\n",
    "\n",
    "# # Analyze the JSON data\n",
    "# def analyze_structure(data, prefix=''):\n",
    "#     structure = defaultdict(set)\n",
    "    \n",
    "#     if isinstance(data, dict):\n",
    "#         for key, value in data.items():\n",
    "#             new_prefix = f'{prefix}.{key}' if prefix else key\n",
    "#             structure[new_prefix].add(type(value))\n",
    "#             structure.update(analyze_structure(value, new_prefix))\n",
    "#     elif isinstance(data, list):\n",
    "#         for item in data:\n",
    "#             structure.update(analyze_structure(item, prefix))\n",
    "    \n",
    "#     return structure\n",
    "\n",
    "# # Generate the report\n",
    "# structure = analyze_structure(data)\n",
    "# descriptions = {\n",
    "#     'field_name': 'The name of the baseball field.',\n",
    "#     'foul': 'A list of coordinates representing the foul territory of the field. (lat, lon)',\n",
    "#     'fop': 'A list of coordinates representing the fair territory of the field. (lat, lon)',\n",
    "#     'level': 'The level of the field, e.g., high_school, college, etc.',\n",
    "#     'home_plate': 'A list of coordinates representing the home plate location on the field. (lat, lon)',\n",
    "#     'foul_area_sqft': 'The total area of the foul territory in square feet.',\n",
    "#     'fop_area_sqft': 'The total area of the fair territory in square feet.',\n",
    "#     'distances': 'A list of distances from home plate to the outfield fence at the vertices of the wall.',\n",
    "#     'max_distance': 'The maximum distance from home plate to the outfield fence.',\n",
    "#     'min_distance': 'The minimum distance from home plate to the outfield fence.',\n",
    "#     'avg_distance': 'The average distance from home plate to the outfield fence.',\n",
    "#     'fop_centroid': 'A list of coordinates representing the centroid of the fair territory.',\n",
    "#     'field_orientation': \"The angle (in degrees) of the field's orientation, with 0 degrees being North.\",\n",
    "#     'field_cardinal_direction': \"The cardinal direction abbreviation (N, S, E, W, NE, NW, SE, SW) representing the field's orientation.\",\n",
    "#     'match': 'The matched school name found using fuzzy matching.',\n",
    "#     'school_id': 'The unique identifier of the matched school.',\n",
    "#     'school_name': 'The name of the matched school.',\n",
    "#     'students': 'The number of students enrolled in the matched school.',\n",
    "#     'division': 'The athletic division the matched school belongs to.'\n",
    "# }\n",
    "\n",
    "# # Replace <filename> with your desired filename without the extension\n",
    "# filename = \"output_data\"\n",
    "\n",
    "# def get_sample_value(data, key):\n",
    "#     for item in data:\n",
    "#         if key in item and item[key] is not None:\n",
    "#             return item[key]\n",
    "#     return None\n",
    "\n",
    "# # Generate the report with sample values\n",
    "# report = pd.DataFrame([(key, ', '.join([t.__name__ for t in types]), descriptions.get(key, ''), get_sample_value(data, key)) \n",
    "#                        for key, types in structure.items()],\n",
    "#                       columns=['Key', 'Data Types', 'Description', 'Sample Value'])\n",
    "\n",
    "# # Save the report as a CSV file\n",
    "# report.to_csv(f\"{filename}_report.csv\", index=False)\n",
    "\n",
    "# print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Code to create report on some interesting stats like total fields, total area, ect\n",
    "\n",
    "# ## Create a function to measure the total distance of the outside of each polygon\n",
    "# from shapely.geometry import Polygon\n",
    "# import pyproj\n",
    "\n",
    "# def calculate_perimeter(coords):\n",
    "\n",
    "#     perimeter = 0\n",
    "\n",
    "#     for i in range(len(coords)):\n",
    "#         x1, y1 = coords[i]\n",
    "#         x2, y2 = coords[(i + 1) % len(coords)]\n",
    "#         perimeter += math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "\n",
    "#     return perimeter\n",
    "\n",
    "# # Get a sum of all of the perimeters\n",
    "# total_perimeter_fop = df['fop'].apply(calculate_perimeter).sum()\n",
    "# total_perimeter_foul = df['foul'].apply(calculate_perimeter).sum()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/default_updated_output.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to process the data, counting the orientations and filtering by level.\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def process_data(data, level_filter=None):\n",
    "    count_by_orientation = defaultdict(int)\n",
    "    \n",
    "    for record in data:\n",
    "        if level_filter is None or record['level'] == level_filter:\n",
    "            orientation = round(record['field_orientation'])\n",
    "            count_by_orientation[orientation] += 1\n",
    "\n",
    "    return count_by_orientation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_polar_chart(data, num_bins=36, level_filter=None):\n",
    "    count_by_orientation = process_data(data, level_filter)\n",
    "    \n",
    "    # Compute the histogram\n",
    "    bin_edges = np.linspace(0.0, 2 * np.pi, num_bins + 1)\n",
    "    bin_counts = np.zeros(num_bins)\n",
    "    \n",
    "    for orientation, count in count_by_orientation.items():\n",
    "        idx = int(orientation / (360 / num_bins))\n",
    "        if idx == num_bins:\n",
    "            idx = 0\n",
    "        bin_counts[idx] += count\n",
    "    \n",
    "    bin_width = 2 * np.pi / num_bins\n",
    "\n",
    "    # Set plot size\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    ax = plt.subplot(111, projection='polar')\n",
    "    ax.set_theta_offset(np.pi / 2)\n",
    "\n",
    "    ax.set_facecolor('#808080')\n",
    "    ###\n",
    "    # ax.set_yscale('log')\n",
    "\n",
    "    \n",
    "    # # Set dark background\n",
    "    # ax.set_facecolor('#2b2b2b')\n",
    "    plt.gca().set_rlabel_position(22.5)\n",
    "    ax.set_ylim(-10, 100)  # Adjust based on max count\n",
    "\n",
    "    bars = ax.bar(bin_edges[:-1], bin_counts, width=bin_width, bottom=-20)\n",
    "    \n",
    "\n",
    "\n",
    "    # Use custom colors and opacity\n",
    "    for r, bar in zip(bin_counts, bars):\n",
    "        bar.set_facecolor(plt.cm.viridis(r / max(bin_counts)))\n",
    "        # bar.set_facecolor(plt.cm.plasma(r / max(bin_counts)))\n",
    "        bar.set_alpha(0.8)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UPDATED GPT CODE - LATE NIGHT FRIDAY\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_polar_chart(data, num_bins=36, level_filter=None):\n",
    "    count_by_orientation = process_data(data, level_filter)\n",
    "    \n",
    "    # Compute the histogram\n",
    "    bin_edges = np.linspace(0.0, 2 * np.pi, num_bins + 1)\n",
    "    bin_counts = np.zeros(num_bins)\n",
    "    \n",
    "    for orientation, count in count_by_orientation.items():\n",
    "        idx = int(orientation / (360 / num_bins))\n",
    "        if idx == num_bins:\n",
    "            idx = 0\n",
    "        bin_counts[idx] += count\n",
    "    \n",
    "    bin_width = 2 * np.pi / num_bins\n",
    "\n",
    "    # Set plot size\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    ax = plt.subplot(111, projection='polar')\n",
    "    ax.set_theta_direction(-1)\n",
    "    ax.set_theta_offset(np.pi / 2)\n",
    "\n",
    "    ax.set_facecolor('#808080')\n",
    "    ###\n",
    "    # ax.set_yscale('log')\n",
    "\n",
    "    \n",
    "    # # Set dark background\n",
    "    ax.set_facecolor('#2b2b2b')\n",
    "    plt.gca().set_rlabel_position(22.5)\n",
    "    ax.set_ylim(-20, 130)  # Adjust based on max count\n",
    "\n",
    "    # Add bars for negative values\n",
    "    zero_height_bars = ax.bar(bin_edges[:-1], np.abs(ax.get_ylim()[0]), width=bin_width, bottom=0.0, color='k', alpha=0.3)\n",
    "\n",
    "    bars = ax.bar(bin_edges[:-1], bin_counts, width=bin_width, bottom=0)\n",
    "    \n",
    "    # Use custom colors and opacity\n",
    "    for r, bar in zip(bin_counts, bars):\n",
    "        bar.set_facecolor(plt.cm.viridis(r / max(bin_counts)))\n",
    "        # bar.set_facecolor(plt.cm.plasma(r / max(bin_counts)))\n",
    "        bar.set_alpha(0.8)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_polar_chart(data, num_bins=50, level_filter=None)\n",
    "\n",
    "\n",
    "#### GOAL\n",
    "## fill the center portion of the plot to create a heat map of the field orientations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_polar_chart(data, num_bins=60, level_filter=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### HEATMAP CODE\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def create_heatmap(data, num_bins=36, level_filter=None):\n",
    "#     count_by_orientation = process_data(data, level_filter)\n",
    "\n",
    "#     # Compute the histogram\n",
    "#     bin_edges = np.linspace(0.0, 2 * np.pi, num_bins + 1)\n",
    "#     bin_counts = np.zeros(num_bins)\n",
    "\n",
    "#     for orientation, count in count_by_orientation.items():\n",
    "#         idx = int(orientation / (360 / num_bins))\n",
    "#         if idx == num_bins:\n",
    "#             idx = 0\n",
    "#         bin_counts[idx] += count\n",
    "\n",
    "#     # Reshape histogram data into a 2D array\n",
    "#     heatmap_data = np.tile(bin_counts, (num_bins, 1))\n",
    "\n",
    "#     # Set plot size\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "\n",
    "#     # Create heatmap\n",
    "#     plt.imshow(heatmap_data, cmap='viridis', aspect='auto', interpolation='nearest', origin='lower')\n",
    "#     plt.colorbar(label='Counts')\n",
    "\n",
    "#     # Set x-axis ticks and labels\n",
    "#     plt.xticks(np.arange(0, num_bins, num_bins // 6), np.arange(0, 361, 60))\n",
    "#     plt.xlabel('Orientation (degrees)')\n",
    "\n",
    "#     # Set y-axis ticks and labels (assuming equal radial divisions)\n",
    "#     max_radius_label = 'Max Radius'\n",
    "#     plt.yticks(np.arange(0, num_bins, num_bins // 6), [0, 1, 2, 3, 4, max_radius_label])\n",
    "#     plt.ylabel('Radial Division')\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "# # Example usage:\n",
    "# # create_heatmap(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage:\n",
    "# create_heatmap(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot a histogram of the field orientations for all levels\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_histogram(data, num_bins=36, level_filter=None):\n",
    "    count_by_orientation = process_data(data, level_filter)\n",
    "    \n",
    "    # Compute the histogram\n",
    "    bin_edges = np.linspace(0.0, 360.0, num_bins + 1)\n",
    "    bin_counts = np.zeros(num_bins)\n",
    "    \n",
    "    for orientation, count in count_by_orientation.items():\n",
    "        idx = int(orientation / (360 / num_bins))\n",
    "        if idx == num_bins:\n",
    "            idx = 0\n",
    "        bin_counts[idx] += count\n",
    "    \n",
    "    bin_width = 360 / num_bins\n",
    "\n",
    "    # Plot the histogram\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(bin_edges[:-1], bin_counts, width=bin_width, edgecolor='black')\n",
    "    ax.set_xlabel('Field Orientation (degrees)')\n",
    "    ax.set_ylabel('Number of Fields')\n",
    "    ax.set_title('Field Orientation Histogram')\n",
    "\n",
    "    # Set the major tick locations\n",
    "    major_tick_locations = [45, 135, 225, 315]\n",
    "    plt.xticks(major_tick_locations, major_tick_locations)\n",
    "\n",
    "\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_histogram(data, num_bins=36, level_filter=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "END WORK BLOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['field_cardinal_direction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Rename the dataframe back to the default name\n",
    "df = merged_df\n",
    "\n",
    "# Set the plot size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.scatter(df_cleaned['min_distance'], df_cleaned['max_distance'], alpha=0.8)\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Min Distance (feet)')\n",
    "plt.ylabel('Max Distance (feet)')\n",
    "plt.title('Scatter Plot of Min and Max Distances to Outfield Fence')\n",
    "\n",
    "# Display the plot in the Jupyter Notebook\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE TO MAKE A LIST OF OUTLIERS #####\n",
    "\n",
    "# Filter the DataFrame for fields with min distances below 100 feet\n",
    "outliers = df[df['min_distance'] < 100]\n",
    "\n",
    "# Display the outlier fields in the Jupyter Notebook\n",
    "print(outliers[['park_name', 'min_distance', 'max_distance']])\n",
    "\n",
    "# Save the outlier fields to a CSV file\n",
    "outliers.to_csv('outlier_fields.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(\"Total time taken:\", total_time, \"seconds\")\n",
    "print(\"Total time taken:\", total_time/60, \"minutes\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
