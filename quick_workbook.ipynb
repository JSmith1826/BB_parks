{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the district html\n",
    "\n",
    "#### Goal: get dataframe that includes entire field with division along with their district assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>division</th>\n",
       "      <th>district</th>\n",
       "      <th>host</th>\n",
       "      <th>nickname</th>\n",
       "      <th>color1</th>\n",
       "      <th>color2</th>\n",
       "      <th>color3</th>\n",
       "      <th>color4</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alpena</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>Wildcats</td>\n",
       "      <td>Green</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marquette</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>Redmen/Redettes</td>\n",
       "      <td>Red</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mount Pleasant</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>Oilers</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Gold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Traverse City Central</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>Trojans</td>\n",
       "      <td>Black</td>\n",
       "      <td>Gold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Warren Fitzgerald</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>Hazel Park</td>\n",
       "      <td>Trojans</td>\n",
       "      <td>Black</td>\n",
       "      <td>Gold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Traverse City West</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>Titans</td>\n",
       "      <td>Forest Green</td>\n",
       "      <td>Vegas Gold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bay City Central</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Midland Dow</td>\n",
       "      <td>Wolves</td>\n",
       "      <td>Purple</td>\n",
       "      <td>Gold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bay City Western</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Midland Dow</td>\n",
       "      <td>Warriors</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Gold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Midland</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Midland Dow</td>\n",
       "      <td>Chemics</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Gold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Midland Dow</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Midland Dow</td>\n",
       "      <td>Chargers</td>\n",
       "      <td>Green</td>\n",
       "      <td>Gold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Saginaw Heritage</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Midland Dow</td>\n",
       "      <td>Hawks</td>\n",
       "      <td>Navy Blue</td>\n",
       "      <td>Kelly Green</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Grand Haven</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Muskegon Mona Shores</td>\n",
       "      <td>Buccaneers</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Gold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Grand Rapids Kenowa Hills</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Muskegon Mona Shores</td>\n",
       "      <td>Knights</td>\n",
       "      <td>Black</td>\n",
       "      <td>Gold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Muskegon</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Muskegon Mona Shores</td>\n",
       "      <td>Big Reds</td>\n",
       "      <td>Cardinal</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Muskegon Mona Shores</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Muskegon Mona Shores</td>\n",
       "      <td>Sailors</td>\n",
       "      <td>Navy Blue</td>\n",
       "      <td>Columbia</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Muskegon Reeths-Puffer</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Muskegon Mona Shores</td>\n",
       "      <td>Rockets</td>\n",
       "      <td>Green</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cedar Springs</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Grand Rapids Forest Hills Northern</td>\n",
       "      <td>Red Hawks</td>\n",
       "      <td>Red</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Grand Rapids Forest Hills Northern</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Grand Rapids Forest Hills Northern</td>\n",
       "      <td>Huskies</td>\n",
       "      <td>Columbia Blue</td>\n",
       "      <td>Black</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Grand Rapids Northview</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Grand Rapids Forest Hills Northern</td>\n",
       "      <td>Wildcats</td>\n",
       "      <td>Red</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Greenville</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Grand Rapids Forest Hills Northern</td>\n",
       "      <td>Yellow Jackets</td>\n",
       "      <td>Purple</td>\n",
       "      <td>Gold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  team division  district  \\\n",
       "0                               Alpena        1         1   \n",
       "1                            Marquette        1         1   \n",
       "2                       Mount Pleasant        1         1   \n",
       "3                Traverse City Central        1         1   \n",
       "4                    Warren Fitzgerald        2        57   \n",
       "5                   Traverse City West        1         1   \n",
       "6                     Bay City Central        1         2   \n",
       "7                     Bay City Western        1         2   \n",
       "8                              Midland        1         2   \n",
       "9                          Midland Dow        1         2   \n",
       "10                    Saginaw Heritage        1         2   \n",
       "11                         Grand Haven        1         3   \n",
       "12           Grand Rapids Kenowa Hills        1         3   \n",
       "13                            Muskegon        1         3   \n",
       "14                Muskegon Mona Shores        1         3   \n",
       "15              Muskegon Reeths-Puffer        1         3   \n",
       "16                       Cedar Springs        1         4   \n",
       "17  Grand Rapids Forest Hills Northern        1         4   \n",
       "18              Grand Rapids Northview        1         4   \n",
       "19                          Greenville        1         4   \n",
       "\n",
       "                                  host         nickname         color1  \\\n",
       "0                            Marquette         Wildcats         Green    \n",
       "1                            Marquette  Redmen/Redettes           Red    \n",
       "2                            Marquette           Oilers          Blue    \n",
       "3                            Marquette          Trojans         Black    \n",
       "4                           Hazel Park          Trojans         Black    \n",
       "5                            Marquette           Titans  Forest Green    \n",
       "6                          Midland Dow           Wolves        Purple    \n",
       "7                          Midland Dow         Warriors         Brown    \n",
       "8                          Midland Dow          Chemics          Blue    \n",
       "9                          Midland Dow         Chargers         Green    \n",
       "10                         Midland Dow            Hawks     Navy Blue    \n",
       "11                Muskegon Mona Shores       Buccaneers          Blue    \n",
       "12                Muskegon Mona Shores          Knights         Black    \n",
       "13                Muskegon Mona Shores         Big Reds      Cardinal    \n",
       "14                Muskegon Mona Shores          Sailors      Navy Blue   \n",
       "15                Muskegon Mona Shores          Rockets         Green    \n",
       "16  Grand Rapids Forest Hills Northern        Red Hawks           Red    \n",
       "17  Grand Rapids Forest Hills Northern          Huskies  Columbia Blue   \n",
       "18  Grand Rapids Forest Hills Northern         Wildcats           Red    \n",
       "19  Grand Rapids Forest Hills Northern   Yellow Jackets        Purple    \n",
       "\n",
       "          color2 color3  color4  score  \n",
       "0          White    NaN     NaN    100  \n",
       "1          White    NaN     NaN    100  \n",
       "2           Gold    NaN     NaN    100  \n",
       "3           Gold    NaN     NaN    100  \n",
       "4           Gold    NaN     NaN     53  \n",
       "5     Vegas Gold    NaN     NaN    100  \n",
       "6           Gold    NaN     NaN    100  \n",
       "7           Gold    NaN     NaN    100  \n",
       "8           Gold    NaN     NaN    100  \n",
       "9           Gold    NaN     NaN    100  \n",
       "10   Kelly Green    NaN     NaN    100  \n",
       "11          Gold    NaN     NaN    100  \n",
       "12          Gold    NaN     NaN    100  \n",
       "13         White    NaN     NaN    100  \n",
       "14      Columbia  White     NaN    100  \n",
       "15         White    NaN     NaN    100  \n",
       "16         White    NaN     NaN    100  \n",
       "17         Black  White     NaN    100  \n",
       "18         White    NaN     NaN    100  \n",
       "19          Gold    NaN     NaN    100  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import re\n",
    "\n",
    "# Load HTML\n",
    "html_path = 'data/districts_2023.html'\n",
    "with open(html_path, 'r') as f:\n",
    "    html = f.read()\n",
    "\n",
    "# Parse HTML\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Extract data\n",
    "divisions = soup.find_all('div', class_='keep-together')\n",
    "\n",
    "data = []\n",
    "for division in divisions:\n",
    "    division_number = division.find('span', {'data-bind': 'text:Division'}).text\n",
    "    tournament_name = division.find('span', {'data-bind': 'text:TournamentName'}).text\n",
    "    host = division.find('span', {'data-bind': 'text:Host'}).text\n",
    "    teams = [a.text for a in division.find_all('a')[1:]]\n",
    "\n",
    "    for team in teams:\n",
    "        data.append({\n",
    "            'team': team,\n",
    "            'division': division_number,\n",
    "            'district': int(re.sub(r'\\D+', '', tournament_name)),\n",
    "            'host': host,\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "df_by_district = pd.DataFrame(data)\n",
    "\n",
    "# Load the csv that contains nickname info\n",
    "df_nickname = pd.read_csv('data/school_info/mhsaa_school_nickname_color_2020.csv')\n",
    "df_nickname.columns = df_nickname.columns.str.lower()\n",
    "\n",
    "# Fuzzy match team names\n",
    "matches = df_by_district['team'].apply(lambda x: process.extractOne(x, df_nickname['school'], scorer=fuzz.ratio))\n",
    "\n",
    "df_by_district['match_name'] = [i[0] for i in matches]\n",
    "df_by_district['score'] = [i[1] for i in matches]\n",
    "\n",
    "# Merge df_by_district and df_nickname on the common columns generated by fuzzy matching\n",
    "final_df = pd.merge(df_by_district, df_nickname, left_on='match_name', right_on='school', how='inner')\n",
    "\n",
    "# Select only the columns you're interested in\n",
    "final_df = final_df[['team', 'division', 'district', 'host', 'nickname', 'color1', 'color2', 'color3', 'color4', 'score']]\n",
    "\n",
    "# Display the final dataframe\n",
    "# print(final_df)\n",
    "final_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output dataframe to new file called 2023_team_info.csv\n",
    "\n",
    "## Team info for 2023 output file\n",
    "# drop host column\n",
    "teams_df = final_df.drop(columns=['host'])\n",
    "\n",
    "# Path: quick_workbook.ipynb\n",
    "teams_df.to_csv('data/2023_team_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   team division  district  \\\n",
      "0                             Marquette        1         1   \n",
      "1                           Midland Dow        1         2   \n",
      "2                  Muskegon Mona Shores        1         3   \n",
      "3    Grand Rapids Forest Hills Northern        1         4   \n",
      "4                            Grandville        1         5   \n",
      "..                                  ...      ...       ...   \n",
      "122                             Genesee        4       124   \n",
      "123  Sterling Heights Parkway Christian        4       125   \n",
      "124     Waterford Our Lady of the Lakes        4       126   \n",
      "125           Riverview Gabriel Richard        4       127   \n",
      "126          Plymouth Christian Academy        4       128   \n",
      "\n",
      "                                   host         nickname         color1  \\\n",
      "0                             Marquette  Redmen/Redettes           Red    \n",
      "1                           Midland Dow         Chargers         Green    \n",
      "2                  Muskegon Mona Shores          Sailors      Navy Blue   \n",
      "3    Grand Rapids Forest Hills Northern          Huskies  Columbia Blue   \n",
      "4                            Grandville         Bulldogs        Maroon    \n",
      "..                                  ...              ...            ...   \n",
      "122                             Genesee           Wolves         Green    \n",
      "123  Sterling Heights Parkway Christian           Eagles     Royal Blue   \n",
      "124     Waterford Our Lady of the Lakes           Tigers  Columbia Blue   \n",
      "125           Riverview Gabriel Richard         Pioneers      Burgundy    \n",
      "126          Plymouth Christian Academy           Eagles         Purple   \n",
      "\n",
      "       color2 color3  color4  score  \n",
      "0       White    NaN     NaN    100  \n",
      "1        Gold    NaN     NaN    100  \n",
      "2    Columbia  White     NaN    100  \n",
      "3       Black  White     NaN    100  \n",
      "4       White    NaN     NaN    100  \n",
      "..        ...    ...     ...    ...  \n",
      "122     White    NaN     NaN    100  \n",
      "123       Red  White     NaN    100  \n",
      "124     White   Navy     NaN     58  \n",
      "125     White    NaN     NaN    100  \n",
      "126      Gold    NaN     NaN    100  \n",
      "\n",
      "[127 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter rows with matching host and team\n",
    "matching_rows = final_df[final_df['host'] == final_df['team']]\n",
    "\n",
    "# Sort the filtered rows by district number\n",
    "sorted_rows = matching_rows.sort_values(by='district')\n",
    "\n",
    "# Reset the index of the sorted rows\n",
    "sorted_rows.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the sorted dataframe\n",
    "print(sorted_rows)\n",
    "\n",
    "# Save the sorted dataframe to a CSV file\n",
    "sorted_rows.to_csv('data/2023_district_hosts.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head(20)\n",
    "\n",
    "## Show the lowest scores in the dataframe\n",
    "\n",
    "final_df.sort_values(by='score').head(20)\n",
    "\n",
    "## Show the distro of scores\n",
    "\n",
    "# final_df['score'].hist()\n",
    "\n",
    "## Show numberical counts of scores in incriments of 5\n",
    "\n",
    "# final_df['score'].value_counts(bins=range(0, 101, 5))\n",
    "\n",
    "# Number of match scores under 90\n",
    "\n",
    "len(final_df[final_df['score'] < 90])\n",
    "\n",
    "# Number of match scores under 80\n",
    "\n",
    "len(final_df[final_df['score'] < 80])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Block opperation above replaces the functionality of the following blocks of beta code\n",
    "\n",
    "## Create a table with School info (Name, division, district assignment - from the district_2023 html on MHSAA site)\n",
    "\n",
    "### Then merge that into the info from the table I have with School Nickname and colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load entire district tree from local html file\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_path = 'data\\districts_2023.html'\n",
    "\n",
    "with open(html_path, 'r') as f:\n",
    "    html = f.read()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ALL IN ONE TRY ####\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "html_doc = html\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "# Create an empty DataFrame to store the data\n",
    "df = pd.DataFrame(columns=['Division', 'Tournament Name', 'Host', 'Location', 'Teams'])\n",
    "\n",
    "# Find all 'div' tags with class 'keep-together'\n",
    "divisions = soup.find_all('div', class_='keep-together')\n",
    "\n",
    "for division in divisions:\n",
    "    division_number = division.find('span', {'data-bind': 'text:Division'}).text\n",
    "    tournament_name = division.find('span', {'data-bind': 'text:TournamentName'}).text\n",
    "    host = division.find('span', {'data-bind': 'text:Host'}).text\n",
    "    location = division.find('a', {'data-bind': 'text: Title, attr: {href: LocationUrl}'}).text\n",
    "    \n",
    "    # Find all the team names, skipping the first 'a' tag which is the location\n",
    "    teams = [a.text for a in division.find_all('a')[1:]]\n",
    "    # # Remove the host team from the list\n",
    "    # if host in teams:\n",
    "    #     teams.remove(host)\n",
    "    \n",
    "    # Add data to the DataFrame\n",
    "    df = df.append({\n",
    "        'Division': division_number, \n",
    "        'Tournament Name': tournament_name, \n",
    "        'Host': host, \n",
    "        'Location': location, \n",
    "        'Teams': teams}, \n",
    "        ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get a DF with a row for every team\n",
    "\n",
    "df_temp = df.explode('Teams')\n",
    "\n",
    "df_temp.info()\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean up the new team DF\n",
    "\n",
    "## Drop The non numberical characters from 'Tournament Name' and Rename to 'District'\n",
    "\n",
    "df_temp['District'] = df_temp['Tournament Name'].str.replace(r'\\D+', '')\n",
    "\n",
    "df_temp['District'] = df_temp['District'].astype(int)\n",
    "\n",
    "# Drop the 'Tournament Name' column\n",
    "df_temp.drop('Tournament Name', axis=1, inplace=True)\n",
    "\n",
    "## Drop Host and Location\n",
    "\n",
    "df_temp.drop(['Host', 'Location'], axis=1, inplace=True)\n",
    "\n",
    "# Rename Teams to Team\n",
    "df_temp.rename(columns={'Teams': 'Team'}, inplace=True)\n",
    "\n",
    "# Remove capitalization from column names\n",
    "df_temp.columns = df_temp.columns.str.lower()\n",
    "\n",
    "\n",
    "## Move team name to first column\n",
    "\n",
    "cols = df_temp.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df_temp = df_temp[cols]\n",
    "\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rename df\n",
    "\n",
    "df_by_district = df_temp\n",
    "\n",
    "## Load the csv that contains nickname ect info\n",
    "\n",
    "df_nickname = pd.read_csv('data\\school_info\\mhsaa_school_nickname_color_2020.csv')\n",
    "\n",
    "## Remove capitalization from column names\n",
    "df_nickname.columns = df_nickname.columns.str.lower()\n",
    "\n",
    "df_nickname.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### match and merge the dataframes based on Team name and School name\n",
    "\n",
    "### Use fuzzy match to match team names\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "def match_name(name, list_names, min_score=0):\n",
    "    # -1 score incase we don't get any matches\n",
    "    max_score = -1\n",
    "    # Returning empty name for no match as well\n",
    "    max_name = \"\"\n",
    "    # Iternating over all names in the other\n",
    "    for name2 in list_names:\n",
    "        #Finding fuzzy match score\n",
    "        score = fuzz.ratio(name, name2)\n",
    "        # Checking if we are above our threshold and have a better score\n",
    "        if (score > min_score) & (score > max_score):\n",
    "            max_name = name2\n",
    "            max_score = score\n",
    "    return (max_name, max_score)\n",
    "\n",
    "# List for dicts for easy dataframe creation\n",
    "dict_list = []\n",
    "# iterating over our players without salaries found above\n",
    "for name in df_by_district.team:\n",
    "    # Use our method to find best match, we can set a threshold here\n",
    "    match = match_name(name, df_nickname.school, 75)\n",
    "    \n",
    "    # New dict for storing data\n",
    "    dict_ = {}\n",
    "    dict_.update({\"team_name\" : name})\n",
    "    dict_.update({\"match_name\" : match[0]})\n",
    "    dict_.update({\"score\" : match[1]})\n",
    "    dict_list.append(dict_)\n",
    "    \n",
    "merge_table = pd.DataFrame(dict_list)\n",
    "# Display results\n",
    "# print(merge_table)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do the table merges\n",
    "\n",
    "df_by_district = df_by_district.merge(merge_table, left_on='team', right_on='team_name', how='left')\n",
    "df_nickname = df_nickname.merge(merge_table, left_on='school', right_on='match_name', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_by_district and df_nickname on the common columns generated by fuzzy matching\n",
    "final_df = pd.merge(df_by_district, df_nickname, left_on='team', right_on='match_name', how='inner')\n",
    "\n",
    "# Select only the columns you're interested in\n",
    "final_df = final_df[['team', 'division', 'district', 'nickname', 'color1', 'color2', 'color3', 'color4', 'score']]\n",
    "\n",
    "\n",
    "# Display the final dataframe\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv to check\n",
    "\n",
    "df.to_csv('data\\district_2023_team_and_host.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End 2023 Team info creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a dictionary of all the teams seperated by division level\n",
    "\n",
    "# Create an empty dictionary to store the data\n",
    "divisions_dict = {}\n",
    "\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "html_doc = html\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "# Create an empty DataFrame to store the data\n",
    "df = pd.DataFrame(columns=['Division', 'Tournament Name', 'Host', 'Location', 'Teams'])\n",
    "\n",
    "# Find all 'div' tags with class 'keep-together'\n",
    "divisions = soup.find_all('div', class_='keep-together')\n",
    "\n",
    "for division in divisions:\n",
    "    division_number = division.find('span', {'data-bind': 'text:Division'}).text\n",
    "    tournament_name = division.find('span', {'data-bind': 'text:TournamentName'}).text\n",
    "    host = division.find('span', {'data-bind': 'text:Host'}).text\n",
    "    location = division.find('a', {'data-bind': 'text: Title, attr: {href: LocationUrl}'}).text\n",
    "    teams = [team.text for team in division.find_all('span', {'data-bind': 'highlightedText: { text: TeamName, highlight: $parents[1].Search, css: \"highlight\" }'})]\n",
    "    \n",
    "    # Add data to the DataFrame\n",
    "    df = df.append({\n",
    "        'Division': division_number, \n",
    "        'Tournament Name': tournament_name, \n",
    "        'Host': host, \n",
    "        'Location': location, \n",
    "        'Teams': teams}, \n",
    "        ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "## File Paths\n",
    "# Path to mhsaa tables to merge\n",
    "\n",
    "enrollment_path = 'data\\school_info\\mhsaa_enrolment_2022.csv'\n",
    "name_color_path = 'data\\school_info\\mhsaa_school_nickname_color_2020.csv'\n",
    "\n",
    "df_enrol = pd.read_csv(enrollment_path)\n",
    "df_name_color = pd.read_csv(name_color_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5-9-23\n",
    "\n",
    "## Code to scrape 2023 MHSAA Tourny Data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace this with the plain text containing the tournament information\n",
    "# read a text file into the variable text\n",
    "\n",
    "text = open('2023_districts_raw.txt', 'r').read()\n",
    "\n",
    "# Split the text into sections for each division\n",
    "sections = text.split('Division ')\n",
    "\n",
    "# Remove the first empty string\n",
    "sections.pop(0)\n",
    "\n",
    "# Initialize empty lists for each column in the dataframe\n",
    "divisions = []\n",
    "districts = []\n",
    "hosts = []\n",
    "locations = []\n",
    "\n",
    "# Loop through the sections and extract the relevant information\n",
    "for section in sections:\n",
    "    lines = section.split('\\n')\n",
    "    division = 'Division ' + lines[0]\n",
    "    for line in lines[1:]:\n",
    "        if 'Baseball District' in line:\n",
    "            district = line\n",
    "        elif 'Host:' in line:\n",
    "            host = line.split(': ')[1]\n",
    "        elif 'Location:' in line:\n",
    "            location = line.split(': ')[1]\n",
    "        elif line != '':\n",
    "            # Skip any blank lines\n",
    "            districts.append(district)\n",
    "            divisions.append(division)\n",
    "            hosts.append(host)\n",
    "            locations.append(location)\n",
    "\n",
    "# Create a dataframe to store the extracted information\n",
    "df = pd.DataFrame({'Division': divisions, 'District': districts, 'Host': hosts, 'Location': locations})\n",
    "\n",
    "# Print the dataframe\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DF came back as a ton of duplicates. I need to clean it up.\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Reindex the dataframe\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# output the dataframe to a csv file\n",
    "df.to_csv('data/2023_district_hosts.csv', index=False)\n",
    "\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regional Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### URLS of pages with retional data\n",
    "\n",
    "urls = {'Division 1': 'https://my.mhsaa.com/Sports/MHSAA-Tournament-Brackets/BracketGroup/9/Classification/1/SportSeasonId/424201',\n",
    "        'Division 2': 'https://my.mhsaa.com/Sports/MHSAA-Tournament-Brackets/BracketGroup/9/Classification/2/SportSeasonId/424201',\n",
    "        'Division 3': 'https://my.mhsaa.com/Sports/MHSAA-Tournament-Brackets/BracketGroup/9/Classification/3/SportSeasonId/424201',\n",
    "        'Division 4': 'https://my.mhsaa.com/Sports/MHSAA-Tournament-Brackets/BracketGroup/9/Classification/4/SportSeasonId/424201'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URLs for each division\n",
    "urls = {'Division 1': 'https://my.mhsaa.com/Sports/MHSAA-Tournament-Brackets/BracketGroup/9/Classification/1/SportSeasonId/424201',\n",
    "        'Division 2': 'https://my.mhsaa.com/Sports/MHSAA-Tournament-Brackets/BracketGroup/9/Classification/2/SportSeasonId/424201',\n",
    "        'Division 3': 'https://my.mhsaa.com/Sports/MHSAA-Tournament-Brackets/BracketGroup/9/Classification/3/SportSeasonId/424201',\n",
    "        'Division 4': 'https://my.mhsaa.com/Sports/MHSAA-Tournament-Brackets/BracketGroup/9/Classification/4/SportSeasonId/424201'}\n",
    "\n",
    "# Initialize empty lists for each column in the dataframe\n",
    "divisions = []\n",
    "locations = []\n",
    "links = []\n",
    "\n",
    "# Loop through each division URL in the dictionary\n",
    "for division, url in urls.items():\n",
    "    try:\n",
    "        # Send a GET request to the URL and parse the HTML content\n",
    "        page = requests.get(url)\n",
    "        tree = html.fromstring(page.content)\n",
    "\n",
    "        # Find all the contest location spans using XPath\n",
    "        location_spans = tree.xpath('//span[@class=\"contestlocation\"]')\n",
    "\n",
    "        # Loop through the location spans and extract the relevant information\n",
    "        for location_span in location_spans:\n",
    "            # Extract the location and link from the contest location span\n",
    "            location = location_span.xpath('text()')[0].strip()\n",
    "            link = location_span.xpath('a/@href')[0]\n",
    "            # Append the information to the respective lists\n",
    "            divisions.append(division)\n",
    "            locations.append(location)\n",
    "            links.append(link)\n",
    "    except:\n",
    "        print(f'Error: Failed to retrieve data for {division}')\n",
    "\n",
    "# Create a dataframe to store the extracted information\n",
    "df = pd.DataFrame({'Division': divisions, 'Location': locations, 'Link': links})\n",
    "\n",
    "# Reset the index of the dataframe\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Print the dataframe\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean up the dataframe\n",
    "\n",
    "## Drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "df.head(30)\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "\n",
    "### Output as a csv\n",
    "## Might want to go back and adjust code to try to store which specific games are at each location\n",
    "## regional has (semis and finals) then there is a quarterfinals round\n",
    "\n",
    "df.to_csv('data/2023_regional_hosts.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Project\n",
    "\n",
    "### Create a json with just the fields in michigan and try to integrate a column that marks the appropriate fields as host of districts and regionals\n",
    "\n",
    "The text of the locations in the playoff csvs is not going to match the field names all that well. it might be worth trying to identify them from the map location - will have to go back to districts and extract map locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Try to get all the google maps link from the districts page\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "## Read local file\n",
    "path = 'districts_2023.html'\n",
    "html = open(path, 'r').read()\n",
    "\n",
    "\n",
    "# Parse the HTML\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Find all the tournament divs\n",
    "tournaments = soup.select('div.keep-together')\n",
    "\n",
    "# Initialize lists to store data\n",
    "district_numbers = []\n",
    "hosts = []\n",
    "locations = []\n",
    "\n",
    "# Extract data for each tournament\n",
    "for tournament in tournaments:\n",
    "    district_number = tournament.find('span', {'data-bind': 'text:Division'}).text\n",
    "    host = tournament.find('span', {'data-bind': 'text:Host'}).text\n",
    "    location = tournament.find('a', {'target': '_blank'}).get('href')\n",
    "    \n",
    "\n",
    "    district_numbers.append(district_number)\n",
    "    hosts.append(host)\n",
    "    locations.append(location)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {'Division': district_numbers, 'Host': hosts, 'Location': locations}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# add another column the is the index number of the row + 1\n",
    "df['District'] = df.index + 1\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "df.to_csv('district_tournaments.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to match up locations from the scraped district and regional and link them to a field in my json data\n",
    "\n",
    "## Stragegy: The district csv contains a field that has a link to a google maps search. Loop through all of those and return the lat and longitude coordinates then match the coordinates to the nearest home plate coordinate in the json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import googlemaps\n",
    "\n",
    "## paths\n",
    "\n",
    "local_json = 'data\\michigan_fields.json'\n",
    "\n",
    "district_csv = 'district_tournaments.csv'\n",
    "\n",
    "regional_csv = 'data\\2023_regional_hosts.csv'\n",
    "\n",
    "# Replace this with your own API key\n",
    "api_key = \"AIzaSyA_BhlTupRdBPBhRptQuR6pYorMVYQnRMA\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Data\n",
    "df = pd.read_csv(district_csv)\n",
    "\n",
    "# df.head()\n",
    "\n",
    "df.info()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clean up the location column to remove first portion and just leave the address remaining\n",
    "\n",
    "\n",
    "\n",
    "# Remove the unwanted portion of the string in the 'Location' column\n",
    "prefix = \"http://maps.google.com/maps?q=\"\n",
    "\n",
    "# Check if the location is a string before applying lstrip\n",
    "df['Location'] = df['Location'].apply(lambda x: x.lstrip(prefix) if isinstance(x, str) else x)\n",
    "\n",
    "# Print the cleaned DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USES GOOGLE CODE\n",
    "import pandas as pd\n",
    "import googlemaps\n",
    "\n",
    "# Replace 'your_api_key' with your actual Google Maps API key\n",
    "api_key = 'AIzaSyA_BhlTupRdBPBhRptQuR6pYorMVYQnRMA'\n",
    "gmaps = googlemaps.Client(key=api_key)\n",
    "\n",
    "# # Create a DataFrame from your data (use your actual DataFrame here)\n",
    "# data = {\n",
    "#     \"Division\": [1, 1, 1],\n",
    "#     \"Host\": [\"Marquette\", \"Midland Dow\", \"Muskegon Mona Shores\"],\n",
    "#     \"Location\": [\n",
    "#         \"North Marquette Fields, Marquette, MI\",\n",
    "#         \"H H Dow High School - Baseball, 3901 N. Saginaw Rd. Midland, MI\",\n",
    "#         \"Mona Shores Baseball Field, 1121 W. Seminole Rd. Muskegon, MI\",\n",
    "#     ],\n",
    "#     \"District\": [1, 2, 3],\n",
    "# }\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# Function to get the coordinates for a given address\n",
    "def get_coordinates(address):\n",
    "    geocode_result = gmaps.geocode(address)\n",
    "    if geocode_result:\n",
    "        lat = geocode_result[0][\"geometry\"][\"location\"][\"lat\"]\n",
    "        lng = geocode_result[0][\"geometry\"][\"location\"][\"lng\"]\n",
    "        return (lat, lng)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Apply the function to the 'Location' column and store the coordinates in a new column\n",
    "df[\"Coordinates\"] = df[\"Location\"].apply(get_coordinates)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check Output\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google code worked OK - returned coords for 126 of 128\n",
    "\n",
    "### Below I am going to try to match up those coordinates to the michigan fields jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### set up paths and load data(copied from above)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "# import googlemaps\n",
    "\n",
    "## paths\n",
    "\n",
    "local_json = 'data\\michigan_fields.json'\n",
    "\n",
    "district_csv = 'district_tournaments.csv'\n",
    "\n",
    "regional_csv = 'data\\2023_regional_hosts.csv'\n",
    "\n",
    "# Replace this with your own API key\n",
    "api_key = \"AIzaSyA_BhlTupRdBPBhRptQuR6pYorMVYQnRMA\"\n",
    "\n",
    "# load Data\n",
    "df = pd.read_csv(district_csv)\n",
    "\n",
    "## Load MI fields data from json file\n",
    "\n",
    "\n",
    "# Read the JSON file\n",
    "with open(local_json) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Create a DataFrame from the JSON data\n",
    "mi_df = pd.DataFrame(data)\n",
    "\n",
    "mi_df.head()\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Try a different approach to match the fields\n",
    "## Use the Host name to find 3 matches from the mi_df\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "# Assuming you have the two dataframes df and mi_df\n",
    "\n",
    "def find_closest_park_names(host, n_closest=3):\n",
    "    closest_park_names = process.extract(host, mi_df[\"park_name\"], limit=n_closest, scorer=fuzz.token_sort_ratio)\n",
    "    return [name for name, score, index in closest_park_names]\n",
    "\n",
    "# Apply the function to the 'Host' column and store the results in new columns\n",
    "df[[\"closest_park_1\", \"closest_park_2\", \"closest_park_3\"]] = df[\"Host\"].apply(find_closest_park_names).apply(pd.Series)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FUNCTION TO FIND NEAREST FIELD TO DISTRICT TOURNAMENT LOCATION\n",
    "\n",
    "import math\n",
    "\n",
    "## Define a function to calculate the Haversine distance between two points\n",
    "def haversine_distance(coord1, coord2):\n",
    "    # Convert latitude and longitude to radians\n",
    "    lat1, lon1 = map(math.radians, coord1)\n",
    "    lat2, lon2 = map(math.radians, coord2)\n",
    "\n",
    "    # Calculate the differences between latitudes and longitudes\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    # Calculate the Haversine distance\n",
    "    a = math.sin(dlat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2) ** 2\n",
    "    c = 2 * math.asin(math.sqrt(a))\n",
    "    r = 6371  # Radius of the Earth in km\n",
    "\n",
    "    return c * r\n",
    "\n",
    "def find_closest_parks(coord, n_closest=3):\n",
    "    if coord is None:\n",
    "        return [\"Unknown\"] * n_closest\n",
    "\n",
    "    mi_df[\"distance\"] = mi_df[\"home_plate\"].apply(lambda x: haversine_distance(coord, (x[1], x[0])))\n",
    "    closest_park_indices = mi_df[\"distance\"].nsmallest(n_closest).index\n",
    "    return mi_df.loc[closest_park_indices, \"park_name\"].tolist()\n",
    "\n",
    "\n",
    "\n",
    "# Make sure 'home_plate' in mi_df has coordinates in the format (lat, lng)\n",
    "mi_df[\"home_plate\"] = mi_df[\"home_plate\"].apply(lambda x: (x[0], x[1]))\n",
    "\n",
    "# Create a new column 'closest_park' in df\n",
    "df[[\"closest_park_1\", \"closest_park_2\", \"closest_park_3\"]] = df[\"Coordinates\"].apply(find_closest_parks).apply(pd.Series)\n",
    "\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output this matching as a csv so I can manulauly check it\n",
    "\n",
    "df.to_csv('district_fields_text_match.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of 5-9-23 Work for now. output csv file with possible matches for the district fields\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with outlier fields \n",
    "\n",
    "## Start 59/23 Night\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependencies and Setup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import numpy as np\n",
    "\n",
    "# Load files\n",
    "out_df = pd.read_csv('outlier_fields.csv')\n",
    "\n",
    "out_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_out = df_out.copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you already have the out_df DataFrame\n",
    "# Creating an empty HP2 column\n",
    "out_df['HP2'] = None\n",
    "\n",
    "# Loop through the DataFrame rows and populate the HP2 column with repeated points\n",
    "for idx, row in out_df.iterrows():\n",
    "    fop_list = row['fop']\n",
    "    repeated_points = [point for point in set(fop_list) if fop_list.count(point) > 1]\n",
    "    if len(repeated_points) > 0:\n",
    "        out_df.loc[idx, 'HP2'] = str(repeated_points[0])\n",
    "\n",
    "# Display the updated DataFrame\n",
    "out_df.head(20)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from lxml import html\n",
    "\n",
    "url = 'https://my.mhsaa.com/Sports/Baseball/Districts'  # Replace this with the URL of the webpage you want to scrape\n",
    "page = requests.get(url)\n",
    "tree = html.fromstring(page.content)\n",
    "\n",
    "# Find the game location using the XPath\n",
    "location = tree.xpath('/html/body/form/div[5]/div[2]/div/div/div[2]/div[1]/div/div/div/div/div/div/div/div[2]/div[2]/div[1]/div[2]/div[1]/a')[0]\n",
    "\n",
    "# Extract the relevant information\n",
    "name = location.text.strip()\n",
    "link = location.get('href')\n",
    "address = link.split('=')[1].strip()\n",
    "\n",
    "# Create a dataframe to store the scraped data\n",
    "df = pd.DataFrame({'Field_name': [name], 'Location': [address], 'Link': [link]})\n",
    "\n",
    "# Print the dataframe\n",
    "print(df)\n",
    "\n",
    "\n",
    "# Get latitude and longitude for each location\n",
    "df[\"Coordinates\"] = df[\"Location\"].apply(get_latitude_longitude)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_name_color.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Match the school name to School and merge the dataframes into a single object\n",
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "def find_best_match(school_name, choices, score_cutoff=70):\n",
    "    best_match = process.extractOne(school_name, choices, scorer=fuzz.token_sort_ratio, score_cutoff=score_cutoff)\n",
    "    if best_match:\n",
    "        return best_match[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Get the list of school names from df_name_color\n",
    "school_names = df_name_color['School'].tolist()\n",
    "\n",
    "# Apply find_best_match function to create a new column 'best_match' in df_enrol\n",
    "df_enrol['best_match'] = df_enrol['school_name'].apply(find_best_match, choices=school_names, score_cutoff=80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the 'School' column in df_name_color to 'best_match'\n",
    "df_name_color = df_name_color.rename(columns={'School': 'best_match'})\n",
    "\n",
    "# Merge the dataframes on the 'best_match' column\n",
    "df_merged = df_enrol.merge(df_name_color, on='best_match', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_enrol.columns)\n",
    "\n",
    "print(df_name_color.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - get icons sorted out\n",
    "# -*** DONE*** get the level assigner sorted out in the etl\n",
    "# - add filter based on level to map\n",
    "# - implement the search box places from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
